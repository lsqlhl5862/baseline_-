{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfplumber'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1490d7ebcde8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteractiveshell\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautonotebook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mast_node_interactivity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"all\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdfplumber'"
     ]
    }
   ],
   "source": [
    "# 导入相关包\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from io import StringIO\n",
    "from datetime import datetime \n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from tqdm.autonotebook import *\n",
    "import pdfplumber\n",
    "tqdm.pandas()\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF解析原始数据 \n",
    "## 加载数据并采用pdfplumber抽取PDF中的文字和表格\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>认购日期</th>\n",
       "      <th>理财产品名称</th>\n",
       "      <th>产品发行方名称</th>\n",
       "      <th>理财类型</th>\n",
       "      <th>认购金额(万元)</th>\n",
       "      <th>产品起息日</th>\n",
       "      <th>产品到息日</th>\n",
       "      <th>产品期限</th>\n",
       "      <th>资金来源</th>\n",
       "      <th>实际购买公司名称</th>\n",
       "      <th>实际购买公司和上市公司关系</th>\n",
       "      <th>买卖方是否有关联关系</th>\n",
       "      <th>公告日期</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>汇聚金1号</td>\n",
       "      <td>中融国际信托有限公司</td>\n",
       "      <td>信托</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>180天</td>\n",
       "      <td>自有资金</td>\n",
       "      <td>恒生电子股份有限公司</td>\n",
       "      <td>公司本身</td>\n",
       "      <td>否</td>\n",
       "      <td>2019-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>招商银行步步生金8699</td>\n",
       "      <td>招商银行</td>\n",
       "      <td>银行理财产品</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>自有资金</td>\n",
       "      <td>恒生电子股份有限公司</td>\n",
       "      <td>公司本身</td>\n",
       "      <td>否</td>\n",
       "      <td>2019-04-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id       认购日期        理财产品名称     产品发行方名称    理财类型  认购金额(万元)  \\\n",
       "0          1 2019-03-27         汇聚金1号  中融国际信托有限公司      信托   10000.0   \n",
       "1          1 2019-03-27  招商银行步步生金8699        招商银行  银行理财产品     200.0   \n",
       "\n",
       "       产品起息日      产品到息日  产品期限  资金来源    实际购买公司名称 实际购买公司和上市公司关系 买卖方是否有关联关系  \\\n",
       "0 2019-03-27 2019-09-23  180天  自有资金  恒生电子股份有限公司          公司本身          否   \n",
       "1 2019-03-27        NaT   NaN  自有资金  恒生电子股份有限公司          公司本身          否   \n",
       "\n",
       "        公告日期  \n",
       "0 2019-04-25  \n",
       "1 2019-04-25  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>text</th>\n",
       "      <th>tabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>datasets/train_data/1.PDF</td>\n",
       "      <td>['                                            ...</td>\n",
       "      <td>[[['', None, None, '', None, None, '', None, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>datasets/train_data/2.PDF</td>\n",
       "      <td>['                                            ...</td>\n",
       "      <td>[[['', None, None, '', None, None, '', None, N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                  file_path  \\\n",
       "0          1  datasets/train_data/1.PDF   \n",
       "1          2  datasets/train_data/2.PDF   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['                                            ...   \n",
       "1  ['                                            ...   \n",
       "\n",
       "                                               tabel  \n",
       "0  [[['', None, None, '', None, None, '', None, N...  \n",
       "1  [[['', None, None, '', None, None, '', None, N...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>text</th>\n",
       "      <th>tabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11188</td>\n",
       "      <td>datasets/test_data/11188.PDF</td>\n",
       "      <td>['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11189</td>\n",
       "      <td>datasets/test_data/11189.PDF</td>\n",
       "      <td>['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                     file_path  \\\n",
       "0      11188  datasets/test_data/11188.PDF   \n",
       "1      11189  datasets/test_data/11189.PDF   \n",
       "\n",
       "                                                text tabel  \n",
       "0  ['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...    []  \n",
       "1  ['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...    []  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据准备(train_output文件中格式有点问题，需要提前用excel或者wps打开然后另存为excel文件)\n",
    "train_outputs = pd.read_excel('datasets/train_output.xls')\n",
    "\n",
    "# 获取pdf中文字和表格\n",
    "def extract_pdf_content(pdf_path):\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for index_page in np.arange(0, len(pdf.pages), 1):\n",
    "            # 读取多页\n",
    "            page = pdf.pages[index_page]   # 第n页的信息\n",
    "            text = page.extract_text()\n",
    "            text_list.append(text)\n",
    "            table = page.extract_tables()\n",
    "            for t in table:\n",
    "                table_list.append(t)\n",
    "    return text_list, table_list\n",
    "\n",
    "def get_dir_file(path):\n",
    "    '''\n",
    "    输入文件夹位置，输出整理好的dataframe\n",
    "    '''\n",
    "    path_list = os.listdir(path)\n",
    "    id_list = []\n",
    "    file_path_list = []\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    for i in tqdm(path_list):\n",
    "        if '.PDF' in i:\n",
    "            file_path = path + i\n",
    "            id_list.append(int(i.split('.')[0]))\n",
    "            file_path_list.append(file_path)\n",
    "            try:\n",
    "                text_temp, table_temp = extract_pdf_content(file_path)\n",
    "            except Exception:\n",
    "                print('此pdf无法读取')\n",
    "                text_temp, table_temp = [], []\n",
    "            text_list.append(text_temp)\n",
    "            table_list.append(table_temp)\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df['sample_id'] = id_list\n",
    "    df['file_path'] = file_path_list\n",
    "    df['text'] = text_list\n",
    "    df['tabel'] = table_list\n",
    "    df = df.sort_values('sample_id')\n",
    "    return df\n",
    "\n",
    "# 文件处理太慢，可持续化保存文件\n",
    "train_path = 'datasets/train.csv'\n",
    "if os.path.exists(train_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "else:\n",
    "    train_df = get_dir_file('datasets/train_data/')\n",
    "    train_df.to_csv(train_path,index=False)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "\n",
    "test_path =  'datasets/test.csv'\n",
    "if os.path.exists(test_path):\n",
    "    test_df = pd.read_csv(test_path)\n",
    "else:\n",
    "    test_df = get_dir_file('datasets/test_data/')\n",
    "    test_df.to_csv(test_path,index=False)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "train_outputs.head(2)\n",
    "train_df.head(2)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造训练集验证集\n",
    "train_df = train_df.sample(frac=1, random_state=1017)\n",
    "val_df = train_df[:1800]\n",
    "train_df = train_df[1800:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理\n",
    "## 抽取整体数据（一个sampleid内此字段内容都相同）\n",
    "## 公告时间，实际购买公司"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.抽取公告时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec82f6d59c30457f9e0eaf02251ca885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4583333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed0cc18a3ad4d09882ac2a95eb5cf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2adfba69cee43ce9a0540d8aa9d1070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8660.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 首先针对任务抽取时间（每个时间跟每个id是一一对应的）\n",
    "# 要不是取第一个时间，要不就是取最后一个时间（或者时间加一）这里可以建立一个模型预测\n",
    "# base这里面直接取最后一个时间作为发布日期\n",
    "\n",
    "CN_NUM = {\n",
    "    u'〇': 0, u'一': 1, u'二': 2, u'三': 3,\n",
    "    u'四': 4, u'五': 5, u'六': 6, u'七': 7,\n",
    "    u'八': 8, u'九': 9, u'零': 0, u'壹': 1,\n",
    "    u'贰': 2, u'叁': 3, u'肆': 4, u'伍': 5,\n",
    "    u'陆': 6, u'柒': 7, u'捌': 8, u'玖': 9,\n",
    "    u'貮': 2, u'两': 2,\n",
    "}\n",
    "\n",
    "\n",
    "def get_put_time_from_text(row):\n",
    "    row = row.replace(' ', '').replace('\\\\n', '')\n",
    "    for key in CN_NUM:\n",
    "        row = row.replace(key, str(CN_NUM[key]))   \n",
    "    r = row.replace(\"年\", \"-\").replace(\"月\", \"-\").replace(\"日\", \" \").replace(\"/\", \"-\").strip()\n",
    "    regex = \"(\\d{4}-\\d{1,2}-\\d{1,2})\"\n",
    "    r = re.findall(regex, r)\n",
    "    if len(r)==0:\n",
    "        return np.nan\n",
    "    time_str = r[-1]\n",
    "    first = time_str.split('-')[0]\n",
    "    second = time_str.split('-')[1]\n",
    "    last = time_str.split('-')[-1]\n",
    "    second = str.zfill(second, 2)\n",
    "    last = str.zfill(last, 2)\n",
    "    r = '-'.join([first, second, last])\n",
    "    return r\n",
    "\n",
    "val_result = pd.DataFrame()\n",
    "val_result['sample_id'] = val_df['sample_id']\n",
    "val_result['predict_time'] = val_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "test_gg = train_outputs.groupby('sample_id').apply(lambda row:list(row['公告日期'])[0]).reset_index()\n",
    "test_gg.columns = ['sample_id', 'time']\n",
    "val_result = pd.merge(val_result, test_gg, on='sample_id', how='left')\n",
    "\n",
    "# 判断验证集的准确率\n",
    "np.sum(val_result['predict_time'].astype(str) == val_result['time'].astype(str))/len(val_result)\n",
    "\n",
    "val_time = val_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "test_time = test_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.抽取实际购买公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽取购买公司\n",
    "# 前几句话出现\n",
    "# 将其按照\\\\n 和空格切割\n",
    "def get_gm(row):\n",
    "    result = re.split('[\\\\\\\\n ]',row)\n",
    "    for i in result:\n",
    "        if '公司' in i:\n",
    "            return i\n",
    "\n",
    "val_gm = val_df.progress_apply(lambda row:get_gm(row['text']), axis=1)\n",
    "test_gm = test_df.progress_apply(lambda row:get_gm(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.清洗提取出来的tabel数据，主要是清洗掉有问题的列 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0733c2d86e36411489165b7f0b7dadfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7217.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eeae823ca69480c874e0c58b1500b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f7f3621a3f48e0975d1a80678840f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8660.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 将table转换格式以及处理\n",
    "def deal_tabel(row):\n",
    "    row = eval(row)\n",
    "    if len(row)==0:\n",
    "        return []\n",
    "    else:\n",
    "        new_row = []\n",
    "        for i in row:\n",
    "            for d in i:\n",
    "                new_temp = []\n",
    "                for h in d:\n",
    "                    # 这里处理空数据或者错误的数据\n",
    "                    h = str(h).replace('None', '').replace('\\n','').replace(' ', '')                    \n",
    "                    if h=='':\n",
    "                        continue\n",
    "                    if h=='.':\n",
    "                        continue\n",
    "                    if h=='/':\n",
    "                        continue\n",
    "                    new_temp.append(h)\n",
    "                new_row.append(new_temp)\n",
    "        # 这里判断是否构成一个完整得认购数据(通过一个list进行判断)\n",
    "        new_new_row = []\n",
    "        for i in new_row:\n",
    "            if len(i) == 0:\n",
    "                continue\n",
    "            elif len(i) <= 4:\n",
    "                continue\n",
    "            else:\n",
    "                new_new_row.append(i)\n",
    "        return new_new_row\n",
    "train_df_tabel = train_df['tabel'].progress_apply(lambda row:deal_tabel(row))\n",
    "val_df_tabel = val_df['tabel'].progress_apply(lambda row:deal_tabel(row))\n",
    "test_df_tabel = test_df['tabel'].progress_apply(lambda row:deal_tabel(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.抽取的是单独的数据包含\n",
    "#### 起息日，到息日， 金额，认购日期，产品发行方，理财产品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b486bb5d5dc34d148f92788a2ad20b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45ae45a4b124be7a599758d787dcc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8660.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 直接提取时间\n",
    "# 如果出现两个时间第一个就是起息日，第二个就是到期日\n",
    "# 如果出现一个时间就是起息日\n",
    "# 出现的第一个money就是最后的金额\n",
    "# 从这里面抽取所有序列\n",
    "# 这里认为有逗号出现的就是money\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    " \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "from src.time_extractor import TimeFinder\n",
    "import datetime\n",
    "def get_list_data(df):\n",
    "    df = list(df)\n",
    "    new_df = []\n",
    "    for i in tqdm(df):\n",
    "        temp_df = []\n",
    "        for h in i:\n",
    "            new_h = []\n",
    "            for digital in h:\n",
    "                if ',' in digital:\n",
    "                    # 这里也是为了统一数据有些是用元，有些是用万元\n",
    "                    try:\n",
    "                        ttt = float(digital.replace(',', '').replace('万元', '').replace('人民币', '').replace('元', ''))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    if ttt > 20000:\n",
    "                        ttt = ttt/10000\n",
    "                    new_h.append(ttt)\n",
    "                else:\n",
    "                    continue\n",
    "            if len(new_h) == 0:\n",
    "                continue\n",
    "            temp_single = {}\n",
    "            a = '_'.join(h)\n",
    "            # 抽取时间和money\n",
    "            t = TimeFinder()\n",
    "            time_all = t.find_time(a)\n",
    "            if time_all == None:\n",
    "                continue\n",
    "            rgrq = time_all[0]\n",
    "            cpqxr = time_all[0]\n",
    "            if len(time_all) > 1:\n",
    "                try:\n",
    "                    cpdxr = time_all[1]\n",
    "                    # 相减\n",
    "                    d1 = datetime.datetime.strptime(cpqxr, '%Y-%m-%d')\n",
    "                    d2 = datetime.datetime.strptime(cpdxr, '%Y-%m-%d')\n",
    "                    d = d2 - d1\n",
    "                    cpqx = str(d.days) + '天'\n",
    "                except Exception:\n",
    "                    cpdxr = np.nan\n",
    "                    cpqx = np.nan\n",
    "            else:\n",
    "                cpdxr = np.nan\n",
    "                cpqx = np.nan\n",
    "                \n",
    "            # 筛选出除开数字与包含时间的列\n",
    "            # 末尾是\n",
    "            last_two = ['公司', '银行', '信托', '证券',  '分行', '支行', '中心', '业部', '商行', '建行']\n",
    "            mowei = np.nan\n",
    "            selected_bank_and_works = []\n",
    "            for l in h:\n",
    "                new_l = list(str(l))\n",
    "                new_l_test = ''.join(l[-2:])\n",
    "                if new_l_test in last_two:\n",
    "                    mowei = l\n",
    "                    continue\n",
    "                if '资金' in l:\n",
    "                    continue\n",
    "                if '收益' in l:\n",
    "                    continue\n",
    "                if '到期' in l:\n",
    "                    continue\n",
    "                if ',' in l:\n",
    "                    continue\n",
    "                if '.' in l:\n",
    "                    continue\n",
    "                if '/' in l:\n",
    "                    continue\n",
    "                if '年' in l:\n",
    "                    continue\n",
    "                if '-' in l:\n",
    "                    continue\n",
    "                if len(l) < 4:\n",
    "                    continue\n",
    "                if is_number(l):\n",
    "                    continue\n",
    "                selected_bank_and_works.append(l)\n",
    "            if len(selected_bank_and_works) < 1:\n",
    "                continue\n",
    "            \n",
    "            temp_single['认购日期'] = rgrq\n",
    "            temp_single['产品起息日'] = cpqxr\n",
    "            temp_single['产品到期日'] = cpdxr\n",
    "            temp_single['产品期限'] = cpqx\n",
    "            temp_single['认购金额(万元)'] = new_h[0]\n",
    "            temp_single['产品发行方名称'] = mowei\n",
    "            temp_single['理财产品名称'] = selected_bank_and_works[0]\n",
    "            temp_df.append(temp_single)\n",
    "        new_df.append(temp_df)\n",
    "    return new_df\n",
    "\n",
    "val_contain_date = get_list_data(val_df_tabel)\n",
    "test_contain_data = get_list_data(test_df_tabel) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.汇总整理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>认购日期</th>\n",
       "      <th>理财产品名称</th>\n",
       "      <th>产品发行方名称</th>\n",
       "      <th>认购金额(万元)</th>\n",
       "      <th>产品起息日</th>\n",
       "      <th>产品到期日</th>\n",
       "      <th>产品期限</th>\n",
       "      <th>实际购买公司名称</th>\n",
       "      <th>公告日期</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1806</td>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>主要投资于银行间市场央票、国债金融债、企业债、短融、中期票据、</td>\n",
       "      <td>银行</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>91天</td>\n",
       "      <td>海联金汇科技股份有限公司关于三级子公司</td>\n",
       "      <td>2017-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1806</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>结构性存款</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>2016-11-24</td>\n",
       "      <td>35天</td>\n",
       "      <td>海联金汇科技股份有限公司关于三级子公司</td>\n",
       "      <td>2017-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1806</td>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>银行理财</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>31天</td>\n",
       "      <td>海联金汇科技股份有限公司关于三级子公司</td>\n",
       "      <td>2017-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1806</td>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>银行理财</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>31天</td>\n",
       "      <td>海联金汇科技股份有限公司关于三级子公司</td>\n",
       "      <td>2017-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1806</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>银行理财</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>2017-02-20</td>\n",
       "      <td>62天</td>\n",
       "      <td>海联金汇科技股份有限公司关于三级子公司</td>\n",
       "      <td>2017-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13090</th>\n",
       "      <td>193</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>“安心快线步步高”法人专属开放式人民币理财产品</td>\n",
       "      <td>中国农业银行</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>银泰资源股份有限公司</td>\n",
       "      <td>2018-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13091</th>\n",
       "      <td>193</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>“安心快线步步高”法人专属开放式人民币理财产品</td>\n",
       "      <td>中国农业银行</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>银泰资源股份有限公司</td>\n",
       "      <td>2018-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>193</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>“安心快线步步高”法人专属开放式人民币理财产品</td>\n",
       "      <td>中国农业银行</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>银泰资源股份有限公司</td>\n",
       "      <td>2018-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093</th>\n",
       "      <td>193</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>“安心快线步步高”法人专属开放式人民币理财产品</td>\n",
       "      <td>中国农业银行</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>银泰资源股份有限公司</td>\n",
       "      <td>2018-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13094</th>\n",
       "      <td>193</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>“安心快线步步高”法</td>\n",
       "      <td>中国农业银行</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>银泰资源股份有限公司</td>\n",
       "      <td>2018-10-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13095 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id        认购日期                           理财产品名称 产品发行方名称  \\\n",
       "0           1806  2017-08-28  主要投资于银行间市场央票、国债金融债、企业债、短融、中期票据、      银行   \n",
       "1           1806  2016-10-20                            结构性存款     NaN   \n",
       "2           1806  2016-12-16                             银行理财     NaN   \n",
       "3           1806  2016-12-16                             银行理财     NaN   \n",
       "4           1806  2016-12-20                             银行理财     NaN   \n",
       "...          ...         ...                              ...     ...   \n",
       "13090        193  2018-10-10          “安心快线步步高”法人专属开放式人民币理财产品  中国农业银行   \n",
       "13091        193  2018-10-11          “安心快线步步高”法人专属开放式人民币理财产品  中国农业银行   \n",
       "13092        193  2018-10-12          “安心快线步步高”法人专属开放式人民币理财产品  中国农业银行   \n",
       "13093        193  2018-10-16          “安心快线步步高”法人专属开放式人民币理财产品  中国农业银行   \n",
       "13094        193  2018-10-19                       “安心快线步步高”法  中国农业银行   \n",
       "\n",
       "       认购金额(万元)       产品起息日       产品到期日 产品期限             实际购买公司名称        公告日期  \n",
       "0       10000.0  2017-08-28  2017-11-27  91天  海联金汇科技股份有限公司关于三级子公司  2017-08-28  \n",
       "1       10000.0  2016-10-20  2016-11-24  35天  海联金汇科技股份有限公司关于三级子公司  2017-08-28  \n",
       "2       20000.0  2016-12-16  2017-01-16  31天  海联金汇科技股份有限公司关于三级子公司  2017-08-28  \n",
       "3           4.3  2016-12-16  2017-01-16  31天  海联金汇科技股份有限公司关于三级子公司  2017-08-28  \n",
       "4       16000.0  2016-12-20  2017-02-20  62天  海联金汇科技股份有限公司关于三级子公司  2017-08-28  \n",
       "...         ...         ...         ...  ...                  ...         ...  \n",
       "13090    2000.0  2018-10-10         NaN  NaN           银泰资源股份有限公司  2018-10-25  \n",
       "13091    2000.0  2018-10-11         NaN  NaN           银泰资源股份有限公司  2018-10-25  \n",
       "13092    1500.0  2018-10-12         NaN  NaN           银泰资源股份有限公司  2018-10-25  \n",
       "13093    3000.0  2018-10-16         NaN  NaN           银泰资源股份有限公司  2018-10-25  \n",
       "13094    1500.0  2018-10-19         NaN  NaN           银泰资源股份有限公司  2018-10-25  \n",
       "\n",
       "[13095 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将前面提取到的数据整理成对应格式\n",
    "sample_id_list = []\n",
    "rgrq_list = []\n",
    "lccp_list = []\n",
    "cpfxf_list = []\n",
    "rgje_list = []\n",
    "cpqxr_list = []\n",
    "cpdxr_list = []\n",
    "cpqx_list = []\n",
    "sjgmgsmc_list = []\n",
    "ggrq_list = []\n",
    "\n",
    "sample_id = list(val_df['sample_id'])\n",
    "gg = list(val_gm)\n",
    "time = list(val_time)\n",
    "for i, value in enumerate(sample_id):\n",
    "    for j in val_contain_date[i]:\n",
    "        sample_id_list.append(sample_id[i])\n",
    "        rgrq_list.append(j['认购日期'])\n",
    "        lccp_list.append(j['理财产品名称'])\n",
    "        cpfxf_list.append(j['产品发行方名称'])\n",
    "        rgje_list.append(j['认购金额(万元)'])\n",
    "        cpqxr_list.append(j['产品起息日'])\n",
    "        cpdxr_list.append(j['产品到期日'])\n",
    "        cpqx_list.append(j['产品期限'])\n",
    "        sjgmgsmc_list.append(gg[i])\n",
    "        ggrq_list.append(time[i])\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['sample_id'] = sample_id_list\n",
    "result['认购日期'] = rgrq_list\n",
    "result['理财产品名称'] = lccp_list\n",
    "result['产品发行方名称'] = cpfxf_list\n",
    "result['认购金额(万元)'] = rgje_list\n",
    "result['产品起息日'] = cpqxr_list\n",
    "result['产品到期日'] = cpdxr_list\n",
    "result['产品期限'] = cpqx_list\n",
    "result['实际购买公司名称'] = sjgmgsmc_list\n",
    "result['公告日期'] = ggrq_list\n",
    "val_result = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>认购日期</th>\n",
       "      <th>理财产品名称</th>\n",
       "      <th>产品发行方名称</th>\n",
       "      <th>认购金额(万元)</th>\n",
       "      <th>产品起息日</th>\n",
       "      <th>产品到期日</th>\n",
       "      <th>产品期限</th>\n",
       "      <th>实际购买公司名称</th>\n",
       "      <th>公告日期</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11190</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>星河文化</td>\n",
       "      <td>建设银行</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>北京京西文化旅游股份有限公司</td>\n",
       "      <td>2016-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11190</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>西藏星河</td>\n",
       "      <td>包商银行</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-12-26</td>\n",
       "      <td>178天</td>\n",
       "      <td>北京京西文化旅游股份有限公司</td>\n",
       "      <td>2016-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11190</td>\n",
       "      <td>2016-07-28</td>\n",
       "      <td>持有期不定</td>\n",
       "      <td>工商银行</td>\n",
       "      <td>13700.0</td>\n",
       "      <td>2016-07-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>北京京西文化旅游股份有限公司</td>\n",
       "      <td>2016-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11190</td>\n",
       "      <td>2016-08-03</td>\n",
       "      <td>西藏星河</td>\n",
       "      <td>南京银行</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2016-08-03</td>\n",
       "      <td>2016-11-12</td>\n",
       "      <td>101天</td>\n",
       "      <td>北京京西文化旅游股份有限公司</td>\n",
       "      <td>2016-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11190</td>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>北京京艺</td>\n",
       "      <td>交通银行</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>2016-11-07</td>\n",
       "      <td>28天</td>\n",
       "      <td>北京京西文化旅游股份有限公司</td>\n",
       "      <td>2016-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24566</th>\n",
       "      <td>22332</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>平安银行卓越计划滚动型保本人民币公司理财产品</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>赛轮金宇集团股份有限公司关于</td>\n",
       "      <td>2016-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24567</th>\n",
       "      <td>22337</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>中国工商银行法人“添利宝”净值型理财产品（TLB1801)</td>\n",
       "      <td>中国工商银行</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>北京东方新星石化工程股份有限公司</td>\n",
       "      <td>2019-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24568</th>\n",
       "      <td>22338</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>结构性存款</td>\n",
       "      <td>招商银行股份有限公司长沙韶山路支行</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>60天</td>\n",
       "      <td>三诺生物传感股份有限公司</td>\n",
       "      <td>2019-01-72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24569</th>\n",
       "      <td>22340</td>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>中信理财之共赢保本步步高升B款人民币理财产品</td>\n",
       "      <td>中信银行</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>丝路视觉科技股份有限公司</td>\n",
       "      <td>2018-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24570</th>\n",
       "      <td>22360</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>花王股份</td>\n",
       "      <td>中信银行丹阳支行</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>91天</td>\n",
       "      <td>江苏花王园艺股份有限公司</td>\n",
       "      <td>2016-10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24571 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id        认购日期                         理财产品名称  \\\n",
       "0          11190  2016-06-28                           星河文化   \n",
       "1          11190  2016-07-01                           西藏星河   \n",
       "2          11190  2016-07-28                          持有期不定   \n",
       "3          11190  2016-08-03                           西藏星河   \n",
       "4          11190  2016-10-10                           北京京艺   \n",
       "...          ...         ...                            ...   \n",
       "24566      22332  2015-10-16         平安银行卓越计划滚动型保本人民币公司理财产品   \n",
       "24567      22337  2019-03-01  中国工商银行法人“添利宝”净值型理财产品（TLB1801)   \n",
       "24568      22338  2019-01-07                          结构性存款   \n",
       "24569      22340  2017-01-19         中信理财之共赢保本步步高升B款人民币理财产品   \n",
       "24570      22360  2016-10-12                           花王股份   \n",
       "\n",
       "                 产品发行方名称  认购金额(万元)       产品起息日       产品到期日  产品期限  \\\n",
       "0                   建设银行    1000.0  2016-06-28         NaN   NaN   \n",
       "1                   包商银行   11500.0  2016-07-01  2016-12-26  178天   \n",
       "2                   工商银行   13700.0  2016-07-28         NaN   NaN   \n",
       "3                   南京银行    1000.0  2016-08-03  2016-11-12  101天   \n",
       "4                   交通银行    1000.0  2016-10-10  2016-11-07   28天   \n",
       "...                  ...       ...         ...         ...   ...   \n",
       "24566                NaN    3900.0  2015-10-16         NaN   NaN   \n",
       "24567             中国工商银行   10000.0  2019-03-01         NaN   NaN   \n",
       "24568  招商银行股份有限公司长沙韶山路支行   12000.0  2019-01-07  2019-03-08   60天   \n",
       "24569               中信银行    4100.0  2017-01-19         NaN   NaN   \n",
       "24570           中信银行丹阳支行   10000.0  2016-10-12  2017-01-11   91天   \n",
       "\n",
       "               实际购买公司名称        公告日期  \n",
       "0        北京京西文化旅游股份有限公司  2016-11-23  \n",
       "1        北京京西文化旅游股份有限公司  2016-11-23  \n",
       "2        北京京西文化旅游股份有限公司  2016-11-23  \n",
       "3        北京京西文化旅游股份有限公司  2016-11-23  \n",
       "4        北京京西文化旅游股份有限公司  2016-11-23  \n",
       "...                 ...         ...  \n",
       "24566    赛轮金宇集团股份有限公司关于  2016-05-12  \n",
       "24567  北京东方新星石化工程股份有限公司  2019-03-04  \n",
       "24568      三诺生物传感股份有限公司  2019-01-72  \n",
       "24569      丝路视觉科技股份有限公司  2018-01-25  \n",
       "24570      江苏花王园艺股份有限公司  2016-10-14  \n",
       "\n",
       "[24571 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_id_list = []\n",
    "rgrq_list = []\n",
    "lccp_list = []\n",
    "cpfxf_list = []\n",
    "rgje_list = []\n",
    "cpqxr_list = []\n",
    "cpdxr_list = []\n",
    "cpqx_list = []\n",
    "sjgmgsmc_list = []\n",
    "ggrq_list = []\n",
    "\n",
    "sample_id = list(test_df['sample_id'])\n",
    "gg = list(test_gm)\n",
    "time = list(test_time)\n",
    "for i, value in enumerate(sample_id):\n",
    "    for j in test_contain_data[i]:\n",
    "        sample_id_list.append(sample_id[i])\n",
    "        rgrq_list.append(j['认购日期'])\n",
    "        lccp_list.append(j['理财产品名称'])\n",
    "        cpfxf_list.append(j['产品发行方名称'])\n",
    "        rgje_list.append(j['认购金额(万元)'])\n",
    "        cpqxr_list.append(j['产品起息日'])\n",
    "        cpdxr_list.append(j['产品到期日'])\n",
    "        cpqx_list.append(j['产品期限'])\n",
    "        sjgmgsmc_list.append(gg[i])\n",
    "        ggrq_list.append(time[i])\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['sample_id'] = sample_id_list\n",
    "result['认购日期'] = rgrq_list\n",
    "result['理财产品名称'] = lccp_list\n",
    "result['产品发行方名称'] = cpfxf_list\n",
    "result['认购金额(万元)'] = rgje_list\n",
    "result['产品起息日'] = cpqxr_list\n",
    "result['产品到期日'] = cpdxr_list\n",
    "result['产品期限'] = cpqx_list\n",
    "result['实际购买公司名称'] = sjgmgsmc_list\n",
    "result['公告日期'] = ggrq_list\n",
    "test_result = result\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模过程（预处理模型）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.采用LSTM网络用提取好的部分跟pdf中的text做交互预测\n",
    "#### 理财类型、资金来源、实际购买公司和上市公司关系、买卖方是否有关联关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后一部分字段采用预测好的部分，跟提取的text做交互采用双输入lstm在dense层做交互预测最后几个字段\n",
    "train_lstm_input = pd.merge(train_df, train_outputs, on='sample_id', how='left')\n",
    "train_lstm_input = train_lstm_input.fillna('否')\n",
    "# label_1理财类型-10  label_2资金来源-3 label_3实际购买公司和上市公司关系-3 label_4买卖方是否有关联关系-2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_1 = LabelEncoder()\n",
    "label_2 = LabelEncoder()\n",
    "label_3 = LabelEncoder()\n",
    "label_4 = LabelEncoder()\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "train_data['text_1'] = train_lstm_input['理财产品名称'].astype(str) + '_' + train_lstm_input['产品发行方名称'].astype(str)\n",
    "train_data['text_2'] = train_lstm_input['text'].astype(str)\n",
    "\n",
    "train_data['label_1'] = label_1.fit_transform(train_lstm_input['理财类型'])\n",
    "train_data['label_2'] = label_2.fit_transform(train_lstm_input['资金来源'])\n",
    "train_data['label_3'] = label_3.fit_transform(train_lstm_input['实际购买公司和上市公司关系'])\n",
    "train_data['label_4'] = label_4.fit_transform(train_lstm_input['买卖方是否有关联关系'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pcl/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pcl/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pcl/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pcl/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pcl/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pcl/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# 导入相关库\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import *\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from gensim.models import FastText, Word2Vec\n",
    "import re\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import *\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "import keras.backend as K\n",
    "from keras.optimizers import *\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import gc\n",
    "import logging\n",
    "import gensim\n",
    "import jieba\n",
    "tqdm.pandas()\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "# 显卡使用（如没显卡需要注释掉）\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "np.random.seed(1024)\n",
    "rn.seed(1024)\n",
    "tf.set_random_seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a02db7c66d4df68576ab65fa743289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27154.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.684 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504844d12eb445828b7f46c5c538fed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27154.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>中银 保本 理财 - 人民币 按期 开放 理财产品 _ 中国银行 股份 有限公司 广州 东山 支行</td>\n",
       "      <td>[ ' 证券 代码 ： 600728                 证券 简称 ： 佳 都...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>中银 保本 理财 - 人民币 按期 开放 理财产品 _ 中国银行 股份 有限公司 广州 东山 支行</td>\n",
       "      <td>[ ' 证券 代码 ： 600728                 证券 简称 ： 佳 都...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>与 利率 挂钩 的 结构性 产品 _ 中国民生银行 股份 有限公司</td>\n",
       "      <td>[ ' 证券 代码 ： 600211                            ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>广发 银行 “ 薪 加薪 ” 16 号 XJXCKJ2578 _ 广发 银行 股份 有限公司...</td>\n",
       "      <td>[ ' 证券 代码 ： 002171                            ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>兴业银行 “ 金 雪球 - 优悦 ” 保本 开放式 人民币 理财产品 ( 2M ) _ 兴业...</td>\n",
       "      <td>[ ' 证券 代码 ： 002171                            ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  中银 保本 理财 - 人民币 按期 开放 理财产品 _ 中国银行 股份 有限公司 广州 东山 支行   \n",
       "1  中银 保本 理财 - 人民币 按期 开放 理财产品 _ 中国银行 股份 有限公司 广州 东山 支行   \n",
       "2                  与 利率 挂钩 的 结构性 产品 _ 中国民生银行 股份 有限公司   \n",
       "3  广发 银行 “ 薪 加薪 ” 16 号 XJXCKJ2578 _ 广发 银行 股份 有限公司...   \n",
       "4  兴业银行 “ 金 雪球 - 优悦 ” 保本 开放式 人民币 理财产品 ( 2M ) _ 兴业...   \n",
       "\n",
       "                                              text_2  label_1  label_2  \\\n",
       "0  [ ' 证券 代码 ： 600728                 证券 简称 ： 佳 都...        9        1   \n",
       "1  [ ' 证券 代码 ： 600728                 证券 简称 ： 佳 都...        9        1   \n",
       "2  [ ' 证券 代码 ： 600211                            ...        9        0   \n",
       "3  [ ' 证券 代码 ： 002171                            ...        9        1   \n",
       "4  [ ' 证券 代码 ： 002171                            ...        9        1   \n",
       "\n",
       "   label_3  label_4  \n",
       "0        0        0  \n",
       "1        0        0  \n",
       "2        0        0  \n",
       "3        2        0  \n",
       "4        0        0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text_1'] = train_data['text_1'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "train_data['text_2'] = train_data['text_2'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenizer 序列化文本\n",
    "def set_tokenizer(docs, split_char=' ', max_len=100):\n",
    "    '''\n",
    "    输入\n",
    "    docs:文本列表\n",
    "    split_char:按什么字符切割\n",
    "    max_len:截取的最大长度\n",
    "    \n",
    "    输出\n",
    "    X:序列化后的数据\n",
    "    word_index:文本和数字对应的索引\n",
    "    '''\n",
    "    tokenizer = Tokenizer(lower=False, char_level=False, split=split_char)\n",
    "    tokenizer.fit_on_texts(docs)\n",
    "    X = tokenizer.texts_to_sequences(docs)\n",
    "    maxlen = max_len\n",
    "    X = pad_sequences(X, maxlen=maxlen, value=0)\n",
    "    word_index=tokenizer.word_index\n",
    "    return X, word_index, tokenizer\n",
    "\n",
    "### 做embedding 这里采用word2vec 可以换成其他例如（glove词向量）\n",
    "def trian_save_word2vec(docs, embed_size=300, save_name='w2v.txt', split_char=' '):\n",
    "    '''\n",
    "    输入\n",
    "    docs:输入的文本列表\n",
    "    embed_size:embed长度\n",
    "    save_name:保存的word2vec位置\n",
    "    \n",
    "    输出\n",
    "    w2v:返回的模型\n",
    "    '''\n",
    "    input_docs = []\n",
    "    for i in docs:\n",
    "        input_docs.append(i.split(split_char))\n",
    "    logging.basicConfig(\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s', level=logging.INFO)\n",
    "    w2v = Word2Vec(input_docs, size=embed_size, sg=1, window=8, seed=1017, workers=24, min_count=1, iter=10)\n",
    "    w2v.save(save_name)\n",
    "    print(\"w2v model done\")\n",
    "    return w2v\n",
    "\n",
    "# 得到embedding矩阵\n",
    "def get_embedding_matrix(word_index, embed_size=300, Emed_path=\"w2v_300.txt\"):\n",
    "    embeddings_index = Word2Vec.load(Emed_path)\n",
    "    nb_words = len(word_index)+1\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    count = 0\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= nb_words:\n",
    "            continue\n",
    "        try:\n",
    "            embedding_vector = embeddings_index[word]\n",
    "        except:\n",
    "            embedding_vector = np.zeros(embed_size)\n",
    "            count += 1\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector  \n",
    "    print(\"null cnt\",count)\n",
    "    return embedding_matrix\n",
    "\n",
    "# 得到fasttext矩阵\n",
    "def load_fasttext(word_index, path):  \n",
    "    count=0\n",
    "    null_list=[]\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(path, encoding='utf-8') if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words =  len(word_index)+1\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= nb_words: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            null_list.append(word)\n",
    "            count+=1\n",
    "    print(\"null cnt:\",count)\n",
    "    return embedding_matrix\n",
    "\n",
    "def get_embedding_matrix_txt(word_index,embed_size=200,Emed_path=\"w2v_300.txt\"):\n",
    "    embeddings_index = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        Emed_path, binary=False)\n",
    "    nb_words = len(word_index)+1\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    count = 0\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= nb_words:\n",
    "            continue\n",
    "        try:\n",
    "            embedding_vector = embeddings_index[word]\n",
    "        except:\n",
    "            embedding_vector = np.zeros(embed_size)\n",
    "            count += 1\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print(\"null cnt\",count)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.训练得到word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始序列化\n",
      "序列化完成\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98687"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-12 14:06:30,630:INFO:loading Word2Vec object from models/w2v_300_1.txt\n",
      "2020-08-12 14:06:30,756:INFO:loading wv recursively from models/w2v_300_1.txt.wv.* with mmap=None\n",
      "2020-08-12 14:06:30,757:INFO:setting ignored attribute vectors_norm to None\n",
      "2020-08-12 14:06:30,758:INFO:loading vocabulary recursively from models/w2v_300_1.txt.vocabulary.* with mmap=None\n",
      "2020-08-12 14:06:30,759:INFO:loading trainables recursively from models/w2v_300_1.txt.trainables.* with mmap=None\n",
      "2020-08-12 14:06:30,759:INFO:setting ignored attribute cum_table to None\n",
      "2020-08-12 14:06:30,760:INFO:loaded models/w2v_300_1.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8342a05b724574807494d44a3595c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcl/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "2020-08-12 14:06:30,870:INFO:loading Word2Vec object from models/w2v_300_3.txt\n",
      "2020-08-12 14:06:30,932:INFO:loading wv recursively from models/w2v_300_3.txt.wv.* with mmap=None\n",
      "2020-08-12 14:06:30,933:INFO:loading vectors from models/w2v_300_3.txt.wv.vectors.npy with mmap=None\n",
      "2020-08-12 14:06:30,949:INFO:setting ignored attribute vectors_norm to None\n",
      "2020-08-12 14:06:30,950:INFO:loading vocabulary recursively from models/w2v_300_3.txt.vocabulary.* with mmap=None\n",
      "2020-08-12 14:06:30,951:INFO:loading trainables recursively from models/w2v_300_3.txt.trainables.* with mmap=None\n",
      "2020-08-12 14:06:30,951:INFO:loading syn1neg from models/w2v_300_3.txt.trainables.syn1neg.npy with mmap=None\n",
      "2020-08-12 14:06:30,966:INFO:setting ignored attribute cum_table to None\n",
      "2020-08-12 14:06:30,967:INFO:loaded models/w2v_300_3.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "null cnt 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f9fb38ac8944f5a3442ec5958a912d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28478.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcl/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "null cnt 1202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_1_list = np.unique(train_data['text_1'])\n",
    "text_3_list = np.unique(train_data['text_2'])\n",
    "\n",
    "print('开始序列化')\n",
    "x1, index_1, token_1 = set_tokenizer(train_data['text_1'], split_char=' ', max_len=30)\n",
    "x3, index_3, token_3 = set_tokenizer(train_data['text_2'], split_char=' ', max_len=600)\n",
    "print('序列化完成')\n",
    "gc.collect()\n",
    "\n",
    "# trian_save_word2vec(text_1_list, save_name='models/w2v_300_1.txt', split_char=' ')\n",
    "# gc.collect()\n",
    "# trian_save_word2vec(text_3_list, save_name='models/w2v_300_3.txt', split_char=' ')\n",
    "# gc.collect()\n",
    "\n",
    "# 得到emb矩阵\n",
    "emb1 = get_embedding_matrix(index_1, Emed_path='models/w2v_300_1.txt')\n",
    "emb3 = get_embedding_matrix(index_3, Emed_path='models/w2v_300_3.txt')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建抽取模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.initializers import *\n",
    "\n",
    "def model_conv(emb1, emb3):\n",
    "    '''\n",
    "    注意这个inputs\n",
    "    seq1、seq2分别是两个输入\n",
    "    是否做emb可选可不选，\n",
    "    这个就是我们之前训练已经得到的用于embedding的（embedding_matrix1， embedding_matrix2）\n",
    "    '''\n",
    "    K.clear_session()\n",
    "\n",
    "    emb_layer_1 = Embedding(\n",
    "        input_dim=emb1.shape[0],\n",
    "        output_dim=emb1.shape[1],\n",
    "        weights=[emb1],\n",
    "        input_length=30,\n",
    "        trainable=False\n",
    "    )\n",
    "    \n",
    "    emb_layer_3 = Embedding(\n",
    "        input_dim=emb3.shape[0],\n",
    "        output_dim=emb3.shape[1],\n",
    "        weights=[emb3],\n",
    "        input_length=600,\n",
    "        trainable=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    seq1 = Input(shape=(30,))\n",
    "    seq3 = Input(shape=(600,))    \n",
    "    \n",
    "    x1 = emb_layer_1(seq1)\n",
    "    x3 = emb_layer_3(seq3)\n",
    "    \n",
    "    sdrop=SpatialDropout1D(rate=0.2)\n",
    "\n",
    "    x1 = sdrop(x1)\n",
    "    x3 = sdrop(x3)\n",
    "     \n",
    "    x = Dropout(0.2)(Bidirectional(GRU(128, return_sequences=True))(x1))\n",
    "    semantic = TimeDistributed(Dense(100, activation=\"tanh\"))(x)\n",
    "    merged_1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(100,))(semantic)\n",
    "    \n",
    "    x = Dropout(0.2)(Bidirectional(GRU(128, return_sequences=True))(x3))\n",
    "    semantic = TimeDistributed(Dense(100, activation=\"tanh\"))(x)\n",
    "    merged_3 = Lambda(lambda x: K.max(x, axis=1), output_shape=(100,))(semantic)\n",
    "    \n",
    "    \n",
    "    x = Multiply()([merged_1, merged_3])\n",
    "    \n",
    "    x = Dropout(0.2)(Activation(activation=\"relu\")(BatchNormalization()(Dense(1000)(x))))\n",
    "    x = Activation(activation=\"relu\")(BatchNormalization()(Dense(500)(x)))\n",
    "    pred_1 = Dense(10, activation='softmax')(x)\n",
    "    pred_2 = Dense(3, activation='softmax')(x)\n",
    "    pred_3 = Dense(3, activation='softmax')(x)\n",
    "    pred_4 = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=[seq1, seq3], outputs=[pred_1, pred_2, pred_3, pred_4])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=0.0001),metrics=[\"accuracy\"])\n",
    "    return model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 300)      2156700     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 600, 300)     8543700     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro multiple             0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 256)      329472      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 600, 256)     329472      spatial_dropout1d_1[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 256)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 600, 256)     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 30, 100)      25700       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 600, 100)     25700       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 100)          0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 100)          0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 100)          0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1000)         101000      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000)         4000        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1000)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000)         0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 500)          500500      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500)          2000        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 500)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           5010        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            1503        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 3)            1503        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            1002        activation_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 12,027,262\n",
      "Trainable params: 1,323,862\n",
      "Non-trainable params: 10,703,400\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/8\n",
      "27154/27154 [==============================] - 144s 5ms/step - loss: 2.7503 - dense_5_loss: 0.8252 - dense_6_loss: 0.8617 - dense_7_loss: 0.9214 - dense_8_loss: 0.1420 - dense_5_acc: 0.7687 - dense_6_acc: 0.5978 - dense_7_acc: 0.5950 - dense_8_acc: 0.9750\n",
      "Epoch 2/8\n",
      "27154/27154 [==============================] - 141s 5ms/step - loss: 1.4093 - dense_5_loss: 0.1651 - dense_6_loss: 0.6680 - dense_7_loss: 0.5468 - dense_8_loss: 0.0294 - dense_5_acc: 0.9634 - dense_6_acc: 0.6849 - dense_7_acc: 0.7821 - dense_8_acc: 0.9986\n",
      "Epoch 3/8\n",
      "27154/27154 [==============================] - 140s 5ms/step - loss: 1.2110 - dense_5_loss: 0.1231 - dense_6_loss: 0.6142 - dense_7_loss: 0.4562 - dense_8_loss: 0.0176 - dense_5_acc: 0.9705 - dense_6_acc: 0.7098 - dense_7_acc: 0.8060 - dense_8_acc: 0.9986\n",
      "Epoch 4/8\n",
      "27154/27154 [==============================] - 140s 5ms/step - loss: 1.0880 - dense_5_loss: 0.1009 - dense_6_loss: 0.5647 - dense_7_loss: 0.4085 - dense_8_loss: 0.0139 - dense_5_acc: 0.9741 - dense_6_acc: 0.7390 - dense_7_acc: 0.8229 - dense_8_acc: 0.9986\n",
      "Epoch 5/8\n",
      "27154/27154 [==============================] - 140s 5ms/step - loss: 0.9588 - dense_5_loss: 0.0914 - dense_6_loss: 0.4741 - dense_7_loss: 0.3813 - dense_8_loss: 0.0121 - dense_5_acc: 0.9760 - dense_6_acc: 0.7972 - dense_7_acc: 0.8351 - dense_8_acc: 0.9986\n",
      "Epoch 6/8\n",
      "27154/27154 [==============================] - 140s 5ms/step - loss: 0.8607 - dense_5_loss: 0.0796 - dense_6_loss: 0.4096 - dense_7_loss: 0.3607 - dense_8_loss: 0.0108 - dense_5_acc: 0.9786 - dense_6_acc: 0.8363 - dense_7_acc: 0.8452 - dense_8_acc: 0.9986\n",
      "Epoch 7/8\n",
      "27154/27154 [==============================] - 140s 5ms/step - loss: 0.7898 - dense_5_loss: 0.0735 - dense_6_loss: 0.3632 - dense_7_loss: 0.3429 - dense_8_loss: 0.0101 - dense_5_acc: 0.9799 - dense_6_acc: 0.8531 - dense_7_acc: 0.8537 - dense_8_acc: 0.9986\n",
      "Epoch 8/8\n",
      "27154/27154 [==============================] - 140s 5ms/step - loss: 0.7352 - dense_5_loss: 0.0657 - dense_6_loss: 0.3341 - dense_7_loss: 0.3257 - dense_8_loss: 0.0097 - dense_5_acc: 0.9825 - dense_6_acc: 0.8650 - dense_7_acc: 0.8594 - dense_8_acc: 0.9986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f239c296ef0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_conv(emb1, emb3)\n",
    "model.summary()\n",
    "l1 = to_categorical(train_data['label_1'], 10)\n",
    "l2 = to_categorical(train_data['label_2'], 3)\n",
    "l3 = to_categorical(train_data['label_3'], 3)\n",
    "l4 = to_categorical(train_data['label_4'], 2)\n",
    "model.fit([x1, x3],[l1, l2, l3, l4], batch_size=256, epochs=8, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存权重\n",
    "model.save_weights('models/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360c6b9a24c54a3493042a50fc8691f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13095.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c761870d9849f4ae639731dbde7f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13095.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13095/13095 [==============================] - 9s 699us/step\n"
     ]
    }
   ],
   "source": [
    "# 预测验证集\n",
    "val_result_for_pred = pd.merge(val_result, val_df, on='sample_id', how='left')\n",
    "val_result_for_pred['text_1'] = val_result_for_pred['理财产品名称'].astype(str) + '_' + val_result_for_pred['产品发行方名称'].astype(str)\n",
    "val_result_for_pred['text_2'] = val_result_for_pred['text'].astype(str)\n",
    "\n",
    "val_result_for_pred['text_1'] = val_result_for_pred['text_1'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "val_result_for_pred['text_2'] = val_result_for_pred['text_2'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "\n",
    "x1 = token_1.texts_to_sequences(val_result_for_pred['text_1'])\n",
    "x1 = pad_sequences(x1, maxlen=30, value=0)\n",
    "x3 = token_3.texts_to_sequences(val_result_for_pred['text_2'])\n",
    "x3 = pad_sequences(x3, maxlen=600, value=0)\n",
    "pred_result = model.predict([x1, x3], batch_size=1024, verbose=1)\n",
    "pred_1 = label_1.inverse_transform(np.argmax(pred_result[0], axis=1))\n",
    "pred_2 = label_2.inverse_transform(np.argmax(pred_result[1], axis=1))\n",
    "pred_3 = label_3.inverse_transform(np.argmax(pred_result[2], axis=1))\n",
    "pred_4 = label_4.inverse_transform(np.argmax(pred_result[3], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_result['理财类型'] = pred_1\n",
    "val_result['资金来源'] = pred_2\n",
    "val_result['实际购买公司和上市公司关系'] = pred_3\n",
    "val_result['买卖方是否有关联关系'] = pred_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.离线验证评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016099797419767567"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算线下f1\n",
    "# R（召回率）=抽取正确的记录数量/（抽取正确的目标数量+漏抽取的记录数量）\n",
    "# P（准确率）=抽取正确的记录数量/（抽取错误的记录数量+抽取正确的记录数量）\n",
    "def get_F1(val_pred, val_true):\n",
    "    val_pred = list(val_pred)\n",
    "    val_true = list(val_true)\n",
    "    curr = list(set(val_pred).intersection(set(val_true)))\n",
    "    R = len(curr)/len(val_true)\n",
    "    P = len(curr)/len(val_pred)\n",
    "    return 2*P*R/(P+R)\n",
    "\n",
    "r = pd.merge(val_df[['sample_id']], train_outputs, on='sample_id', how='left')\n",
    "val_true = r['sample_id'].astype(str) + r['认购日期'].astype(str) + r['理财产品名称'].astype(str) + r['理财类型'].astype(str) + r['认购金额(万元)'].astype(str) + r['产品起息日'].astype(str)+ r['产品到息日'].astype(str) + r['产品期限'].astype(str) + r['资金来源'].astype(str) + r['实际购买公司名称'].astype(str) + r['实际购买公司和上市公司关系'].astype(str) + r['买卖方是否有关联关系'].astype(str) + r['公告日期'].astype(str)\n",
    "\n",
    "r = val_result\n",
    "val_pred = r['sample_id'].astype(str) + r['认购日期'].astype(str) + r['理财产品名称'].astype(str) + r['理财类型'].astype(str) + r['认购金额(万元)'].astype(str) + r['产品起息日'].astype(str)+ r['产品到期日'].astype(str) + r['产品期限'].astype(str) + r['资金来源'].astype(str) + r['实际购买公司名称'].astype(str) + r['实际购买公司和上市公司关系'].astype(str) + r['买卖方是否有关联关系'].astype(str) + r['公告日期'].astype(str)\n",
    "\n",
    "score = get_F1(val_pred, val_true)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.最终输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24571/24571 [==============================] - 17s 695us/step\n"
     ]
    }
   ],
   "source": [
    "# 预测测试集\n",
    "test_result_for_pred = pd.merge(test_result, test_df, on='sample_id', how='left')\n",
    "test_result_for_pred['text_1'] = test_result_for_pred['理财产品名称'].astype(str) + '_' + test_result_for_pred['产品发行方名称'].astype(str)\n",
    "test_result_for_pred['text_2'] = test_result_for_pred['text'].astype(str)\n",
    "\n",
    "test_result_for_pred['text_1'] = test_result_for_pred['text_1'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "test_result_for_pred['text_2'] = test_result_for_pred['text_2'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "\n",
    "x1 = token_1.texts_to_sequences(test_result_for_pred['text_1'])\n",
    "x1 = pad_sequences(x1, maxlen=30, value=0)\n",
    "x3 = token_3.texts_to_sequences(test_result_for_pred['text_2'])\n",
    "x3 = pad_sequences(x3, maxlen=600, value=0)\n",
    "pred_result = model.predict([x1, x3], batch_size=1024, verbose=1)\n",
    "pred_1 = label_1.inverse_transform(np.argmax(pred_result[0], axis=1))\n",
    "pred_2 = label_2.inverse_transform(np.argmax(pred_result[1], axis=1))\n",
    "pred_3 = label_3.inverse_transform(np.argmax(pred_result[2], axis=1))\n",
    "pred_4 = label_4.inverse_transform(np.argmax(pred_result[3], axis=1))\n",
    "\n",
    "test_result['理财类型'] = pred_1\n",
    "test_result['资金来源'] = pred_2\n",
    "test_result['实际购买公司和上市公司关系'] = pred_3\n",
    "test_result['买卖方是否有关联关系'] = pred_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.to_csv('results/re_lstm_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}