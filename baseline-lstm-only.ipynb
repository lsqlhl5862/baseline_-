{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关包\n",
    "import os\n",
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from io import StringIO\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from tqdm.autonotebook import *\n",
    "import pdfplumber\n",
    "import collections\n",
    "tqdm.pandas()\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from tgrocery import Grocery\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from src.time_extractor import TimeFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF解析原始数据 \n",
    "## 加载数据并采用pdfplumber抽取PDF中的文字和表格\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id       认购日期        理财产品名称     产品发行方名称    理财类型  认购金额(万元)  \\\n0          1 2019-03-27         汇聚金1号  中融国际信托有限公司      信托   10000.0   \n1          1 2019-03-27  招商银行步步生金8699        招商银行  银行理财产品     200.0   \n\n       产品起息日      产品到息日  产品期限  资金来源    实际购买公司名称 实际购买公司和上市公司关系 买卖方是否有关联关系  \\\n0 2019-03-27 2019-09-23  180天  自有资金  恒生电子股份有限公司          公司本身          否   \n1 2019-03-27        NaT   NaN  自有资金  恒生电子股份有限公司          公司本身          否   \n\n        公告日期  \n0 2019-04-25  \n1 2019-04-25  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>认购日期</th>\n      <th>理财产品名称</th>\n      <th>产品发行方名称</th>\n      <th>理财类型</th>\n      <th>认购金额(万元)</th>\n      <th>产品起息日</th>\n      <th>产品到息日</th>\n      <th>产品期限</th>\n      <th>资金来源</th>\n      <th>实际购买公司名称</th>\n      <th>实际购买公司和上市公司关系</th>\n      <th>买卖方是否有关联关系</th>\n      <th>公告日期</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2019-03-27</td>\n      <td>汇聚金1号</td>\n      <td>中融国际信托有限公司</td>\n      <td>信托</td>\n      <td>10000.0</td>\n      <td>2019-03-27</td>\n      <td>2019-09-23</td>\n      <td>180天</td>\n      <td>自有资金</td>\n      <td>恒生电子股份有限公司</td>\n      <td>公司本身</td>\n      <td>否</td>\n      <td>2019-04-25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2019-03-27</td>\n      <td>招商银行步步生金8699</td>\n      <td>招商银行</td>\n      <td>银行理财产品</td>\n      <td>200.0</td>\n      <td>2019-03-27</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>自有资金</td>\n      <td>恒生电子股份有限公司</td>\n      <td>公司本身</td>\n      <td>否</td>\n      <td>2019-04-25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id                  file_path  \\\n0          1  datasets/train_data/1.PDF   \n1          2  datasets/train_data/2.PDF   \n\n                                                text  \\\n0  ['                                            ...   \n1  ['                                            ...   \n\n                                               tabel  \n0  [[['', None, None, '', None, None, '', None, N...  \n1  [[['', None, None, '', None, None, '', None, N...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>file_path</th>\n      <th>text</th>\n      <th>tabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>datasets/train_data/1.PDF</td>\n      <td>['                                            ...</td>\n      <td>[[['', None, None, '', None, None, '', None, N...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>datasets/train_data/2.PDF</td>\n      <td>['                                            ...</td>\n      <td>[[['', None, None, '', None, None, '', None, N...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id                     file_path  \\\n0      11188  datasets/test_data/11188.PDF   \n1      11189  datasets/test_data/11189.PDF   \n\n                                                text tabel  \n0  ['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...    []  \n1  ['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...    []  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>file_path</th>\n      <th>text</th>\n      <th>tabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11188</td>\n      <td>datasets/test_data/11188.PDF</td>\n      <td>['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11189</td>\n      <td>datasets/test_data/11189.PDF</td>\n      <td>['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# 数据准备(train_output文件中格式有点问题，需要提前用excel或者wps打开然后另存为excel文件)\n",
    "train_outputs = pd.read_excel('datasets/train_output.xlsx')\n",
    "\n",
    "# 获取pdf中文字和表格\n",
    "def extract_pdf_content(pdf_path):\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for index_page in np.arange(0, len(pdf.pages), 1):\n",
    "            # 读取多页\n",
    "            page = pdf.pages[index_page]   # 第n页的信息\n",
    "            text = page.extract_text()\n",
    "            text_list.append(text)\n",
    "            table = page.extract_tables()\n",
    "            for t in table:\n",
    "                table_list.append(t)\n",
    "    return text_list, table_list\n",
    "\n",
    "def get_dir_file(path):\n",
    "    '''\n",
    "    输入文件夹位置，输出整理好的dataframe\n",
    "    '''\n",
    "    path_list = os.listdir(path)\n",
    "    id_list = []\n",
    "    file_path_list = []\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    for i in tqdm(path_list):\n",
    "        if '.PDF' in i:\n",
    "            file_path = path + i\n",
    "            id_list.append(int(i.split('.')[0]))\n",
    "            file_path_list.append(file_path)\n",
    "            try:\n",
    "                text_temp, table_temp = extract_pdf_content(file_path)\n",
    "            except Exception:\n",
    "                print('此pdf无法读取')\n",
    "                text_temp, table_temp = [], []\n",
    "            text_list.append(text_temp)\n",
    "            table_list.append(table_temp)\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df['sample_id'] = id_list\n",
    "    df['file_path'] = file_path_list\n",
    "    df['text'] = text_list\n",
    "    df['tabel'] = table_list\n",
    "    df = df.sort_values('sample_id')\n",
    "    return df\n",
    "\n",
    "# 文件处理太慢，可持续化保存文件\n",
    "train_path = 'datasets/train.csv'\n",
    "if os.path.exists(train_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "else:\n",
    "    train_df = get_dir_file('datasets/train_data/')\n",
    "    train_df.to_csv(train_path,index=False)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "\n",
    "test_path =  'datasets/test.csv'\n",
    "if os.path.exists(test_path):\n",
    "    test_df = pd.read_csv(test_path)\n",
    "else:\n",
    "    test_df = get_dir_file('datasets/test_data/')\n",
    "    test_df.to_csv(test_path,index=False)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "train_outputs.head(2)\n",
    "train_df.head(2)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造训练集验证集\n",
    "train_df = train_df.sample(frac=1, random_state=1017)\n",
    "\n",
    "val_df = train_df[:1800]\n",
    "# val_df = train_df[:1800].head(20)\n",
    "train_df = train_df[1800:]\n",
    "# test_df=test_df.head(20)\n",
    "\n",
    "train_outputs[\"sample_id\"]=train_outputs[\"sample_id\"].astype(str)\n",
    "val_df[\"sample_id\"]=val_df[\"sample_id\"].astype(str)\n",
    "train_df[\"sample_id\"]=train_df[\"sample_id\"].astype(str)\n",
    "test_df[\"sample_id\"]=test_df[\"sample_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:18<00:00, 99.14it/s]\n100%|██████████| 7217/7217 [01:29<00:00, 80.42it/s]\n100%|██████████| 8660/8660 [01:50<00:00, 78.18it/s]\n"
    }
   ],
   "source": [
    "#text=text.replace(r'[ ]+',' ').replace('\\r','^')\n",
    "def get_title(text):\n",
    "    global title_num_char\n",
    "    title_list=[]\n",
    "    title_type_list=[]\n",
    "    text_start_iter_list=[]\n",
    "    text_end_iter_list=[]\n",
    " \n",
    "    for item in title_num_char:\n",
    "        pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5 ()\\[\\]（）【】：:]*?[\\^]\")\n",
    "        #pattern = re.compile(item+r\"[ ]*?[^ ]+?[ ]\")\n",
    "        #pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5 ()[]（）【】][]\")#*?[\\^]\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(1)\n",
    "            text_end_iter_list.append(i.span(0)[1])\n",
    "\n",
    "    # for item in title_list:\n",
    "    for item in s_title_num_char:\n",
    "        # pattern = re.compile(item+r\"[ ]*?[ ]*?[\\d][^ ]+?:?[ ]?\") \n",
    "        # pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5\\^ ]*\")\n",
    "        # pattern = re.compile(item+'[0-9\\u4e00-\\u9fa5()[]（）【】*?[\\^]]')*?[\\^]\n",
    "    #    pattern = re.compile(item+r\"[\\d]*?\\u4e00-\\u9fa5+[ ]\")\n",
    "        pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5 ()\\[\\]（）【】：:]*?[ ][\\^]\")\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(1)\n",
    "            text_end_iter_list.append(i.span(0)[1])\n",
    "\n",
    "    title_list.append(\"引言\")\n",
    "    title_type_list.append(1)\n",
    "    text_start_iter_list.append(0)\n",
    "    text_end_iter_list.append(0)\n",
    "\n",
    "    result_df=pd.DataFrame([title_list,title_type_list,text_start_iter_list,text_end_iter_list]).T.sort_values(by=2).reset_index(drop=True)\n",
    "    # print(result_df)\n",
    "    return result_df\n",
    "\n",
    "def get_title_text(text,title_df):\n",
    "    # print(title_df)\n",
    "    title_1_df=title_df[title_df[1]==1]\n",
    "    text_iter_list=[]\n",
    "    text_list=[]\n",
    "    # print(title_1_df)\n",
    "    for iter1,iter2 in title_1_df[[2,3]].values:\n",
    "        # print(iter1)\n",
    "        if(len(text_iter_list)!=0):\n",
    "            text_iter_list.append(iter1)\n",
    "        text_iter_list.append(iter2)\n",
    "    # text_iter_list.append(text_iter_list[len(text_iter_list)-1])\n",
    "    text_iter_list.append(len(text))\n",
    "    for index in range(int(len(text_iter_list)/2)):\n",
    "        text_list.append(text[text_iter_list[2*index]:text_iter_list[2*index+1]])\n",
    "    \n",
    "    title_1_df[4]=text_list\n",
    "\n",
    "    return title_1_df.reset_index(drop=True)\n",
    "\n",
    "#from fuzzywuzzy import fuzz\n",
    "def judge_title(sample_id=0,text=r\"test\\n\"):\n",
    "    # print(text)\n",
    "    text=text.replace(r\"\\n\",\"^\").replace(r'[ ]+',' ')\n",
    "    title_df=get_title(text)\n",
    "    title_df[\"sample_id\"]=[sample_id for x in range(title_df.shape[0])]\n",
    "    # print(title_df)`\n",
    "    title_1_df=get_title_text(text,title_df)[[\"sample_id\",0,1,2,3,4]]\n",
    "\n",
    "    \n",
    "\n",
    "    global val_df\n",
    "    global train_outputs\n",
    "    val_true_name=train_outputs[train_outputs[\"sample_id\"]==sample_id][\"理财产品名称\"]\n",
    "    \n",
    "    index=0\n",
    "    neg_index=[]\n",
    "    for title_des in title_1_df[0].values:\n",
    "        for item in title_neg_words:\n",
    "            if re.search(item,title_des) is not None:\n",
    "                neg_index.append(index)\n",
    "                break\n",
    "        index+=1\n",
    "\n",
    "\n",
    "    return title_1_df.drop(neg_index)\n",
    "    # print(title_list)\n",
    "\n",
    "def get_judge_title_result(val_df):\n",
    "\n",
    "    judge_title_result=None\n",
    "\n",
    "\n",
    "    for sample_id,text in tqdm(val_df[[\"sample_id\",\"text\"]].values):\n",
    "        # print(sample_id)\n",
    "        # print(text)\n",
    "        judge_title_result= judge_title(sample_id,text) if judge_title_result is None else pd.concat([judge_title_result,judge_title(sample_id,text)])\n",
    "\n",
    "        judge_title_result[\"sample_id\"]=judge_title_result[\"sample_id\"].astype(str)        \n",
    "    return judge_title_result\n",
    "\n",
    "title_num_char=[\"一、\",\"二、\",\"三、\",\"四、\",\"五、\",\"六、\",\"七、\",\"八、\",\"九、\",\"十、\",\"十一、\",\"十二、\",\"十三、\",\"十四、\",\"十五、\"]\n",
    "s_title_num_char=[\"（一）\",\"（二）\",\"（三）\",\"（四）\",\"（五）\",\"（六）\",\"（七）\",\"（八）\",\"（九）\",\"（十）\",\"（十一）\",\"（十二）\",\"（十三）\",\"（十四）\",\"（十五）\"]\n",
    "s_title_num_char.extend([\"[(]一[)]\",\"[(]二[)]\",\"[(]三[)]\",\"[(]四[)]\",\"[(]五[)]\",\"[(]六[)]\",\"[(]七[)]\",\"[(]八[)]\",\"[(]九[)]\",\"[(]十[)]\",\"[(]十一[)]\",\"[(]十二[)]\",\"[(]十三[)]\",\"[(]十四[)]\",\"[(]十五[)]\"])\n",
    "\n",
    "title_pos_words=[]\n",
    "title_neg_words=[]\n",
    "title_neg_words=[\"备查\",\"日前\",\"过去\",\"履行\",\"审批\",\"程序\",\"风险\",\"措施\",\"影响\",\"累计\",\"赎回\",\"到期[^日].*[^2][^0]\",\"到期.{0,2}[/^]\",\"截至\",\"意见\",\"十二个月内\",\"公告前\",\"报备文件\",\"前期\"]\n",
    "\n",
    "val_judge_title_result=get_judge_title_result(val_df)\n",
    "train_judge_title_result=get_judge_title_result(train_df)\n",
    "test_judge_title_result=get_judge_title_result(test_df)\n",
    "# judge_title_result.to_excel(\"训练集段落标题分类结果.xlsx\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:01<00:00, 950.34it/s]\n100%|██████████| 7217/7217 [00:14<00:00, 484.70it/s]\n100%|██████████| 8660/8660 [00:20<00:00, 432.13it/s]\n"
    }
   ],
   "source": [
    "###9月11日\n",
    "#val_judge_title_result.head(100)\n",
    "def get_content_df(val_judge_title_result):\n",
    "    sample_id=val_judge_title_result['sample_id'].drop_duplicates() \n",
    "    text_list=[]\n",
    "    text_sampleid_list=[]\n",
    "    content_df=pd.DataFrame()\n",
    "    for i in tqdm(sample_id):\n",
    "        text_df=val_judge_title_result[val_judge_title_result['sample_id']==i]\n",
    "    #  text_df.iloc[0,5]\n",
    "        #text_df\n",
    "        n=len(text_df)\n",
    "        text_sampleid_list.append(i)\n",
    "        text=''\n",
    "        for y in range(0,n):\n",
    "            text=text+text_df.iloc[y,1]+text_df.iloc[y,5]\n",
    "            text=re.sub(\"[ ]+\",\" \",text).replace(\"（\",\"(\").replace(\"）\",\")\")\n",
    "        #text\n",
    "        text_list.append(text)\n",
    "    content_df[\"sample_id\"]=text_sampleid_list\n",
    "    content_df[\"text\"]=text_list\n",
    "    return content_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "val_content_df=get_content_df(val_judge_title_result)\n",
    "train_content_df=get_content_df(train_judge_title_result)\n",
    "test_content_df=get_content_df(test_judge_title_result)\n",
    "\n",
    "val_content_df=pd.merge(val_content_df,val_df[[\"sample_id\",\"tabel\"]],on=\"sample_id\")\n",
    "train_content_df=pd.merge(train_content_df,train_df[[\"sample_id\",\"tabel\"]],on=\"sample_id\")\n",
    "test_content_df=pd.merge(test_content_df,test_df[[\"sample_id\",\"tabel\"]],on=\"sample_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.采用LSTM网络用提取好的部分跟pdf中的text做交互预测\n",
    "#### 理财类型、资金来源、实际购买公司和上市公司关系、买卖方是否有关联关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df=val_content_df\n",
    "train_df=train_content_df\n",
    "test_df=test_content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后一部分字段采用预测好的部分，跟提取的text做交互采用双输入lstm在dense层做交互预测最后几个字段\n",
    "train_lstm_input = pd.merge(train_df, train_outputs, on='sample_id', how='left')\n",
    "train_lstm_input = train_lstm_input.fillna('否')\n",
    "# label_1理财类型-10  label_2资金来源-3 label_3实际购买公司和上市公司关系-3 label_4买卖方是否有关联关系-2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_1 = LabelEncoder()\n",
    "label_2 = LabelEncoder()\n",
    "label_3 = LabelEncoder()\n",
    "label_4 = LabelEncoder()\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "train_data['text_1'] = train_lstm_input['理财产品名称'].astype(str) + '_' + train_lstm_input['产品发行方名称'].astype(str)+\"_\"+train_lstm_input['实际购买公司名称'].astype(str)\n",
    "\n",
    "train_data['text_2'] = train_lstm_input['text'].astype(str)\n",
    "# train_data['text_2'] = train_lstm_input['实际购买公司'].astype(str)\n",
    "\n",
    "train_data['label_1'] = label_1.fit_transform(train_lstm_input['理财类型'])\n",
    "train_data['label_2'] = label_2.fit_transform(train_lstm_input['资金来源'])\n",
    "train_data['label_3'] = label_3.fit_transform(train_lstm_input['实际购买公司和上市公司关系'])\n",
    "train_data['label_4'] = label_4.fit_transform(train_lstm_input['买卖方是否有关联关系'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关库\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import *\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from gensim.models import FastText, Word2Vec\n",
    "import re\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import *\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "import keras.backend as K\n",
    "from keras.optimizers import *\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import gc\n",
    "import logging\n",
    "import gensim\n",
    "import jieba\n",
    "tqdm.pandas()\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "# 显卡使用（如没显卡需要注释掉）\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "np.random.seed(1024)\n",
    "rn.seed(1024)\n",
    "tf.random.set_seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 27154/27154 [00:06<00:00, 4502.53it/s]\n100%|██████████| 27154/27154 [06:03<00:00, 74.65it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                              text_1  \\\n0  中银 保本 理财 - 人民币 按期 开放 理财产品 _ 中国银行 股份 有限公司 广州 东山...   \n1  中银 保本 理财 - 人民币 按期 开放 理财产品 _ 中国银行 股份 有限公司 广州 东山...   \n2  与 利率 挂钩 的 结构性 产品 _ 中国民生银行 股份 有限公司 _ 西藏 诺迪康 药业 ...   \n3  广发 银行 “ 薪 加薪 ” 16 号 XJXCKJ2578 _ 广发 银行 股份 有限公司...   \n4  兴业银行 “ 金 雪球 - 优悦 ” 保本 开放式 人民币 理财产品 ( 2M ) _ 兴业...   \n\n                                              text_2  label_1  label_2  \\\n0  引言 [ ' 证券 代码 ： 600728   证券 简称 ： 佳 都 科技   公告 编号...        9        1   \n1  引言 [ ' 证券 代码 ： 600728   证券 简称 ： 佳 都 科技   公告 编号...        9        1   \n2  引言 [ ' 证券 代码 ： 600211   证券 简称 ： 西藏药业   公告 编号 ：...        9        0   \n3  引言 [ ' 证券 代码 ： 002171   证券 简称 ： 楚江 新材   公告 编号 ...        9        1   \n4  引言 [ ' 证券 代码 ： 002171   证券 简称 ： 楚江 新材   公告 编号 ...        9        1   \n\n   label_3  label_4  \n0        0        0  \n1        0        0  \n2        0        0  \n3        2        0  \n4        0        0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_1</th>\n      <th>text_2</th>\n      <th>label_1</th>\n      <th>label_2</th>\n      <th>label_3</th>\n      <th>label_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>中银 保本 理财 - 人民币 按期 开放 理财产品 _ 中国银行 股份 有限公司 广州 东山...</td>\n      <td>引言 [ ' 证券 代码 ： 600728   证券 简称 ： 佳 都 科技   公告 编号...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>中银 保本 理财 - 人民币 按期 开放 理财产品 _ 中国银行 股份 有限公司 广州 东山...</td>\n      <td>引言 [ ' 证券 代码 ： 600728   证券 简称 ： 佳 都 科技   公告 编号...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>与 利率 挂钩 的 结构性 产品 _ 中国民生银行 股份 有限公司 _ 西藏 诺迪康 药业 ...</td>\n      <td>引言 [ ' 证券 代码 ： 600211   证券 简称 ： 西藏药业   公告 编号 ：...</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>广发 银行 “ 薪 加薪 ” 16 号 XJXCKJ2578 _ 广发 银行 股份 有限公司...</td>\n      <td>引言 [ ' 证券 代码 ： 002171   证券 简称 ： 楚江 新材   公告 编号 ...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>兴业银行 “ 金 雪球 - 优悦 ” 保本 开放式 人民币 理财产品 ( 2M ) _ 兴业...</td>\n      <td>引言 [ ' 证券 代码 ： 002171   证券 简称 ： 楚江 新材   公告 编号 ...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "train_data['text_1'] = train_data['text_1'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "train_data['text_2'] = train_data['text_2'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "# train_data['text_2'] = train_data['text_2'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenizer 序列化文本\n",
    "def set_tokenizer(docs, split_char=' ', max_len=100):\n",
    "    '''\n",
    "    输入\n",
    "    docs:文本列表\n",
    "    split_char:按什么字符切割\n",
    "    max_len:截取的最大长度\n",
    "    \n",
    "    输出\n",
    "    X:序列化后的数据\n",
    "    word_index:文本和数字对应的索引\n",
    "    '''\n",
    "    tokenizer = Tokenizer(lower=False, char_level=False, split=split_char)\n",
    "    tokenizer.fit_on_texts(docs)\n",
    "    X = tokenizer.texts_to_sequences(docs)\n",
    "    maxlen = max_len\n",
    "    X = pad_sequences(X, maxlen=maxlen, value=0)\n",
    "    word_index=tokenizer.word_index\n",
    "    return X, word_index, tokenizer\n",
    "\n",
    "### 做embedding 这里采用word2vec 可以换成其他例如（glove词向量）\n",
    "def trian_save_word2vec(docs, embed_size=300, save_name='w2v.txt', split_char=' '):\n",
    "    '''\n",
    "    输入\n",
    "    docs:输入的文本列表\n",
    "    embed_size:embed长度\n",
    "    save_name:保存的word2vec位置\n",
    "    \n",
    "    输出\n",
    "    w2v:返回的模型\n",
    "    '''\n",
    "    input_docs = []\n",
    "    for i in docs:\n",
    "        input_docs.append(i.split(split_char))\n",
    "    logging.basicConfig(\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s', level=logging.INFO)\n",
    "    w2v = Word2Vec(input_docs, size=embed_size, sg=1, window=8, seed=1017, workers=24, min_count=1, iter=10)\n",
    "    w2v.save(save_name)\n",
    "    print(\"w2v model done\")\n",
    "    return w2v\n",
    "\n",
    "# 得到embedding矩阵\n",
    "def get_embedding_matrix(word_index, embed_size=300, Emed_path=\"w2v_300.txt\"):\n",
    "    embeddings_index = Word2Vec.load(Emed_path)\n",
    "    nb_words = len(word_index)+1\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    count = 0\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= nb_words:\n",
    "            continue\n",
    "        try:\n",
    "            embedding_vector = embeddings_index[word]\n",
    "        except:\n",
    "            embedding_vector = np.zeros(embed_size)\n",
    "            count += 1\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector  \n",
    "    print(\"null cnt\",count)\n",
    "    return embedding_matrix\n",
    "\n",
    "# 得到fasttext矩阵\n",
    "def load_fasttext(word_index, path):  \n",
    "    count=0\n",
    "    null_list=[]\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(path, encoding='utf-8') if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words =  len(word_index)+1\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= nb_words: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            null_list.append(word)\n",
    "            count+=1\n",
    "    print(\"null cnt:\",count)\n",
    "    return embedding_matrix\n",
    "\n",
    "def get_embedding_matrix_txt(word_index,embed_size=200,Emed_path=\"w2v_300.txt\"):\n",
    "    embeddings_index = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        Emed_path, binary=False)\n",
    "    nb_words = len(word_index)+1\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    count = 0\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= nb_words:\n",
    "            continue\n",
    "        try:\n",
    "            embedding_vector = embeddings_index[word]\n",
    "        except:\n",
    "            embedding_vector = np.zeros(embed_size)\n",
    "            count += 1\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print(\"null cnt\",count)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.训练得到word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "开始序列化\n序列化完成\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 31
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "8 more threads\n2020-09-12 12:47:43,883:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:47:43,886:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:47:43,899:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:47:43,907:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:47:43,915:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:47:43,920:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:47:43,922:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:47:43,928:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:47:43,934:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:47:43,937:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:47:43,949:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:47:43,951:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:47:43,952:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:47:43,954:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:47:43,963:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:47:44,001:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:47:44,010:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:47:44,047:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:47:44,048:INFO:EPOCH - 2 : training on 274775 raw words (173856 effective words) took 0.6s, 292327 effective words/s\n2020-09-12 12:47:44,455:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:47:44,470:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:47:44,473:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:47:44,478:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:47:44,483:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:47:44,485:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:47:44,493:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:47:44,499:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:47:44,506:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:47:44,509:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:47:44,511:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:47:44,513:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:47:44,514:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:47:44,523:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:47:44,526:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:47:44,528:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:47:44,531:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:47:44,540:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:47:44,544:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:47:44,550:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:47:44,562:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:47:44,586:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:47:44,615:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:47:44,647:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:47:44,648:INFO:EPOCH - 3 : training on 274775 raw words (173810 effective words) took 0.6s, 300485 effective words/s\n2020-09-12 12:47:45,083:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:47:45,089:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:47:45,090:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:47:45,091:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:47:45,096:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:47:45,098:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:47:45,100:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:47:45,103:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:47:45,105:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:47:45,111:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:47:45,118:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:47:45,121:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:47:45,123:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:47:45,129:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:47:45,144:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:47:45,146:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:47:45,151:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:47:45,154:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:47:45,155:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:47:45,160:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:47:45,164:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:47:45,169:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:47:45,199:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:47:45,214:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:47:45,216:INFO:EPOCH - 4 : training on 274775 raw words (173674 effective words) took 0.5s, 318702 effective words/s\n2020-09-12 12:47:45,686:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:47:45,690:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:47:45,695:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:47:45,698:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:47:45,708:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:47:45,710:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:47:45,711:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:47:45,714:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:47:45,716:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:47:45,719:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:47:45,721:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:47:45,723:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:47:45,726:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:47:45,735:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:47:45,739:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:47:45,744:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:47:45,746:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:47:45,752:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:47:45,755:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:47:45,761:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:47:45,773:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:47:45,776:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:47:45,813:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:47:45,850:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:47:45,852:INFO:EPOCH - 5 : training on 274775 raw words (173823 effective words) took 0.6s, 283203 effective words/s\n2020-09-12 12:47:46,279:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:47:46,294:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:47:46,296:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:47:46,303:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:47:46,308:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:47:46,315:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:47:46,324:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:47:46,326:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:47:46,331:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:47:46,334:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:47:46,336:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:47:46,339:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:47:46,353:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:47:46,361:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:47:46,364:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:47:46,366:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:47:46,368:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:47:46,370:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:47:46,377:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:47:46,382:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:47:46,385:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:47:46,388:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:47:46,433:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:47:46,434:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:47:46,435:INFO:EPOCH - 6 : training on 274775 raw words (174026 effective words) took 0.6s, 310113 effective words/s\n2020-09-12 12:47:46,849:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:47:46,853:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:47:46,858:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:47:46,861:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:47:46,868:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:47:46,870:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:47:46,874:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:47:46,892:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:47:46,909:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:47:46,917:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:47:46,927:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:47:46,934:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:47:46,936:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:47:46,941:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:47:46,947:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:47:46,950:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:47:46,957:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:47:46,959:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:47:46,961:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:47:46,963:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:47:46,965:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:47:46,967:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:47:46,980:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:47:46,982:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:47:46,983:INFO:EPOCH - 7 : training on 274775 raw words (173835 effective words) took 0.5s, 329393 effective words/s\n2020-09-12 12:47:47,436:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:47:47,442:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:47:47,450:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:47:47,454:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:47:47,458:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:47:47,468:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:47:47,471:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:47:47,474:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:47:47,496:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:47:47,501:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:47:47,505:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:47:47,517:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:47:47,520:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:47:47,522:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:47:47,524:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:47:47,527:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:47:47,529:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:47:47,532:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:47:47,535:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:47:47,545:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:47:47,548:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:47:47,552:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:47:47,558:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:47:47,586:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:47:47,588:INFO:EPOCH - 8 : training on 274775 raw words (173750 effective words) took 0.6s, 298727 effective words/s\n2020-09-12 12:47:48,002:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:47:48,007:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:47:48,015:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:47:48,018:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:47:48,026:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:47:48,029:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:47:48,031:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:47:48,038:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:47:48,041:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:47:48,045:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:47:48,057:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:47:48,064:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:47:48,073:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:47:48,075:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:47:48,085:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:47:48,088:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:47:48,089:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:47:48,092:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:47:48,098:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:47:48,100:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:47:48,103:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:47:48,110:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:47:48,130:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:47:48,145:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:47:48,146:INFO:EPOCH - 9 : training on 274775 raw words (173656 effective words) took 0.5s, 322836 effective words/s\n2020-09-12 12:47:48,554:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:47:48,559:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:47:48,565:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:47:48,575:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:47:48,587:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:47:48,594:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:47:48,596:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:47:48,598:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:47:48,612:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:47:48,615:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:47:48,624:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:47:48,636:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:47:48,657:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:47:48,660:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:47:48,661:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:47:48,668:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:47:48,670:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:47:48,678:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:47:48,683:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:47:48,686:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:47:48,693:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:47:48,696:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:47:48,702:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:47:48,740:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:47:48,742:INFO:EPOCH - 10 : training on 274775 raw words (173775 effective words) took 0.6s, 301962 effective words/s\n2020-09-12 12:47:48,742:INFO:training on a 2747750 raw words (1738299 effective words) took 5.8s, 297908 effective words/s\n2020-09-12 12:47:48,743:INFO:saving Word2Vec object under models/w2v_300_1.txt, separately None\n2020-09-12 12:47:48,744:INFO:not storing attribute vectors_norm\n2020-09-12 12:47:48,745:INFO:not storing attribute cum_table\n2020-09-12 12:47:48,959:INFO:saved models/w2v_300_1.txt\nw2v model done\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<gensim.models.word2vec.Word2Vec at 0x1b8000c0130>"
     },
     "metadata": {},
     "execution_count": 31
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 31
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "s/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:22,044:INFO:EPOCH 6 - PROGRESS: at 9.56% examples, 213800 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:23,085:INFO:EPOCH 6 - PROGRESS: at 16.96% examples, 247457 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:24,161:INFO:EPOCH 6 - PROGRESS: at 23.23% examples, 252949 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:25,168:INFO:EPOCH 6 - PROGRESS: at 31.38% examples, 266538 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:26,170:INFO:EPOCH 6 - PROGRESS: at 36.05% examples, 263499 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:27,184:INFO:EPOCH 6 - PROGRESS: at 40.33% examples, 265560 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:28,187:INFO:EPOCH 6 - PROGRESS: at 45.27% examples, 272918 words/s, in_qsize 46, out_qsize 1\n2020-09-12 12:49:29,221:INFO:EPOCH 6 - PROGRESS: at 52.83% examples, 273797 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:30,287:INFO:EPOCH 6 - PROGRESS: at 60.49% examples, 274831 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:31,331:INFO:EPOCH 6 - PROGRESS: at 67.42% examples, 274631 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:32,428:INFO:EPOCH 6 - PROGRESS: at 75.18% examples, 275786 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:33,494:INFO:EPOCH 6 - PROGRESS: at 80.91% examples, 274751 words/s, in_qsize 46, out_qsize 1\n2020-09-12 12:49:34,496:INFO:EPOCH 6 - PROGRESS: at 88.73% examples, 275586 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:35,567:INFO:EPOCH 6 - PROGRESS: at 96.60% examples, 273354 words/s, in_qsize 23, out_qsize 2\n2020-09-12 12:49:35,570:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:49:35,571:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:49:35,573:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:49:35,575:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:49:35,590:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:49:35,597:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:49:35,615:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:49:35,617:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:49:35,620:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:49:35,623:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:49:35,625:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:49:35,628:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:49:35,639:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:49:35,653:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:49:35,655:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:49:35,696:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:49:35,714:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:49:35,718:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:49:35,722:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:49:35,729:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:49:35,731:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:49:35,763:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:49:35,771:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:49:35,773:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:49:35,774:INFO:EPOCH - 6 : training on 7353504 raw words (4392077 effective words) took 15.8s, 278725 effective words/s\n2020-09-12 12:49:36,838:INFO:EPOCH 7 - PROGRESS: at 4.57% examples, 189523 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:37,842:INFO:EPOCH 7 - PROGRESS: at 10.13% examples, 226148 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:38,875:INFO:EPOCH 7 - PROGRESS: at 17.01% examples, 250134 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:39,936:INFO:EPOCH 7 - PROGRESS: at 23.49% examples, 256205 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:40,945:INFO:EPOCH 7 - PROGRESS: at 30.28% examples, 257410 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:41,979:INFO:EPOCH 7 - PROGRESS: at 35.74% examples, 260545 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:43,055:INFO:EPOCH 7 - PROGRESS: at 40.25% examples, 258813 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:44,066:INFO:EPOCH 7 - PROGRESS: at 43.89% examples, 263914 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:45,082:INFO:EPOCH 7 - PROGRESS: at 51.30% examples, 264714 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:46,089:INFO:EPOCH 7 - PROGRESS: at 58.32% examples, 265142 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:47,101:INFO:EPOCH 7 - PROGRESS: at 64.10% examples, 265019 words/s, in_qsize 48, out_qsize 1\n2020-09-12 12:49:48,179:INFO:EPOCH 7 - PROGRESS: at 71.48% examples, 266442 words/s, in_qsize 48, out_qsize 0\n2020-09-12 12:49:49,186:INFO:EPOCH 7 - PROGRESS: at 78.66% examples, 269566 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:50,194:INFO:EPOCH 7 - PROGRESS: at 85.61% examples, 269938 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:51,212:INFO:EPOCH 7 - PROGRESS: at 92.85% examples, 267303 words/s, in_qsize 48, out_qsize 0\n2020-09-12 12:49:51,814:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:49:51,819:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:49:51,821:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:49:51,823:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:49:51,835:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:49:51,892:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:49:51,942:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:49:51,944:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:49:51,958:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:49:51,971:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:49:51,992:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:49:52,004:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:49:52,006:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:49:52,016:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:49:52,028:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:49:52,043:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:49:52,063:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:49:52,082:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:49:52,106:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:49:52,127:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:49:52,137:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:49:52,139:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:49:52,145:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:49:52,147:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:49:52,149:INFO:EPOCH - 7 : training on 7353504 raw words (4390521 effective words) took 16.3s, 268890 effective words/s\n2020-09-12 12:49:53,234:INFO:EPOCH 8 - PROGRESS: at 3.23% examples, 148631 words/s, in_qsize 48, out_qsize 0\n2020-09-12 12:49:54,251:INFO:EPOCH 8 - PROGRESS: at 8.79% examples, 197209 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:55,265:INFO:EPOCH 8 - PROGRESS: at 14.51% examples, 210075 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:56,275:INFO:EPOCH 8 - PROGRESS: at 18.60% examples, 213908 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:57,299:INFO:EPOCH 8 - PROGRESS: at 24.41% examples, 215071 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:49:58,316:INFO:EPOCH 8 - PROGRESS: at 30.53% examples, 218554 words/s, in_qsize 46, out_qsize 1\n2020-09-12 12:49:59,372:INFO:EPOCH 8 - PROGRESS: at 35.23% examples, 220141 words/s, in_qsize 48, out_qsize 0\n2020-09-12 12:50:00,428:INFO:EPOCH 8 - PROGRESS: at 40.03% examples, 225260 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:01,472:INFO:EPOCH 8 - PROGRESS: at 41.77% examples, 221312 words/s, in_qsize 46, out_qsize 1\n2020-09-12 12:50:02,508:INFO:EPOCH 8 - PROGRESS: at 46.74% examples, 223919 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:03,508:INFO:EPOCH 8 - PROGRESS: at 54.95% examples, 230190 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:04,533:INFO:EPOCH 8 - PROGRESS: at 62.18% examples, 235133 words/s, in_qsize 43, out_qsize 4\n2020-09-12 12:50:05,538:INFO:EPOCH 8 - PROGRESS: at 69.37% examples, 240917 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:06,564:INFO:EPOCH 8 - PROGRESS: at 77.01% examples, 243997 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:07,628:INFO:EPOCH 8 - PROGRESS: at 82.73% examples, 244244 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:08,634:INFO:EPOCH 8 - PROGRESS: at 91.46% examples, 247831 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:09,278:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:50:09,281:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:50:09,282:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:50:09,284:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:50:09,285:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:50:09,292:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:50:09,331:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:50:09,337:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:50:09,359:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:50:09,370:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:50:09,387:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:50:09,408:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:50:09,411:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:50:09,416:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:50:09,432:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:50:09,462:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:50:09,464:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:50:09,501:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:50:09,531:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:50:09,540:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:50:09,546:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:50:09,554:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:50:09,580:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:50:09,584:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:50:09,586:INFO:EPOCH - 8 : training on 7353504 raw words (4392445 effective words) took 17.4s, 252994 effective words/s\n2020-09-12 12:50:10,668:INFO:EPOCH 9 - PROGRESS: at 4.60% examples, 198418 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:11,677:INFO:EPOCH 9 - PROGRESS: at 10.03% examples, 225418 words/s, in_qsize 48, out_qsize 0\n2020-09-12 12:50:12,678:INFO:EPOCH 9 - PROGRESS: at 17.03% examples, 256855 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:13,690:INFO:EPOCH 9 - PROGRESS: at 23.01% examples, 255331 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:14,791:INFO:EPOCH 9 - PROGRESS: at 30.28% examples, 257054 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:15,799:INFO:EPOCH 9 - PROGRESS: at 35.87% examples, 261264 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:16,858:INFO:EPOCH 9 - PROGRESS: at 40.28% examples, 260743 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:17,907:INFO:EPOCH 9 - PROGRESS: at 44.14% examples, 264662 words/s, in_qsize 48, out_qsize 0\n2020-09-12 12:50:18,984:INFO:EPOCH 9 - PROGRESS: at 51.48% examples, 264285 words/s, in_qsize 48, out_qsize 1\n2020-09-12 12:50:20,032:INFO:EPOCH 9 - PROGRESS: at 60.06% examples, 269478 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:21,053:INFO:EPOCH 9 - PROGRESS: at 67.25% examples, 271537 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:22,112:INFO:EPOCH 9 - PROGRESS: at 71.95% examples, 266005 words/s, in_qsize 44, out_qsize 3\n2020-09-12 12:50:23,115:INFO:EPOCH 9 - PROGRESS: at 79.14% examples, 270120 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:24,149:INFO:EPOCH 9 - PROGRESS: at 86.00% examples, 268990 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:25,181:INFO:EPOCH 9 - PROGRESS: at 94.75% examples, 269796 words/s, in_qsize 35, out_qsize 0\n2020-09-12 12:50:25,434:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:50:25,436:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:50:25,437:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:50:25,457:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:50:25,469:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:50:25,574:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:50:25,586:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:50:25,618:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:50:25,623:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:50:25,638:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:50:25,654:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:50:25,668:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:50:25,673:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:50:25,690:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:50:25,692:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:50:25,701:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:50:25,714:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:50:25,718:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:50:25,722:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:50:25,725:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:50:25,749:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:50:25,758:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:50:25,775:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:50:25,779:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:50:25,782:INFO:EPOCH - 9 : training on 7353504 raw words (4391548 effective words) took 16.1s, 272430 effective words/s\n2020-09-12 12:50:26,871:INFO:EPOCH 10 - PROGRESS: at 4.01% examples, 172789 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:27,877:INFO:EPOCH 10 - PROGRESS: at 10.27% examples, 226166 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:28,968:INFO:EPOCH 10 - PROGRESS: at 17.02% examples, 246194 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:30,000:INFO:EPOCH 10 - PROGRESS: at 23.30% examples, 252055 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:31,135:INFO:EPOCH 10 - PROGRESS: at 30.42% examples, 250292 words/s, in_qsize 44, out_qsize 5\n2020-09-12 12:50:32,157:INFO:EPOCH 10 - PROGRESS: at 35.90% examples, 254908 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:33,199:INFO:EPOCH 10 - PROGRESS: at 40.28% examples, 256868 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:34,217:INFO:EPOCH 10 - PROGRESS: at 43.84% examples, 259474 words/s, in_qsize 48, out_qsize 0\n2020-09-12 12:50:35,268:INFO:EPOCH 10 - PROGRESS: at 51.52% examples, 261174 words/s, in_qsize 48, out_qsize 1\n2020-09-12 12:50:36,415:INFO:EPOCH 10 - PROGRESS: at 58.48% examples, 258008 words/s, in_qsize 46, out_qsize 1\n2020-09-12 12:50:37,480:INFO:EPOCH 10 - PROGRESS: at 63.94% examples, 256037 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:38,496:INFO:EPOCH 10 - PROGRESS: at 69.85% examples, 255191 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:39,500:INFO:EPOCH 10 - PROGRESS: at 76.35% examples, 253600 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:40,502:INFO:EPOCH 10 - PROGRESS: at 80.53% examples, 251087 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:41,534:INFO:EPOCH 10 - PROGRESS: at 87.26% examples, 251344 words/s, in_qsize 47, out_qsize 0\n2020-09-12 12:50:42,561:INFO:EPOCH 10 - PROGRESS: at 94.72% examples, 250296 words/s, in_qsize 34, out_qsize 2\n2020-09-12 12:50:42,876:INFO:worker thread finished; awaiting finish of 23 more threads\n2020-09-12 12:50:42,879:INFO:worker thread finished; awaiting finish of 22 more threads\n2020-09-12 12:50:42,914:INFO:worker thread finished; awaiting finish of 21 more threads\n2020-09-12 12:50:42,920:INFO:worker thread finished; awaiting finish of 20 more threads\n2020-09-12 12:50:43,006:INFO:worker thread finished; awaiting finish of 19 more threads\n2020-09-12 12:50:43,014:INFO:worker thread finished; awaiting finish of 18 more threads\n2020-09-12 12:50:43,042:INFO:worker thread finished; awaiting finish of 17 more threads\n2020-09-12 12:50:43,045:INFO:worker thread finished; awaiting finish of 16 more threads\n2020-09-12 12:50:43,063:INFO:worker thread finished; awaiting finish of 15 more threads\n2020-09-12 12:50:43,074:INFO:worker thread finished; awaiting finish of 14 more threads\n2020-09-12 12:50:43,088:INFO:worker thread finished; awaiting finish of 13 more threads\n2020-09-12 12:50:43,111:INFO:worker thread finished; awaiting finish of 12 more threads\n2020-09-12 12:50:43,126:INFO:worker thread finished; awaiting finish of 11 more threads\n2020-09-12 12:50:43,128:INFO:worker thread finished; awaiting finish of 10 more threads\n2020-09-12 12:50:43,145:INFO:worker thread finished; awaiting finish of 9 more threads\n2020-09-12 12:50:43,160:INFO:worker thread finished; awaiting finish of 8 more threads\n2020-09-12 12:50:43,169:INFO:worker thread finished; awaiting finish of 7 more threads\n2020-09-12 12:50:43,182:INFO:worker thread finished; awaiting finish of 6 more threads\n2020-09-12 12:50:43,184:INFO:worker thread finished; awaiting finish of 5 more threads\n2020-09-12 12:50:43,195:INFO:worker thread finished; awaiting finish of 4 more threads\n2020-09-12 12:50:43,218:INFO:worker thread finished; awaiting finish of 3 more threads\n2020-09-12 12:50:43,222:INFO:worker thread finished; awaiting finish of 2 more threads\n2020-09-12 12:50:43,224:INFO:worker thread finished; awaiting finish of 1 more threads\n2020-09-12 12:50:43,242:INFO:worker thread finished; awaiting finish of 0 more threads\n2020-09-12 12:50:43,244:INFO:EPOCH - 10 : training on 7353504 raw words (4390092 effective words) took 17.4s, 252334 effective words/s\n2020-09-12 12:50:43,245:INFO:training on a 73535040 raw words (43918396 effective words) took 165.1s, 266059 effective words/s\n2020-09-12 12:50:43,247:INFO:saving Word2Vec object under models/w2v_300_3.txt, separately None\n2020-09-12 12:50:43,248:INFO:not storing attribute vectors_norm\n2020-09-12 12:50:43,250:INFO:not storing attribute cum_table\n2020-09-12 12:50:44,830:INFO:saved models/w2v_300_3.txt\nw2v model done\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<gensim.models.word2vec.Word2Vec at 0x1b82bbe2460>"
     },
     "metadata": {},
     "execution_count": 31
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 31
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020-09-12 12:50:45,285:INFO:loading Word2Vec object from models/w2v_300_1.txt\n2020-09-12 12:50:45,556:INFO:loading wv recursively from models/w2v_300_1.txt.wv.* with mmap=None\n2020-09-12 12:50:45,558:INFO:setting ignored attribute vectors_norm to None\n2020-09-12 12:50:45,559:INFO:loading vocabulary recursively from models/w2v_300_1.txt.vocabulary.* with mmap=None\n2020-09-12 12:50:45,561:INFO:loading trainables recursively from models/w2v_300_1.txt.trainables.* with mmap=None\n2020-09-12 12:50:45,562:INFO:setting ignored attribute cum_table to None\n2020-09-12 12:50:45,564:INFO:loaded models/w2v_300_1.txt\n100%|██████████| 8360/8360 [00:00<00:00, 44751.46it/s]\n2020-09-12 12:50:45,805:INFO:loading Word2Vec object from models/w2v_300_3.txt\nnull cnt 5\n2020-09-12 12:50:46,383:INFO:loading wv recursively from models/w2v_300_3.txt.wv.* with mmap=None\n2020-09-12 12:50:46,384:INFO:setting ignored attribute vectors_norm to None\n2020-09-12 12:50:46,385:INFO:loading vocabulary recursively from models/w2v_300_3.txt.vocabulary.* with mmap=None\n2020-09-12 12:50:46,385:INFO:loading trainables recursively from models/w2v_300_3.txt.trainables.* with mmap=None\n2020-09-12 12:50:46,386:INFO:setting ignored attribute cum_table to None\n2020-09-12 12:50:46,387:INFO:loaded models/w2v_300_3.txt\n100%|██████████| 21826/21826 [00:00<00:00, 95406.36it/s]\nnull cnt 492\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "9"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "text_1_list = np.unique(train_data['text_1'])\n",
    "# text_2_list = np.unique(train_data['text_3'])\n",
    "text_3_list = np.unique(train_data['text_2'])\n",
    "\n",
    "print('开始序列化')\n",
    "x1, index_1, token_1 = set_tokenizer(train_data['text_1'], split_char=' ', max_len=60)\n",
    "x3, index_3, token_3 = set_tokenizer(train_data['text_2'], split_char=' ', max_len=600)\n",
    "\n",
    "print('序列化完成')\n",
    "gc.collect()\n",
    "\n",
    "trian_save_word2vec(text_1_list, save_name='models/w2v_300_1.txt', split_char=' ')\n",
    "gc.collect()\n",
    "trian_save_word2vec(text_3_list, save_name='models/w2v_300_3.txt', split_char=' ')\n",
    "gc.collect()\n",
    "\n",
    "# 得到emb矩阵\n",
    "emb1 = get_embedding_matrix(index_1, Emed_path='models/w2v_300_1.txt')\n",
    "emb3 = get_embedding_matrix(index_3, Emed_path='models/w2v_300_3.txt')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建抽取模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "from keras.initializers import *\n",
    "\n",
    "def model_conv(emb1, emb3):\n",
    "    '''\n",
    "    注意这个inputs\n",
    "    seq1、seq2分别是两个输入\n",
    "    是否做emb可选可不选，\n",
    "    这个就是我们之前训练已经得到的用于embedding的（embedding_matrix1， embedding_matrix2）\n",
    "    '''\n",
    "    K.clear_session()\n",
    "\n",
    "    emb_layer_1 = Embedding(\n",
    "        input_dim=emb1.shape[0],\n",
    "        output_dim=emb1.shape[1],\n",
    "        weights=[emb1],\n",
    "        input_length=30,\n",
    "        trainable=False\n",
    "    )\n",
    "    \n",
    "    emb_layer_3 = Embedding(\n",
    "        input_dim=emb3.shape[0],\n",
    "        output_dim=emb3.shape[1],\n",
    "        weights=[emb3],\n",
    "        input_length=600,\n",
    "        trainable=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    seq1 = Input(shape=(30,))\n",
    "    seq3 = Input(shape=(600,))    \n",
    "    \n",
    "    x1 = emb_layer_1(seq1)\n",
    "    x3 = emb_layer_3(seq3)\n",
    "    \n",
    "    sdrop=SpatialDropout1D(rate=0.2)\n",
    "\n",
    "    x1 = sdrop(x1)\n",
    "    x3 = sdrop(x3)\n",
    "     \n",
    "    x = Dropout(0.2)(Bidirectional(GRU(128, return_sequences=True))(x1))\n",
    "    semantic = TimeDistributed(Dense(100, activation=\"tanh\"))(x)\n",
    "    merged_1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(100,))(semantic)\n",
    "    \n",
    "    x = Dropout(0.2)(Bidirectional(GRU(128, return_sequences=True))(x3))\n",
    "    semantic = TimeDistributed(Dense(100, activation=\"tanh\"))(x)\n",
    "    merged_3 = Lambda(lambda x: K.max(x, axis=1), output_shape=(100,))(semantic)\n",
    "    \n",
    "    \n",
    "    x = Multiply()([merged_1, merged_3])\n",
    "    \n",
    "    x = Dropout(0.2)(Activation(activation=\"relu\")(BatchNormalization()(Dense(1000)(x))))\n",
    "    x = Activation(activation=\"relu\")(BatchNormalization()(Dense(500)(x)))\n",
    "    pred_1 = Dense(10, activation='softmax')(x)\n",
    "    pred_2 = Dense(3, activation='softmax')(x)\n",
    "    pred_3 = Dense(3, activation='softmax')(x)\n",
    "    pred_4 = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=[seq1, seq3], outputs=[pred_1, pred_2, pred_3, pred_4])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=0.0001),metrics=[\"accuracy\"])\n",
    "    return model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 30)]         0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, 600)]        0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 30, 300)      2508300     input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 600, 300)     6548100     input_2[0][0]                    \n__________________________________________________________________________________________________\nspatial_dropout1d (SpatialDropo multiple             0           embedding[0][0]                  \n                                                                 embedding_1[0][0]                \n__________________________________________________________________________________________________\nbidirectional (Bidirectional)   (None, 30, 256)      330240      spatial_dropout1d[0][0]          \n__________________________________________________________________________________________________\nbidirectional_1 (Bidirectional) (None, 600, 256)     330240      spatial_dropout1d[1][0]          \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 30, 256)      0           bidirectional[0][0]              \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 600, 256)     0           bidirectional_1[0][0]            \n__________________________________________________________________________________________________\ntime_distributed (TimeDistribut (None, 30, 100)      25700       dropout[0][0]                    \n__________________________________________________________________________________________________\ntime_distributed_1 (TimeDistrib (None, 600, 100)     25700       dropout_1[0][0]                  \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 100)          0           time_distributed[0][0]           \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 100)          0           time_distributed_1[0][0]         \n__________________________________________________________________________________________________\nmultiply (Multiply)             (None, 100)          0           lambda[0][0]                     \n                                                                 lambda_1[0][0]                   \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1000)         101000      multiply[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 1000)         4000        dense_2[0][0]                    \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 1000)         0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 1000)         0           activation[0][0]                 \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 500)          500500      dropout_2[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 500)          2000        dense_3[0][0]                    \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 500)          0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 10)           5010        activation_1[0][0]               \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 3)            1503        activation_1[0][0]               \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 3)            1503        activation_1[0][0]               \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 2)            1002        activation_1[0][0]               \n==================================================================================================\nTotal params: 10,384,798\nTrainable params: 1,325,398\nNon-trainable params: 9,059,400\n__________________________________________________________________________________________________\nEpoch 1/8\nWARNING:tensorflow:Model was constructed with shape (None, 30) for input Tensor(\"input_1:0\", shape=(None, 30), dtype=float32), but it was called on an input with incompatible shape (None, 60).\n2020-09-12 12:50:49,483:WARNING:Model was constructed with shape (None, 30) for input Tensor(\"input_1:0\", shape=(None, 30), dtype=float32), but it was called on an input with incompatible shape (None, 60).\nWARNING:tensorflow:Model was constructed with shape (None, 30) for input Tensor(\"input_1:0\", shape=(None, 30), dtype=float32), but it was called on an input with incompatible shape (None, 60).\n2020-09-12 12:50:54,393:WARNING:Model was constructed with shape (None, 30) for input Tensor(\"input_1:0\", shape=(None, 30), dtype=float32), but it was called on an input with incompatible shape (None, 60).\n107/107 [==============================] - 2085s 19s/step - loss: 2.8126 - dense_4_loss: 0.9039 - dense_5_loss: 0.7750 - dense_6_loss: 0.8750 - dense_7_loss: 0.2587 - dense_4_accuracy: 0.7513 - dense_5_accuracy: 0.6461 - dense_6_accuracy: 0.6240 - dense_7_accuracy: 0.9170\nEpoch 2/8\n107/107 [==============================] - 2997s 28s/step - loss: 1.1309 - dense_4_loss: 0.1800 - dense_5_loss: 0.6210 - dense_6_loss: 0.2847 - dense_7_loss: 0.0452 - dense_4_accuracy: 0.9620 - dense_5_accuracy: 0.7037 - dense_6_accuracy: 0.9104 - dense_7_accuracy: 0.9985\nEpoch 3/8\n107/107 [==============================] - 3041s 28s/step - loss: 0.8377 - dense_4_loss: 0.1335 - dense_5_loss: 0.5537 - dense_6_loss: 0.1261 - dense_7_loss: 0.0244 - dense_4_accuracy: 0.9694 - dense_5_accuracy: 0.7428 - dense_6_accuracy: 0.9672 - dense_7_accuracy: 0.9986\nEpoch 4/8\n107/107 [==============================] - 2961s 28s/step - loss: 0.6433 - dense_4_loss: 0.1104 - dense_5_loss: 0.4272 - dense_6_loss: 0.0882 - dense_7_loss: 0.0175 - dense_4_accuracy: 0.9733 - dense_5_accuracy: 0.8200 - dense_6_accuracy: 0.9783 - dense_7_accuracy: 0.9986\nEpoch 5/8\n107/107 [==============================] - 2891s 27s/step - loss: 0.5406 - dense_4_loss: 0.0945 - dense_5_loss: 0.3591 - dense_6_loss: 0.0727 - dense_7_loss: 0.0143 - dense_4_accuracy: 0.9760 - dense_5_accuracy: 0.8578 - dense_6_accuracy: 0.9817 - dense_7_accuracy: 0.9986\nEpoch 6/8\n107/107 [==============================] - 2965s 28s/step - loss: 0.4780 - dense_4_loss: 0.0841 - dense_5_loss: 0.3206 - dense_6_loss: 0.0612 - dense_7_loss: 0.0120 - dense_4_accuracy: 0.9778 - dense_5_accuracy: 0.8738 - dense_6_accuracy: 0.9846 - dense_7_accuracy: 0.9986\nEpoch 7/8\n107/107 [==============================] - 3096s 29s/step - loss: 0.4369 - dense_4_loss: 0.0761 - dense_5_loss: 0.2946 - dense_6_loss: 0.0551 - dense_7_loss: 0.0111 - dense_4_accuracy: 0.9805 - dense_5_accuracy: 0.8859 - dense_6_accuracy: 0.9850 - dense_7_accuracy: 0.9986\nEpoch 8/8\n107/107 [==============================] - 2887s 27s/step - loss: 0.3963 - dense_4_loss: 0.0676 - dense_5_loss: 0.2734 - dense_6_loss: 0.0451 - dense_7_loss: 0.0102 - dense_4_accuracy: 0.9820 - dense_5_accuracy: 0.8941 - dense_6_accuracy: 0.9883 - dense_7_accuracy: 0.9986\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1b852551eb0>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "model = model_conv(emb1, emb3)\n",
    "model.summary()\n",
    "l1 = to_categorical(train_data['label_1'], 10)\n",
    "l2 = to_categorical(train_data['label_2'], 3)\n",
    "l3 = to_categorical(train_data['label_3'], 3)\n",
    "l4 = to_categorical(train_data['label_4'], 2)\n",
    "model.fit([x1, x3],[l1, l2, l3, l4], batch_size=256, epochs=8, verbose=1, shuffle=True)\n",
    "# model.load_weights('models\\lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存权重\n",
    "model.save_weights('models/lstm_valid_text_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'val_result' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-26ce19f84820>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 预测验证集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mval_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sample_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sample_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mval_result_for_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sample_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mval_result_for_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_result_for_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'理财产品名称'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_result_for_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'产品发行方名称'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_result_for_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_result_for_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_result' is not defined"
     ]
    }
   ],
   "source": [
    "# 预测验证集\n",
    "val_df[\"sample_id\"]=val_df[\"sample_id\"].astype(str)\n",
    "val_result_for_pred = pd.merge(val_result, val_df, on='sample_id', how='left')\n",
    "val_result_for_pred['text_1'] = val_result_for_pred['理财产品名称'].astype(str) + '_' + val_result_for_pred['产品发行方名称'].astype(str)\n",
    "val_result_for_pred['text_2'] = val_result_for_pred['text'].astype(str)\n",
    "\n",
    "val_result_for_pred['text_1'] = val_result_for_pred['text_1'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "val_result_for_pred['text_2'] = val_result_for_pred['text_2'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "\n",
    "x1 = token_1.texts_to_sequences(val_result_for_pred['text_1'])\n",
    "x1 = pad_sequences(x1, maxlen=30, value=0)\n",
    "x3 = token_3.texts_to_sequences(val_result_for_pred['text_2'])\n",
    "x3 = pad_sequences(x3, maxlen=600, value=0)\n",
    "pred_result = model.predict([x1, x3], batch_size=1024, verbose=1)\n",
    "pred_1 = label_1.inverse_transform(np.argmax(pred_result[0], axis=1))\n",
    "pred_2 = label_2.inverse_transform(np.argmax(pred_result[1], axis=1))\n",
    "pred_3 = label_3.inverse_transform(np.argmax(pred_result[2], axis=1))\n",
    "pred_4 = label_4.inverse_transform(np.argmax(pred_result[3], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pred_1' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-33bb5074b888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'理财类型'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'资金来源'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mval_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'实际购买公司和上市公司关系'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mval_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'买卖方是否有关联关系'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_1' is not defined"
     ]
    }
   ],
   "source": [
    "val_result['理财类型'] = pred_1\n",
    "val_result['资金来源'] = pred_2\n",
    "val_result['实际购买公司和上市公司关系'] = pred_3\n",
    "val_result['买卖方是否有关联关系'] = pred_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.离线验证评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'val_result' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-9836af1d8ef2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mval_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'认购日期'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'理财产品名称'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'理财类型'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'认购金额(万元)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'产品起息日'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'产品到息日'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'产品期限'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'资金来源'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'实际购买公司名称'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'实际购买公司和上市公司关系'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'买卖方是否有关联关系'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'公告日期'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mval_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'认购日期'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'理财产品名称'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'理财类型'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'认购金额(万元)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'产品起息日'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'产品到息日'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'产品期限'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'资金来源'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'实际购买公司名称'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'实际购买公司和上市公司关系'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'买卖方是否有关联关系'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'公告日期'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_result' is not defined"
     ]
    }
   ],
   "source": [
    "# 计算线下f1\n",
    "# R（召回率）=抽取正确的记录数量/（抽取正确的目标数量+漏抽取的记录数量）\n",
    "# P（准确率）=抽取正确的记录数量/（抽取错误的记录数量+抽取正确的记录数量）\n",
    "def get_F1(val_pred, val_true):\n",
    "    val_pred = list(val_pred)\n",
    "    val_true = list(val_true)\n",
    "    curr = list(set(val_pred).intersection(set(val_true)))\n",
    "    R = len(curr)/len(val_true)\n",
    "    P = len(curr)/len(val_pred)\n",
    "    return 2*P*R/(P+R)\n",
    "\n",
    "train_outputs[\"sample_id\"]=train_outputs[\"sample_id\"].astype(str)\n",
    "r = pd.merge(val_df[['sample_id']], train_outputs, on='sample_id', how='left')\n",
    "val_true = r['sample_id'].astype(str) + r['认购日期'].astype(str) + r['理财产品名称'].astype(str) + r['理财类型'].astype(str) + r['认购金额(万元)'].astype(str) + r['产品起息日'].astype(str)+ r['产品到息日'].astype(str) + r['产品期限'].astype(str) + r['资金来源'].astype(str) + r['实际购买公司名称'].astype(str) + r['实际购买公司和上市公司关系'].astype(str) + r['买卖方是否有关联关系'].astype(str) + r['公告日期'].astype(str)\n",
    "\n",
    "r = val_result\n",
    "val_pred = r['sample_id'].astype(str) + r['认购日期'].astype(str) + r['理财产品名称'].astype(str) + r['理财类型'].astype(str) + r['认购金额(万元)'].astype(str) + r['产品起息日'].astype(str)+ r['产品到息日'].astype(str) + r['产品期限'].astype(str) + r['资金来源'].astype(str) + r['实际购买公司名称'].astype(str) + r['实际购买公司和上市公司关系'].astype(str) + r['买卖方是否有关联关系'].astype(str) + r['公告日期'].astype(str)\n",
    "\n",
    "score = get_F1(val_pred, val_true)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'val_result' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-24e817b98e00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtr_true_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"results/tr_true.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mval_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sample_id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_pred_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sample_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sample_id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_true_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sample_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sample_id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_true_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_result' is not defined"
     ]
    }
   ],
   "source": [
    "val_true_file=pl.Path(\"results/val_true.csv\")\n",
    "val_pred_file=pl.Path(\"results/val_pred.csv\")\n",
    "\n",
    "tr_true_file=pl.Path(\"results/tr_true.csv\")\n",
    "val_result.copy().sort_values(by=\"sample_id\").sort_index(axis=1).to_csv(val_pred_file,index=None)\n",
    "pd.merge(val_df[['sample_id']], train_outputs, on='sample_id', how='left').sort_index(axis=1).sort_values(by=\"sample_id\").to_csv(val_true_file,index=None)\n",
    "pd.merge(train_df[['sample_id']], train_outputs, on='sample_id', how='left').sort_index(axis=1).sort_values(by=\"sample_id\").to_csv(tr_true_file,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.最终输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_data=pl.Path(\"text_test_2210_result.xlsx\")\n",
    "test_result=pd.read_excel(test_result_data)\n",
    "test_result[\"sample_id\"]=test_result[\"sample_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 5369/5369 [00:01<00:00, 3928.73it/s]\n100%|██████████| 5369/5369 [00:41<00:00, 129.93it/s]\n6/6 [==============================] - 43s 7s/step\n"
    }
   ],
   "source": [
    "# 预测测试集\n",
    "test_df[\"sample_id\"]=test_df[\"sample_id\"].astype(str)\n",
    "test_result_for_pred = pd.merge(test_result, test_df, on='sample_id', how='left')\n",
    "test_result_for_pred['text_1'] = test_result_for_pred['理财产品名称'].astype(str) + '_' + test_result_for_pred['产品发行方名称'].astype(str)+\"_\"+train_lstm_input['实际购买公司名称'].astype(str)\n",
    "test_result_for_pred['text_2'] = test_result_for_pred['text'].astype(str)\n",
    "\n",
    "test_result_for_pred['text_1'] = test_result_for_pred['text_1'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "test_result_for_pred['text_2'] = test_result_for_pred['text_2'].progress_apply(lambda row:' '.join(jieba.lcut(str(row))))\n",
    "\n",
    "x1 = token_1.texts_to_sequences(test_result_for_pred['text_1'])\n",
    "x1 = pad_sequences(x1, maxlen=30, value=0)\n",
    "x3 = token_3.texts_to_sequences(test_result_for_pred['text_2'])\n",
    "x3 = pad_sequences(x3, maxlen=600, value=0)\n",
    "pred_result = model.predict([x1, x3], batch_size=1024, verbose=1)\n",
    "pred_1 = label_1.inverse_transform(np.argmax(pred_result[0], axis=1))\n",
    "pred_2 = label_2.inverse_transform(np.argmax(pred_result[1], axis=1))\n",
    "pred_3 = label_3.inverse_transform(np.argmax(pred_result[2], axis=1))\n",
    "pred_4 = label_4.inverse_transform(np.argmax(pred_result[3], axis=1))\n",
    "\n",
    "test_result['理财类型'] = pred_1\n",
    "test_result['资金来源'] = pred_2\n",
    "test_result['实际购买公司和上市公司关系'] = pred_3\n",
    "test_result['买卖方是否有关联关系'] = pred_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_result.to_csv('results/re_lstm_base.csv',encoding=\"utf8\", index=False)\n",
    "test_result.to_excel('results/re_lstm_base2218.xlsx',encoding=\"gb18030\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "files_num=int(test_df.shape[0]/4)\n",
    "test_time[\"sample_id\"]=test_time[\"sample_id\"].astype(str)\n",
    "\n",
    "# test_time.shape\n",
    "# test_time.dropna(subset=[\"公告日期\"]).shape\n",
    "import random\n",
    "for i in range(1,20):\n",
    "    random_seed=random.randint(0,10000)\n",
    "    random_test_df = test_df.sample(frac=1, random_state=random_seed)\n",
    "    change_df=random_test_df[:files_num]\n",
    "    stable_df=random_test_df[files_num:]\n",
    "    random_test_time=pd.merge(change_df,test_time,on=[\"sample_id\"])\n",
    "    random_test_time.shape\n",
    "    random_test_time=random_test_time.dropna(subset=[\"公告日期\"])\n",
    "    random_test_time.shape\n",
    "    random_test_time[\"公告日期\"]=random_test_time[\"公告日期\"].map(lambda x:datetime.datetime.strftime(datetime.datetime.strptime(str(x.replace(\"\\r\",\"\")), '%Y-%m-%d'),'%Y-%m-%d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-4c1b78c9b79b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msample_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4663\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# sample_id=7123\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sample_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0msample_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tabel\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtable_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart_rows_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfirst_line_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mproduct_df_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrow_combine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1435\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1437\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "sample_id=4663\n",
    "# sample_id=7123\n",
    "tabel=val_df[val_df[\"sample_id\"]==sample_id][\"tabel\"].iloc[0]\n",
    "table_result,start_rows_list,first_line_list,product_df_list=row_combine(sample_id,tabel)\n",
    "index=0\n",
    "table_result[index]\n",
    "product_df_list_ele=product_df_list[index].reset_index(drop=True)\n",
    "product_df_list_ele\n",
    "# product_df_list_ele\n",
    "each_sum_rows=get_each_product_row(table_result[index],product_df_list_ele.reset_index(drop=True))\n",
    "\n",
    "each_sum_rows2=result_matrix[result_matrix[\"sample_id\"]==sample_id][\"product_df\"].iloc[0]\n",
    "# # each_sum_rows\n",
    "each_sum_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}