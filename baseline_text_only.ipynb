{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关包\n",
    "import os\n",
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from io import StringIO\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from tqdm.autonotebook import *\n",
    "import pdfplumber\n",
    "import collections\n",
    "tqdm.pandas()\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from tgrocery import Grocery\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id                     file_path  \\\n0      11188  datasets/test_data/11188.PDF   \n1      11189  datasets/test_data/11189.PDF   \n\n                                                text tabel  \n0  ['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...    []  \n1  ['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...    []  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>file_path</th>\n      <th>text</th>\n      <th>tabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11188</td>\n      <td>datasets/test_data/11188.PDF</td>\n      <td>['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11189</td>\n      <td>datasets/test_data/11189.PDF</td>\n      <td>['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# 数据准备(train_output文件中格式有点问题，需要提前用excel或者wps打开然后另存为excel文件)\n",
    "train_outputs = pd.read_excel('datasets/train_output.xlsx')\n",
    "\n",
    "# 获取pdf中文字和表格\n",
    "def extract_pdf_content(pdf_path):\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for index_page in np.arange(0, len(pdf.pages), 1):\n",
    "            # 读取多页\n",
    "            page = pdf.pages[index_page]   # 第n页的信息\n",
    "            text = page.extract_text()\n",
    "            text_list.append(text)\n",
    "            table = page.extract_tables()\n",
    "            for t in table:\n",
    "                table_list.append(t)\n",
    "    return text_list, table_list\n",
    "\n",
    "def get_dir_file(path):\n",
    "    '''\n",
    "    输入文件夹位置，输出整理好的dataframe\n",
    "    '''\n",
    "    path_list = os.listdir(path)\n",
    "    id_list = []\n",
    "    file_path_list = []\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    for i in tqdm(path_list):\n",
    "        if '.PDF' in i:\n",
    "            file_path = path + i\n",
    "            id_list.append(int(i.split('.')[0]))\n",
    "            file_path_list.append(file_path)\n",
    "            try:\n",
    "                text_temp, table_temp = extract_pdf_content(file_path)\n",
    "            except Exception:\n",
    "                print('此pdf无法读取')\n",
    "                text_temp, table_temp = [], []\n",
    "            text_list.append(text_temp)\n",
    "            table_list.append(table_temp)\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df['sample_id'] = id_list\n",
    "    df['file_path'] = file_path_list\n",
    "    df['text'] = text_list\n",
    "    df['tabel'] = table_list\n",
    "    df = df.sort_values('sample_id')\n",
    "    return df\n",
    "\n",
    "# 文件处理太慢，可持续化保存文件\n",
    "train_path = 'datasets/train.csv'\n",
    "if os.path.exists(train_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "else:\n",
    "    train_df = get_dir_file('datasets/train_data/')\n",
    "    train_df.to_csv(train_path,index=False)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "\n",
    "test_path =  'datasets/test.csv'\n",
    "if os.path.exists(test_path):\n",
    "    test_df = pd.read_csv(test_path)\n",
    "else:\n",
    "    test_df = get_dir_file('datasets/test_data/')\n",
    "    test_df.to_csv(test_path,index=False)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "train_outputs.head(2)\n",
    "train_df.head(2)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造训练集验证集\n",
    "train_df = train_df.sample(frac=1, random_state=1017)\n",
    "\n",
    "val_df = train_df[:1800]\n",
    "# val_df = train_df[:1800].head(20)\n",
    "train_df = train_df[1800:]\n",
    "# test_df=test_df.head(20)\n",
    "\n",
    "train_outputs[\"sample_id\"]=train_outputs[\"sample_id\"].astype(str)\n",
    "val_df[\"sample_id\"]=val_df[\"sample_id\"].astype(str)\n",
    "train_df[\"sample_id\"]=train_df[\"sample_id\"].astype(str)\n",
    "# test_df[\"sample_id\"]=test_df[\"sample_id\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有效文本挖掘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:00<00:00, 2140.31it/s]\nSeries([], Name: text, dtype: object)\nSeries([], Name: text, dtype: object)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5883333333333334"
     },
     "metadata": {},
     "execution_count": 15
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:00<00:00, 2441.53it/s]\n100%|██████████| 8660/8660 [00:02<00:00, 3037.53it/s]\n"
    }
   ],
   "source": [
    "# 首先针对任务抽取时间（每个时间跟每个id是一一对应的）\n",
    "# 要不是取第一个时间，要不就是取最后一个时间（或者时间加一）这里可以建立一个模型预测\n",
    "# base这里面直接取最后一个时间作为发布日期\n",
    "\n",
    "##wjc字典里添加了十\n",
    "CN_NUM = {\n",
    "    u'月十日':'月10日',u'十月':'10月', u'十日': '0日',u'二十':'二',u'三十':'三', u'十': 1, u'○': 0, u'O':'0', u'Ο':'0',\n",
    "    u'〇': 0, u'一': 1, u'二': 2, u'三': 3,\n",
    "    u'四': 4, u'五': 5, u'六': 6, u'七': 7,\n",
    "    u'八': 8, u'九': 9, u'零': 0, u'壹': 1,\n",
    "    u'贰': 2, u'叁': 3, u'肆': 4, u'伍': 5,\n",
    "    u'陆': 6, u'柒': 7, u'捌': 8, u'玖': 9,\n",
    "    u'貮': 2, u'两': 2,  \n",
    "}\n",
    "######### u'○': 0, u'O':'0', u'Ο':'0',##########可删除这些字典，改用添加内容效果一致，这里暂且保留字典\n",
    "\n",
    "\n",
    "def get_put_time_from_text(row):\n",
    "    row = row.replace(' ', '').replace('\\\\n', '')\n",
    "\n",
    "    ############添加#################改善年份中0有多个不识别的问题########\n",
    "    start=1\n",
    "    for word in '一二三四五六七八九':   \n",
    "        row=re.sub('二.一'+word,'201'+str(start),row)\n",
    "        start=start+1\n",
    "    ########添加############慢#######################\n",
    "\n",
    "    for key in CN_NUM:\n",
    "        row = row.replace(key, str(CN_NUM[key]))   \n",
    "\n",
    "    r = row.replace(\"年\", \"-\").replace(\"月\", \"-\").replace(\"日\", \" \").replace(\"/\", \"-\").strip()\n",
    "    regex = \"(\\d{4}-\\d{1,2}-\\d{1,2})\"\n",
    "    r = re.findall(regex, r)\n",
    "    if len(r)==0:\n",
    "        return np.nan\n",
    "    time_str = r[-1]\n",
    "    first = time_str.split('-')[0]\n",
    "    second = time_str.split('-')[1]\n",
    "    last = time_str.split('-')[-1]\n",
    "    second = str.zfill(second, 2)\n",
    "    last = str.zfill(last, 2)\n",
    "    r = '-'.join([first, second, last])\n",
    "    return r\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_result = pd.DataFrame()\n",
    "val_result['sample_id'] = val_df['sample_id']\n",
    "val_result['predict_time'] = val_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "test_gg = train_outputs.groupby('sample_id').apply(lambda row:list(row['公告日期'])[0]).reset_index()\n",
    "test_gg.columns = ['sample_id', 'time']\n",
    "val_result = pd.merge(val_result, test_gg, on='sample_id', how='left')\n",
    "##val_result['time'].head(10)\n",
    "###val_result['predict_time'].head(10)\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "testid=6375\n",
    "print(train_df[train_df.sample_id==testid]['text'].astype(str))\n",
    "print(val_df[val_df.sample_id==testid]['text'].astype(str))\n",
    "\n",
    "\n",
    "# 对于每一行，通过列名name访问对应的元素\n",
    "for index,row in val_result.iterrows():\n",
    "    #type(row['predict_time'])\n",
    "    #print(row['sample_id'],row['predict_time']) # 输出每一行\n",
    "    try:\n",
    "        val_result.at[index,'predict_time1']=datetime.strptime(row['predict_time'], \"%Y-%m-%d\").strftime('%Y/%m/%d')\n",
    "        #val_result.at[index,'predict_time1']=time.strptime(row['predict_time'], \"%Y-%m-%d\")\n",
    "    except:\n",
    "        #val_result.at[index,'predict_time1']='1900/01/01'\n",
    "        continue\n",
    "        # print(row['sample_id'])\n",
    "        # print(val_df[val_df.sample_id==row['sample_id']]['text'].astype(str))\n",
    "        \n",
    "for index,row in val_result.iterrows():\n",
    "    val_result.at[index,'time1']=val_result.at[index,'time'].strftime(\"%Y-%m-%d %H:%M:%S\")[0:10]\n",
    "    val_result.at[index,'time2']=val_result.at[index,'time1'].replace('-','')\n",
    "    try:\n",
    "        val_result.at[index,'predict_time2']=val_result.at[index,'predict_time'].replace('-','')\n",
    "    except:\n",
    "        continue\n",
    "    #######粗计算时间具体误差################\n",
    "    val_result.at[index,'差值']=(int)(val_result.at[index,'predict_time2'])-(int)(val_result.at[index,'time2'])\n",
    "\n",
    "fail_val_result=val_result[val_result['差值']!=0]\n",
    "#######抽取错误列放入fail的dataframe########################\n",
    "\n",
    "\n",
    "# val_result['predict_time_inf']=pd.to_datetime(val_result['predict_time'],format='%Y/%m/%d')\n",
    "# val_result['predict_time_inf'].head(10)\n",
    "\n",
    "#val_result['predict_time1'] = datetime.strptime(val_result['predict_time'], \"%Y-%m-%d\").strftime('%Y/%m/%d')\n",
    "#val_result['predict_time_inf']=pd.to_datetime(val_result['predict_time1'],format='%Y/%m/%d')\n",
    "#val_result['日期差值']=val_result['predict_time_inf']-val_result['time']\n",
    "#val_result.head(10)\n",
    "\n",
    "# 判断验证集的准确率\n",
    "np.sum(val_result['predict_time'].astype(str) == val_result['time'].astype(str))/len(val_result)\n",
    "\n",
    "# val_time = val_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "# test_time = test_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "\n",
    "val_time=pd.DataFrame()\n",
    "val_time[\"公告日期\"]=val_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "# val_gm = val_df.progress_apply(lambda row:my_get_gm(row['text']), axis=1)\n",
    "val_time['sample_id'] = val_df['sample_id']\n",
    "#test_gm = test_df.progress_apply(lambda row:get_gm(row['text']), axis=1)\n",
    "\n",
    "test_time=pd.DataFrame()\n",
    "test_time[\"公告日期\"]=test_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "# val_gm = val_df.progress_apply(lambda row:my_get_gm(row['text']), axis=1)\n",
    "test_time['sample_id'] = test_df['sample_id']\n",
    "#test_gm = test_df.progress_apply(lambda row:get_gm(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:02<00:00, 681.04it/s]\n100%|██████████| 8660/8660 [00:08<00:00, 1067.16it/s]\n100%|██████████| 1800/1800 [00:03<00:00, 580.46it/s]\nSeries([], Name: text, dtype: object)\nSeries([], Name: text, dtype: object)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7972222222222223"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# 抽取购买公司\n",
    "# 前几句话出现\n",
    "# 将其按照\\\\n 和空格切割\n",
    "def get_gm(row):\n",
    "    row=row.replace('[','').replace(']','').replace('\\'','')    ######粗datawash,去除部分典型符号###########\n",
    "    #head_row=re.split('资金',row)[0]\n",
    "    #head_row=re.split('使用',head_row)[0]\n",
    "    #tag_head_row=headrow.replace('[\\\\\\\\n ]','$|$')\n",
    "    result = re.split('[\\\\\\\\n ]',row)\n",
    "    for i in result:\n",
    "        if '公司' in i:\n",
    "            i=i.replace('（','(').replace('）',')') ##########修改中文括号#################\n",
    "            regex=\"(^.*公司)\"##################此四行为添加的##############################\n",
    "            i=re.findall(regex, i)###########取此行最后一个“公司”前的字符#######\n",
    "            i=i[0]###############格式转换，list取出str####################################\n",
    "            if i=='公司':\n",
    "                continue   ###########跳过字段为公司的答案进入下一个循环#####################\n",
    "            return i\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################粗改进######################################\n",
    "def my_get_gm(row):\n",
    "    row=row.replace('[','').replace(']','').replace('\\'','')    ######粗datawash,去除部分典型符号###########\n",
    "    re_row = re.split('[\\\\\\\\n ]',row)\n",
    "    \n",
    "    ##################取第一次出现公司的行开始计算###################\n",
    "    for i in re_row:\n",
    "        if '公司' not in i:\n",
    "            re_row.remove(i)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    head_row=\"\"\n",
    "    #################list替换为文本##########################\n",
    "    for i in re_row:\n",
    "        head_row=head_row+i+'$|$'\n",
    "    \n",
    "    \n",
    "\n",
    "    # print(type(head_row.find(\"公告编号\")))\n",
    "    # head_row=head_row[head_row.find(\"公告编号\"):-1]\n",
    "\n",
    "    # head_row=head_row.split(\"^.*公告编号：\")[0]\n",
    "    # head_row_a=head_row.split(\"资金\")[0]\n",
    "    # head_row=head_row_a.split(\"使用\")[0]\n",
    "    # head_row=head_row_a.split(\"委托\")[0]\n",
    "    # head_row=head_row_a.split(\"董事\")[0]\n",
    "    head_row=head_row.split(\"理财\")[0].split(\"资金\")[0].split(\"使用\")[0].split(\"董事\")[0]\n",
    "    # print(head_row_a)\n",
    "    tag_head_row=head_row.replace(' ','').replace('子公司','$|$').replace('公司','公司$|$').replace('关于','$|$').replace('-','$|$')\n",
    "    # spl_head_row = re.split('\\$\\|\\$',tag_head_row)\n",
    "    spl_head_row = tag_head_row.split('$|$')\n",
    "    spl_head_row.reverse()\n",
    "    result=spl_head_row\n",
    "    for i in result:\n",
    "        if '公司' in i:\n",
    "            i=i.replace('（','(').replace('）',')') ##########修改中文括号#################\n",
    "            regex=\"(^.*公司)\"##################此四行为添加的##############################\n",
    "            i=re.findall(regex, i)###########取此行最后一个“公司”前的字符#######\n",
    "            i=i[0]###############格式转换，list取出str####################################\n",
    "            if i=='公司' or len(i)<=4 or '”' in i or '“' in i or '简称' in i:\n",
    "                continue   ###########跳过字段为公司的答案进入下一个循环#####################\n",
    "            return i\n",
    "#################到此为止####################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################二次改进,文本内容查找追加，成功率暂时比不追加要低一点######################################\n",
    "def my_get_gm2(row):\n",
    "    row=row.replace('[','').replace(']','').replace('\\'','')    ######粗datawash,去除部分典型符号###########\n",
    "    re_row = re.split('[\\\\\\\\n ]',row)\n",
    "    \n",
    "    ###################取第一次出现公司的行开始计算###################\n",
    "    for i in re_row:\n",
    "        if '公司' not in i:\n",
    "            re_row.remove(i)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    head_row=\"\"\n",
    "    #################list替换为文本##########################\n",
    "    for i in re_row:\n",
    "        head_row=head_row+i+'$|$'\n",
    "    \n",
    "    #################去除标题#############################\n",
    "    text_row1=head_row[head_row.find(\"公告\"):-1]\n",
    "    text_row2=head_row[head_row.find(\"意见\"):-1]\n",
    "    regex = \"(子公司.*公司.*购买)\"\n",
    "    text1 = re.findall(regex, text_row1)\n",
    "    text2 = re.findall(regex, text_row2)\n",
    "    text=text1+text2\n",
    "    for i in text:\n",
    "        if '$|$' in i:\n",
    "            text.remove(i)\n",
    "    my_list=[]\n",
    "    for i in text:\n",
    "        spl_i=i.replace(\"购买\",\"$|$\").replace(\"子公司\",\"$|$\").replace(\"公司\",\"公司$|$\")\n",
    "        spl_i=spl_i.split(\"$|$\")\n",
    "        spl_i.reverse()\n",
    "        for j in spl_i:\n",
    "            if '公司' in j:\n",
    "                j=j.replace('（','(').replace('）',')')\n",
    "                regex=\"(^.*公司)\"\n",
    "                j=re.findall(regex, j)\n",
    "                j=j[0]\n",
    "                if j=='公司' or len(j)<=4 or len(j)>30 or '”' in j or '“' in j or '简称' in j:\n",
    "                    continue\n",
    "                my_list.append(j)\n",
    "    #print(text1)\n",
    "\n",
    "    \n",
    "    \n",
    "    head_row=head_row.split(\"理财\")[0].split(\"资金\")[0].split(\"使用\")[0].split(\"董事\")[0]\n",
    "    # print(head_row_a)\n",
    "    tag_head_row=head_row.replace(' ','').replace('子公司','$|$').replace('公司','公司$|$').replace('关于','$|$').replace('-','$|$')\n",
    "    # spl_head_row = re.split('\\$\\|\\$',tag_head_row)\n",
    "    spl_head_row = tag_head_row.split('$|$')\n",
    "    spl_head_row.reverse()\n",
    "    result=spl_head_row\n",
    "    for i in result:\n",
    "        if '公司' in i:\n",
    "            i=i.replace('（','(').replace('）',')') ##########修改中文括号#################\n",
    "            regex=\"(^.*公司)\"##################此四行为添加的##############################\n",
    "            i=re.findall(regex, i)###########取此行最后一个“公司”前的字符#######\n",
    "            i=i[0]###############格式转换，list取出str####################################\n",
    "            if i=='公司' or len(i)<=4 or '”' in i or '“' in i or '简称' in i:\n",
    "                continue   ###########跳过字段为公司的答案进入下一个循环#####################\n",
    "            my_list.insert(0,i)\n",
    "            i=my_list[-1]\n",
    "            return i\n",
    "#################到此为止####################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###val_gm = val_df.progress_apply(lambda row:get_gm(row['text']), axis=1)\n",
    "val_gm=pd.DataFrame()\n",
    "val_gm[\"实际购买公司名称\"]=val_df.progress_apply(lambda row:my_get_gm(row['text']), axis=1)\n",
    "# val_gm = val_df.progress_apply(lambda row:my_get_gm(row['text']), axis=1)\n",
    "val_gm['sample_id'] = val_df['sample_id']\n",
    "#test_gm = test_df.progress_apply(lambda row:get_gm(row['text']), axis=1)\n",
    "\n",
    "test_gm=pd.DataFrame()\n",
    "test_gm[\"实际购买公司名称\"] = test_df.progress_apply(lambda row:my_get_gm(row['text']), axis=1)\n",
    "test_gm['sample_id']=test_df['sample_id']\n",
    "\n",
    "\n",
    "my_val_result = pd.DataFrame()\n",
    "my_val_result['sample_id'] = val_df['sample_id']\n",
    "my_val_result['predict_gs'] = val_df.progress_apply(lambda row: my_get_gm(row['text']), axis=1)\n",
    "my_test_gs = train_outputs.groupby('sample_id').apply(lambda row:list(row['实际购买公司名称'])[0]).reset_index()\n",
    "my_test_gs.columns = ['sample_id', 'gs']\n",
    "my_val_result = pd.merge(my_val_result, my_test_gs, on='sample_id', how='left')\n",
    "my_val_result['是否相等']=my_val_result['predict_gs']==my_val_result['gs']\n",
    "fail_my_val_result=my_val_result[my_val_result['是否相等']!=True]\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "testid=3597\n",
    "print(train_df[train_df.sample_id==testid]['text'].astype(str))\n",
    "print(val_df[val_df.sample_id==testid]['text'].astype(str))\n",
    "\n",
    "# 判断验证集的准确率\n",
    "np.sum(my_val_result['predict_gs'].astype(str) == my_val_result['gs'].astype(str))/len(my_val_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:41<00:00, 43.16it/s]\n100%|██████████| 7217/7217 [02:29<00:00, 48.23it/s]\n"
    }
   ],
   "source": [
    "#text=text.replace(r'[ ]+',' ').replace('\\r','^')\n",
    "def get_title(text):\n",
    "    global title_num_char\n",
    "    title_list=[]\n",
    "    title_type_list=[]\n",
    "    text_start_iter_list=[]\n",
    "    text_end_iter_list=[]\n",
    " \n",
    "    for item in title_num_char:\n",
    "        pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5 ()\\[\\]（）【】：:]*?[\\^]\")\n",
    "        #pattern = re.compile(item+r\"[ ]*?[^ ]+?[ ]\")\n",
    "        #pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5 ()[]（）【】][]\")#*?[\\^]\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(1)\n",
    "            text_end_iter_list.append(i.span(0)[1])\n",
    "\n",
    "    # for item in title_list:\n",
    "    for item in s_title_num_char:\n",
    "        # pattern = re.compile(item+r\"[ ]*?[ ]*?[\\d][^ ]+?:?[ ]?\") \n",
    "        # pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5\\^ ]*\")\n",
    "        # pattern = re.compile(item+'[0-9\\u4e00-\\u9fa5()[]（）【】*?[\\^]]')*?[\\^]\n",
    "    #    pattern = re.compile(item+r\"[\\d]*?\\u4e00-\\u9fa5+[ ]\")\n",
    "        pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5 ()\\[\\]（）【】：:]*?[ ][\\^]\")\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(1)\n",
    "            text_end_iter_list.append(i.span(0)[1])\n",
    "\n",
    "    title_list.append(\"引言\")\n",
    "    title_type_list.append(1)\n",
    "    text_start_iter_list.append(0)\n",
    "    text_end_iter_list.append(0)\n",
    "\n",
    "    result_df=pd.DataFrame([title_list,title_type_list,text_start_iter_list,text_end_iter_list]).T.sort_values(by=2).reset_index(drop=True)\n",
    "    # print(result_df)\n",
    "    return result_df\n",
    "\n",
    "def get_title_text(text,title_df):\n",
    "    # print(title_df)\n",
    "    title_1_df=title_df[title_df[1]==1]\n",
    "    text_iter_list=[]\n",
    "    text_list=[]\n",
    "    # print(title_1_df)\n",
    "    for iter1,iter2 in title_1_df[[2,3]].values:\n",
    "        # print(iter1)\n",
    "        if(len(text_iter_list)!=0):\n",
    "            text_iter_list.append(iter1)\n",
    "        text_iter_list.append(iter2)\n",
    "    # text_iter_list.append(text_iter_list[len(text_iter_list)-1])\n",
    "    text_iter_list.append(len(text))\n",
    "    for index in range(int(len(text_iter_list)/2)):\n",
    "        text_list.append(text[text_iter_list[2*index]:text_iter_list[2*index+1]])\n",
    "    \n",
    "    title_1_df[4]=text_list\n",
    "\n",
    "    return title_1_df.reset_index(drop=True)\n",
    "\n",
    "#from fuzzywuzzy import fuzz\n",
    "def judge_title(sample_id=0,text=r\"test\\n\"):\n",
    "    # print(text)\n",
    "    text=text.replace(r\"\\n\",\"^\").replace(r'[ ]+',' ')\n",
    "    title_df=get_title(text)\n",
    "    title_df[\"sample_id\"]=[sample_id for x in range(title_df.shape[0])]\n",
    "    # print(title_df)`\n",
    "    title_1_df=get_title_text(text,title_df)[[\"sample_id\",0,1,2,3,4]]\n",
    "\n",
    "    \n",
    "\n",
    "    global val_df\n",
    "    global train_outputs\n",
    "    val_true_name=train_outputs[train_outputs[\"sample_id\"]==sample_id][\"理财产品名称\"]\n",
    "    \n",
    "    index=0\n",
    "    neg_index=[]\n",
    "    for title_des in title_1_df[0].values:\n",
    "        for item in title_neg_words:\n",
    "            if re.search(item,title_des) is not None:\n",
    "                neg_index.append(index)\n",
    "                break\n",
    "        index+=1\n",
    "\n",
    "\n",
    "    return title_1_df.drop(neg_index)\n",
    "    # print(title_list)\n",
    "\n",
    "def get_judge_title_result(val_df):\n",
    "\n",
    "    judge_title_result=None\n",
    "\n",
    "\n",
    "    for sample_id,text in tqdm(val_df[[\"sample_id\",\"text\"]].values):\n",
    "        # print(sample_id)\n",
    "        # print(text)\n",
    "        judge_title_result= judge_title(sample_id,text) if judge_title_result is None else pd.concat([judge_title_result,judge_title(sample_id,text)])\n",
    "\n",
    "        judge_title_result[\"sample_id\"]=judge_title_result[\"sample_id\"].astype(str)        \n",
    "    return judge_title_result\n",
    "\n",
    "title_num_char=[\"一、\",\"二、\",\"三、\",\"四、\",\"五、\",\"六、\",\"七、\",\"八、\",\"九、\",\"十、\",\"十一、\",\"十二、\",\"十三、\",\"十四、\",\"十五、\"]\n",
    "s_title_num_char=[\"（一）\",\"（二）\",\"（三）\",\"（四）\",\"（五）\",\"（六）\",\"（七）\",\"（八）\",\"（九）\",\"（十）\",\"（十一）\",\"（十二）\",\"（十三）\",\"（十四）\",\"（十五）\"]\n",
    "s_title_num_char.extend([\"[(]一[)]\",\"[(]二[)]\",\"[(]三[)]\",\"[(]四[)]\",\"[(]五[)]\",\"[(]六[)]\",\"[(]七[)]\",\"[(]八[)]\",\"[(]九[)]\",\"[(]十[)]\",\"[(]十一[)]\",\"[(]十二[)]\",\"[(]十三[)]\",\"[(]十四[)]\",\"[(]十五[)]\"])\n",
    "\n",
    "title_pos_words=[]\n",
    "title_neg_words=[]\n",
    "title_neg_words=[\"备查\",\"日前\",\"过去\",\"履行\",\"审批\",\"程序\",\"风险\",\"措施\",\"影响\",\"累计\",\"赎回\",\"到期[^日].*[^2][^0]\",\"到期.{0,2}[/^]\",\"截至\",\"意见\",\"十二个月内\",\"公告前\",\"报备文件\",\"前期\"]\n",
    "\n",
    "val_judge_title_result=get_judge_title_result(val_df)\n",
    "train_judge_title_result=get_judge_title_result(train_df)\n",
    "# test_judge_title_result=get_judge_title_result(test_df)\n",
    "# judge_title_result.to_excel(\"训练集段落标题分类结果.xlsx\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:12<00:00, 147.52it/s]\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_judge_title_result' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-275d19fd7573>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mval_content_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_content_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_judge_title_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mtrain_content_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_content_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_judge_title_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mtest_content_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_content_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_judge_title_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_judge_title_result' is not defined"
     ]
    }
   ],
   "source": [
    "###9月11日\n",
    "#val_judge_title_result.head(100)\n",
    "def get_content_df(val_judge_title_result):\n",
    "    sample_id=val_judge_title_result['sample_id'].drop_duplicates() \n",
    "    text_list=[]\n",
    "    text_sampleid_list=[]\n",
    "    content_df=pd.DataFrame()\n",
    "    for i in tqdm(sample_id):\n",
    "        text_df=val_judge_title_result[val_judge_title_result['sample_id']==i]\n",
    "    #  text_df.iloc[0,5]\n",
    "        #text_df\n",
    "        n=len(text_df)\n",
    "        text_sampleid_list.append(i)\n",
    "        text=''\n",
    "        for y in range(0,n):\n",
    "            text=text+text_df.iloc[y,1]+text_df.iloc[y,5]\n",
    "            text=re.sub(\"[ ]+\",\" \",text).replace(\"（\",\"(\").replace(\"）\",\")\")\n",
    "        #text\n",
    "        text_list.append(text)\n",
    "    content_df[\"sample_id\"]=text_sampleid_list\n",
    "    content_df[\"text\"]=text_list\n",
    "    return content_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "val_content_df=get_content_df(val_judge_title_result)\n",
    "train_content_df=get_content_df(train_judge_title_result)\n",
    "test_content_df=get_content_df(test_judge_title_result)\n",
    "\n",
    "val_content_df=pd.merge(val_content_df,val_df[[\"sample_id\",\"tabel\"]],on=\"sample_id\")\n",
    "# train_content_df=pd.merge(train_content_df,train_df[[\"sample_id\",\"tabel\"]],on=\"sample_id\")\n",
    "# test_content_df=pd.merge(test_content_df,test_df[[\"sample_id\",\"tabel\"]],on=\"sample_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名称提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######计算文本位置长度#############\n",
    "def len_count(my_list,my_str):\n",
    "    my_len=0\n",
    "    for i in my_list:\n",
    "        my_len=my_len+len(i)\n",
    "    my_len=my_len+(len(my_list)-1)*len(my_str)\n",
    "    return my_len\n",
    "\n",
    "\n",
    "######基于冒号做文本拼接与分割####效果优\n",
    "def maohao_cat(text):\n",
    "    text=text.replace(r\"\\n\",\"^\")\n",
    "    text=text.replace(r\"', '\",\"^\")\n",
    "    text=text.replace(' ','')\n",
    "    text=text.replace('（','(').replace('）',')').replace('；','^')     ###############;直接去掉,有极个别答案(答案中出现了引号)将会收到负反馈，多数正反馈\n",
    "    text=re.sub('\\^[1-9]\\^','^',text)\n",
    "    text=re.sub('\\^\\-[1-9]\\-\\^','^',text)\n",
    "    text=re.sub(\"[（][^）]*?[\\^]*$\",'',text)\n",
    "    text=re.sub('[，]*$','',text)\n",
    "    pos_word=[\"名称\",\"期限\",\"年\",\"月\",\"日\",\"时间\",\"产品\",\"资金\",\"金额\",\"天\",\"来源\",\"总额\",\"类型\",\"元\",\"关系\",\"无关\",\"不存在关\"]\n",
    "    if '^' not in text:\n",
    "        return \n",
    "    my_list=text.split(\"^\")\n",
    "    my_str=''\n",
    "    str_list=[]\n",
    "    # for i in my_list:\n",
    "    #     if \"：\" not in i and \":\" not in i and \"无关\" not in i and \"不存在关\" not in i and \"名称\" not in my_str:\n",
    "    #         my_str=my_str+i\n",
    "    #         # if len(i)<=6:\n",
    "    #         #     str_list.append(my_str)      #############解决最后一行被后函数因字数过长舍弃的办法\n",
    "    #         #     continue\n",
    "    #     else:\n",
    "    #         str_list.append(my_str)\n",
    "    #         my_str=i\n",
    "    \n",
    "    for i in my_list:\n",
    "        if \"：\" not in i and \":\" not in i and len(re.sub('[^\\u4e00-\\u9fa5]*','',i))<5:\n",
    "            my_str=my_str+i\n",
    "            # if \"不存在关\" in my_str:\n",
    "            #     str_list.append(my_str)\n",
    "            #     my_str=''\n",
    "            # if len(i)<=6:\n",
    "            #     str_list.append(my_str)      #############解决最后一行被后函数因字数过长舍弃的办法\n",
    "            #     continue\n",
    "        else:\n",
    "            str_list.append(my_str)\n",
    "            my_str=i\n",
    "    \n",
    "    str_list.append(my_str)\n",
    "    # print(my_list)\n",
    "    # print('-----')\n",
    "    # print(str_list)\n",
    "    # print('-----')\n",
    "    cat_text=''\n",
    "    # print(str_list)\n",
    "    for i in str_list:\n",
    "        cat_text=cat_text+i+r'^'\n",
    "        # print(cat_text)\n",
    "    # print(cat_text.replace(r'^','\\n'))\n",
    "    return cat_text\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######寻找文本中的答案##############\n",
    "####以如下及冒号行做切片#############\n",
    "def wjc_spl(text):\n",
    "    spl1=[]      ###如下切片\n",
    "    maohao=3  ####设定冒号出现次数阈值\n",
    "    zishu=30   ####设定单行冒号后字数阈值\n",
    "    my_str=\"\"\n",
    "    text=maohao_cat(text)    #########调用函数做text正规化\n",
    "    spl2=[]      ###行切片\n",
    "    spl3=[]\n",
    "    neg_word=[]\n",
    "    pos_word=[\"名称\",\"期限\",\"年\",\"月\",\"日\",\"时间\",\"产品\",\"资金\",\"金额\",\"天\",\"来源\",\"总额\",\"类型\",\"元\",\"关系\",\"额\",\"金\",\"受托\",\"签约银行\"]\n",
    "    # pos_word=[\"名称\"]\n",
    "    # print(len(text))\n",
    "    if text==None:\n",
    "        return -1,-1,-1\n",
    "    text=text.replace(r\"\\n\",\"^\")\n",
    "    # print(len(text))\n",
    "    text=text.replace(r\"', '\",\"^\")    ######解决换页符被置为', '的问题\n",
    "    # print(len(text))\n",
    "    text=text.replace(' ','')\n",
    "    text=text.replace('（','(').replace('）',')').replace(':','：').replace('如^下：','如下：').replace('如下^：','如下：')\n",
    "    # print(len(text))\n",
    "    # print(text[:10000])\n",
    "    if \"如下：\" not in text:\n",
    "        return -1,-1,-1\n",
    "    else:\n",
    "        move=[]\n",
    "        spl1=text.split(\"如下：\")   #####首次切割####\n",
    "        # print(len_count(spl1,'如下：'))\n",
    "        # print(len(spl1[0])+len(spl1[1]))\n",
    "        my_len=len(spl1[0])+len('如下：')\n",
    "        spl1=spl1[1:]              ######第一次如下前的内容不关心##########\n",
    "        len_list=[]\n",
    "        tag1=[]\n",
    "        # print(spl1)\n",
    "        for i in spl1:\n",
    "            len_list.append(len(i))\n",
    "            if i.count(\"：\")<=maohao:\n",
    "                # print('aaaaaaa',len(len_list))\n",
    "                tag1.append(len(len_list))\n",
    "                move.append(i)\n",
    "        # move=list(set(move))\n",
    "        for x in move:\n",
    "            # print('pppppppppppppppppppppppppppp')\n",
    "            # print(x)\n",
    "            spl1.remove(x)    ####去除冒号过少的部分切片\n",
    "                \n",
    "        # print(my_len+0)\n",
    "        # print(spl1)\n",
    "        for i in spl1:\n",
    "            test=i.split('^')\n",
    "            #print(test[10])\n",
    "            for j in test:\n",
    "                spl2.append(j)\n",
    "            \n",
    "        # print(spl2[100])\n",
    "        move=[]\n",
    "        for i in spl2:\n",
    "            #print(i)\n",
    "            if i.count(\"：\")!=1 and i.count(\":\")!=1:\n",
    "                # print(i.count(\"：\"))\n",
    "                move.append(i)    ####以行做切片，去除单行里非只有一个冒号的行\n",
    "        for x in move:\n",
    "            # print(x)\n",
    "            spl2.remove(x)\n",
    "        # print(spl2[0])\n",
    "        move=[]\n",
    "        for i in spl2:\n",
    "            judge1=re.sub('[a-zA-Z]','',i.split(\"：\")[-1])\n",
    "            judge1=re.sub(r\"\\d\",'',judge1)\n",
    "            judge1=re.sub(r'”','',judge1)\n",
    "            judge1=re.sub(r'“','',judge1)\n",
    "            judge1=re.sub(r'（','',judge1)\n",
    "            judge1=re.sub(r'）','',judge1)\n",
    "            # print(len(judge1))\n",
    "            if len(judge1)>=zishu or len(judge1)<1:     #######去除冒号后关心字段所提中文内容过长或过短的行\n",
    "                move.append(i)\n",
    "                # print(i)\n",
    "        for x in move:\n",
    "            # print(x)\n",
    "            spl2.remove(x)\n",
    "        # print(spl2)\n",
    "        move=[]\n",
    "        # print(spl2)\n",
    "        # print('-----------')\n",
    "\n",
    "        # print(spl2)\n",
    "        if spl2==[]:\n",
    "            # print('该文本变量做行切片结果为空')\n",
    "            return -1,-1,-1\n",
    "\n",
    "        for i in spl2:\n",
    "            x=0\n",
    "            for j in pos_word:\n",
    "                judge2=i.split(\"：\")[0]      ########舍弃冒号前（分类字段）不包含pos_word的行\n",
    "                if j not in judge2:\n",
    "                    x=x+1\n",
    "                if x==len(pos_word):\n",
    "                    # print(i)\n",
    "                    move.append(i)\n",
    "            new_move=list(set(move))\n",
    "            # print(new_move)\n",
    "        for x in new_move:\n",
    "            # print(x)\n",
    "            spl2.remove(x)\n",
    "            \n",
    "        # print(spl2)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    tag1=0\n",
    "    key_pos_word=['名称']                 ############计算一个pdf生成的dataframe一共需要几行，及每行需要多少列###########\n",
    "    x=1\n",
    "    ele_times=[]\n",
    "    judge3=0\n",
    "    for i in spl2:\n",
    "        for j in key_pos_word:\n",
    "            if j not in i:\n",
    "                x=x+1                     ############若不含名称字段则结果会是实际+1###############\n",
    "            else:\n",
    "                ele_times.append(x)\n",
    "                x=1\n",
    "    \n",
    "            # print(i)\n",
    "            # print(x)\n",
    "    ele_times.append(x)\n",
    "\n",
    "    \n",
    "    # print(ele_times)\n",
    "    if len(ele_times)>1:\n",
    "        mo_times=ele_times[0]+ele_times[-1]-1\n",
    "        # print(type(mo_times))\n",
    "        ele_times=ele_times[1:-1]\n",
    "        ele_times.append(mo_times)\n",
    "    else:\n",
    "        test=0\n",
    "        # print(len(spl2))\n",
    "        # print(ele_times[0])\n",
    "        if len(ele_times)==1 and ele_times[0]==len(spl2)+1:\n",
    "            # print(\"不含名称字段\")                              ##############此处需处理，或者返回一个标记以后处理  冒号行不包含名称字段的情况\n",
    "            tag1=1\n",
    "    \n",
    "\n",
    "    ele_times1=ele_times\n",
    "    # print(ele_times)\n",
    "    # print(type(ele_times))\n",
    "\n",
    "    tag2=0\n",
    "    key_pos_word=['金额']                 ############计算一个pdf生成的dataframe一共需要几行，及每行需要多少列###########\n",
    "    x=1\n",
    "    ele_times=[]\n",
    "    judge3=0\n",
    "    for i in spl2:\n",
    "        for j in key_pos_word:\n",
    "            if j not in i:\n",
    "                x=x+1                     ############若不含金额字段则结果会是实际+1###############\n",
    "            else:\n",
    "                ele_times.append(x)\n",
    "                x=1\n",
    "    \n",
    "            # print(i)\n",
    "            # print(x)\n",
    "    ele_times.append(x)\n",
    "    # print(ele_times)\n",
    "    if len(ele_times)>1:\n",
    "        mo_times=ele_times[0]+ele_times[-1]-1\n",
    "        # print(type(mo_times))\n",
    "        ele_times=ele_times[1:-1]\n",
    "        ele_times.append(mo_times)\n",
    "    else:\n",
    "        test=0\n",
    "        # print(len(spl2))\n",
    "        # print(ele_times[0])\n",
    "        if len(ele_times)==1 and ele_times[0]==len(spl2)+1:\n",
    "            # print(\"不含金额字段\")                              ##############此处需处理，或者返回一个标记以后处理  冒号行不包含金额字段的情况\n",
    "            tag2=1\n",
    "    \n",
    "    ele_times2=ele_times\n",
    "    # print(ele_times2)\n",
    "\n",
    "    # print('---')\n",
    "\n",
    "    \n",
    "\n",
    "    if len(spl2)<=2:\n",
    "        return -1,-1,-1\n",
    "\n",
    "    \n",
    "\n",
    "    # print(ele_times2)\n",
    "    # if len(spl2)==1 and spl2[0]=='':\n",
    "    #     return\n",
    "    # if len(spl2)==1:\n",
    "    #     spl2[0].replace(' ','')\n",
    "   \n",
    "    return spl2,ele_times1,tag1     ######仅返回“关心”的行切片    #############注意返回变量可能造成函数无法执行\n",
    "\n",
    "\n",
    "\n",
    "def cut_list(text):\n",
    "    spl2,ele_times1,tag1=wjc_spl(text)\n",
    "    # print(spl2)\n",
    "    # print(ele_times1)\n",
    "    # print(tag1)\n",
    "    my_list=[]\n",
    "    if tag1==0:\n",
    "        for i in ele_times1:\n",
    "            # print(i)\n",
    "            get=spl2[0:i]\n",
    "            my_list.append(get)\n",
    "            spl2=spl2[i:]\n",
    "    else:\n",
    "        return 0\n",
    "    # print(my_list)\n",
    "    return my_list\n",
    "\n",
    "\n",
    "\n",
    "def get_mc(text):\n",
    "    # my_list=cut_list(text)\n",
    "    mc_list=[]\n",
    "    my_list=cut_list(text)\n",
    "    if my_list==0:\n",
    "        return \n",
    "    else:\n",
    "        my_list=cut_list(text)\n",
    "\n",
    "        for i in my_list:\n",
    "            this_str=i[0]\n",
    "            if \"名\" not in this_str or \"受托方\" in this_str or \"公司名称\" in this_str:\n",
    "                continue\n",
    "            index=this_str.index(\"：\")\n",
    "            this_str=this_str[index+1:].replace('。','').replace('；','').replace(';','').replace('、','')\n",
    "            mc_list.append(this_str)\n",
    "            # print(mc_list)\n",
    "    if mc_list ==[]:\n",
    "        return\n",
    "    return mc_list\n",
    "\n",
    "\n",
    "\n",
    "def spl2_iswm(text):\n",
    "    spl2,ele_times1,tag1=wjc_spl(text)\n",
    "    # print(spl2)\n",
    "    # print(ele_times1)\n",
    "    # print(tag1)\n",
    "    my_list=[]\n",
    "    if tag1==1:\n",
    "        return \"无名称\"\n",
    "    else:\n",
    "        return \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 位置定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到关键字在文本中的位置\n",
    "def find_pos_in_text(text, keys, sample_id = 0):\n",
    "    ret = []\n",
    "\n",
    "    if not keys or len(keys) == 0 or not text:\n",
    "        return None\n",
    "\n",
    "    textWithArrow = re.sub(' +', ' ', text).replace(r'\\n', '^').replace(' ', '^')\n",
    "    textWithoutWhite = textWithArrow.replace('^', '')\n",
    "\n",
    "    # 每个非空词的前缀空格个数\n",
    "    seq, totalSpace = 0, 0\n",
    "    preleadingSpaceDict = collections.defaultdict(int)\n",
    "    for i in range(len(textWithArrow)):\n",
    "        if (textWithArrow[i]) == '^':\n",
    "            totalSpace += 1\n",
    "            preleadingSpaceDict[seq] = totalSpace\n",
    "        else:\n",
    "            preleadingSpaceDict[seq] = totalSpace\n",
    "            seq += 1        \n",
    "\n",
    "    for key in keys:\n",
    "        nkey = str(key).replace('(', r'\\(').replace(')', r'\\)').replace('[', r'\\[').replace(']', r'\\]')\n",
    "        for it in re.finditer(nkey, textWithoutWhite):\n",
    "            ret.append([key, it.span()[0]+preleadingSpaceDict[it.span()[0]], \\\n",
    "                it.span()[1]+preleadingSpaceDict[it.span()[1]], sample_id])\n",
    "\n",
    "    if not len(ret):\n",
    "        return None\n",
    "\n",
    "    ret.sort(key = lambda x: x[1])\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理财名称提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [01:16<00:00, 23.46it/s]\n"
    }
   ],
   "source": [
    "def get_product_text(val_content_df):\n",
    "    result_df=None\n",
    "    for sample_id,text in tqdm(val_content_df[[\"sample_id\",\"text\"]].values):\n",
    "        mc_list=get_mc(text)\n",
    "        if mc_list is not None:\n",
    "            mc_list=list(set(mc_list))\n",
    "            # print(mc_list)\n",
    "        # print(\"-----------\")\n",
    "        # sample_id\n",
    "        tmp_df=pd.DataFrame(find_pos_in_text(text,mc_list),columns=[0,1,2,3])\n",
    "        tmp_df[[0,1,2,3]]=tmp_df[[0,3,1,2]]\n",
    "        tmp_df[1]=1\n",
    "        tmp_df[3]=tmp_df[2]\n",
    "        tmp_df[\"sample_id\"]=sample_id\n",
    "        result_df=get_title_text(text,tmp_df) if result_df is None else pd.concat([result_df,get_title_text(text,tmp_df)])\n",
    "    return result_df.reset_index(drop=True)\n",
    "    \n",
    "val_product_text=get_product_text(val_content_df)\n",
    "train_product_text=get_product_text(train_content_df)\n",
    "test_product_text=get_product_text(test_content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.34086359736917354"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "  def get_F1(val_pred, val_true):\n",
    "      val_pred = list(val_pred)\n",
    "      val_true = list(val_true)\n",
    "      curr = list(set(val_pred).intersection(set(val_true)))\n",
    "      R = len(curr)/len(val_true)\n",
    "      P = len(curr)/len(val_pred)\n",
    "      return 2*P*R/(P+R)\n",
    "\n",
    "  r = pd.merge(val_df[['sample_id']], train_outputs, on='sample_id', how='left')\n",
    "  val_true = r['sample_id'].astype(str) + r['理财产品名称'].astype(str)\n",
    "    # r.to_excel(\"result_after_drop.xlsx\",index=None)\n",
    "  r=val_product_text.drop_duplicates(subset=[\"sanple_id\",0])\n",
    "\n",
    "  val_pred = r['sanple_id'].astype(str) + r[0].astype(str)\n",
    "  score = get_F1(val_pred, val_true)\n",
    "  score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'1837', '9967', '3622', '3982', '5288', '5614', '9329', '125', '3327', '5227', '2430', '2547', '7465', '185', '1328', '5107', '1852', '3993', '11025', '1009', '7203', '10803', '8099', '3979', '9399', '3319', '10446', '7617', '5126', '4185', '9129', '3052', '10031', '2549', '1713', '1238', '10120', '5592', '6486', '5128', '4107', '5447', '1464', '2410', '1234', '1832', '6492', '7751', '7124', '3245', '8404', '5575', '8115', '8618', '7152', '953', '1789', '7505', '5116', '6697', '10122', '4522', '1783', '1172', '7748', '10121', '7175', '1982', '4972', '6842', '5596', '5135', '6706', '1755', '7600', '3605', '4275', '3983', '4420', '5226', '3989', '3604', '3089', '10105', '3945', '3961', '7204', '10974', '3247', '10177', '1631', '1070', '4261', '3974', '4202', '6840', '7618', '10460', '7182', '4406', '10131', '2565', '9652', '6966', '5891', '9330', '6684', '1606', '6863', '9369', '9143', '6780', '1814', '9181', '1810', '5173', '4147', '8525', '7880', '10183', '8441', '7149', '5188', '10456', '1821', '5613', '10174', '1799', '3114', '7591', '5223', '10777', '1677', '4568', '7753', '1255', '1245', '6215', '9318', '1123', '1914', '3243', '8281', '8927', '7593', '10106', '4160', '5398', '4526', '1592', '10115', '4187', '1638', '9216', '4521', '5071', '9634', '1825', '9210', '10020', '1655', '9219', '4127', '1815', '3987', '5006', '930', '10137', '1743', '7354', '9345', '5205', '5402', '1752', '7343', '10034', '5151', '5220', '8986', '2777', '184', '1779', '4504', '6207', '8381', '5098', '1561', '2537', '9214', '8951', '5190', '4988', '9444', '8992', '10027', '7405', '8612', '6431', '4571', '1775', '3599', '1312', '3624', '2412', '1488', '5092', '9992', '3967', '3988', '6439', '8477', '5579', '10412', '1868', '10208', '5622', '10454', '4170', '7278', '9547', '5240', '6843', '3997', '2533', '1566', '3249', '8519', '7210', '1584', '10021', '1709', '2654', '3761', '5085', '10217', '10453', '4969', '3200', '4980', '5097', '5250', '1647', '8422', '3242', '4552', '6386', '2390', '4546', '9639', '4174', '2498', '7197', '6700', '4631', '1244', '5252', '8408', '1242', '9635', '2566', '2557', '2778', '3417', '3969', '4106', '4639', '1803', '3603', '3581', '5396', '1959', '963', '1219', '4564', '1656', '5903', '7252', '8438', '3618', '7832', '1653', '943', '1984', '6113', '2949', '7263', '4057', '10933', '4549', '5110', '2880', '7740', '5130', '1806', '4525', '2414', '3415', '2744', '8620', '4120', '8973', '1226', '4989', '9366', '5175', '2457', '1202', '7264', '4139', '2090', '2779', '8631', '6389', '10789', '3087', '8126', '8392', '9833', '7828', '4255', '2474', '6563', '3043', '2765', '2782', '5192', '1769', '1249', '1215', '3084', '8437', '9334', '6029', '4993', '7202', '5583', '4188', '4172', '9706', '960', '2946', '9430', '10017', '1952', '1642', '1167', '5150', '5438', '6837', '7199', '1361', '3626', '8439', '10459', '1867', '959', '10796', '3236', '10176', '5202', '1675', '5154', '3606', '10793', '9131', '1222', '11113', '3600', '7882', '9363', '2405', '1173', '5008', '3589', '954', '5587', '8985', '9328', '41', '6471', '1757', '2424', '3773', '10423', '35', '3097', '5153', '1844', '2083', '2527', '118', '3777', '11039', '4171', '9642', '5419', '5277', '8116', '4538', '4151', '2668', '4165', '8430', '4533', '3111', '1781', '4266', '5104', '4210', '9541', '1574', '10188', '5598', '8967'}\n"
    }
   ],
   "source": [
    "a=val_product_text.drop_duplicates(subset=[\"sanple_id\",0])\n",
    "\n",
    "b=\"lhl\\验证集row数量对比.xlsx\"\n",
    "b=pd.read_excel(b).reset_index(drop=True)\n",
    "b[\"sample_id\"]=b[\"sample_id\"].astype(str)\n",
    "b=b[b[\"实际\"]<=4]\n",
    "a=set(list(pd.merge(a,b,left_on=\"sanple_id\",right_on=\"sample_id\")[\"sample_id\"].values))\n",
    "b=set(list(b[\"sample_id\"].values))\n",
    "print(b.difference(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理财名称所属文本提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理财信息字段提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                              text_1 label_1\n0                 中银保本理财-人民币按期开放理财产品    理财产品\n1                 中银保本理财-人民币按期开放理财产品    理财产品\n2                        与利率挂钩的结构性产品    理财产品\n3             广发银行“薪加薪”16号XJXCKJ2578    理财产品\n4       兴业银行“金雪球-优悦”保本开放式人民币理财产品(2M)    理财产品\n...                              ...     ...\n185903                  上海浦兴投资发展有限公司      其它\n185904                  上海浦兴投资发展有限公司      其它\n185905                  上海浦兴投资发展有限公司      其它\n185906                  上海浦兴投资发展有限公司      其它\n185907             上海市浦东新区建设(集团)有限公司      其它\n\n[185908 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_1</th>\n      <th>label_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>中银保本理财-人民币按期开放理财产品</td>\n      <td>理财产品</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>中银保本理财-人民币按期开放理财产品</td>\n      <td>理财产品</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>与利率挂钩的结构性产品</td>\n      <td>理财产品</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>广发银行“薪加薪”16号XJXCKJ2578</td>\n      <td>理财产品</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>兴业银行“金雪球-优悦”保本开放式人民币理财产品(2M)</td>\n      <td>理财产品</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>185903</th>\n      <td>上海浦兴投资发展有限公司</td>\n      <td>其它</td>\n    </tr>\n    <tr>\n      <th>185904</th>\n      <td>上海浦兴投资发展有限公司</td>\n      <td>其它</td>\n    </tr>\n    <tr>\n      <th>185905</th>\n      <td>上海浦兴投资发展有限公司</td>\n      <td>其它</td>\n    </tr>\n    <tr>\n      <th>185906</th>\n      <td>上海浦兴投资发展有限公司</td>\n      <td>其它</td>\n    </tr>\n    <tr>\n      <th>185907</th>\n      <td>上海市浦东新区建设(集团)有限公司</td>\n      <td>其它</td>\n    </tr>\n  </tbody>\n</table>\n<p>185908 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Building prefix dict from the default dictionary ...\nLoading model from cache C:\\Users\\lsqlh\\AppData\\Local\\Temp\\jieba.cache\nLoading model cost 1.910 seconds.\nPrefix dict has been built successfully.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tgrocery.Grocery at 0x1e133b82be0>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# 最后一部分字段采用预测好的部分，跟提取的text做交互采用双输入lstm在dense层做交互预测最后几个字段\n",
    "\n",
    "# train_lstm_input = pd.merge(train_df, train_outputs, on='sample_id', how='left')\n",
    "# result_matrix\n",
    "from tgrocery import Grocery\n",
    "train_lstm_input = pd.merge(train_df, train_outputs, on='sample_id', how='left')\n",
    "\n",
    "train_lstm_input = train_lstm_input.fillna('否')\n",
    "\n",
    "# label_1理财类型-10  label_2资金来源-3 label_3实际购买公司和上市公司关系-3 label_4买卖方是否有关联关系-2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_1 = LabelEncoder()\n",
    "# label_2 = LabelEncoder()\n",
    "# label_3 = LabelEncoder()\n",
    "# label_4 = LabelEncoder()\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "tmp=pd.DataFrame()\n",
    "train_data['text_1'] = train_lstm_input['理财产品名称'].astype(str) \n",
    "\n",
    "# train_data['text_1'] = train_lstm_input['理财产品名称'].astype(str) + '_' + train_lstm_input['产品发行方名称'].astype(str)\n",
    "\n",
    "# train_data['text_2'] = train_lstm_input['text'].astype(str)\n",
    "\n",
    "# train_lstm_input[\"文本类别\"]=\"理财产品\"\n",
    "\n",
    "train_data['label_1'] = \"理财产品\"\n",
    "\n",
    "\n",
    "train_data2=train_lstm_input[train_lstm_input[\"产品发行方名称\"]!=\"否\"].reset_index(drop=True)\n",
    "\n",
    "# train_data2[\"文本类别\"]=\"发行方\"\n",
    "\n",
    "tmp['text_1']=train_data2[\"产品发行方名称\"].astype(str)\n",
    "\n",
    "# tmp['text_2']= train_data2[\"text\"].astype(str)\n",
    "\n",
    "tmp['label_1']=\"发行方\"\n",
    "\n",
    "train_data = pd.concat([train_data,tmp]).reset_index(drop=True)\n",
    "\n",
    "# train_data2=train_lstm_input[train_lstm_input[\"实际购买公司名称\"]!=\"否\"].reset_index(drop=True)\n",
    "\n",
    "# # train_data2[\"文本类别\"]=\"发行方\"\n",
    "\n",
    "# tmp['text_1']=train_data2[\"实际购买公司名称\"].astype(str)\n",
    "\n",
    "# # tmp['text_2']= train_data2[\"text\"].astype(str)\n",
    "\n",
    "# tmp['label_1']=\"购买公司\"\n",
    "\n",
    "# train_data = pd.concat([train_data,tmp]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "other_columns_list=[\"认购金额(万元)\",\"认购日期\",\"资金来源\",\"实际购买公司和上市公司关系\",\"实际购买公司名称\"]\n",
    "\n",
    "for item in other_columns_list:\n",
    "\n",
    "    train_lstm_input[item]=train_lstm_input[item].astype(str)\n",
    "    train_data2=train_lstm_input[train_lstm_input[item]!=\"否\"].reset_index(drop=True)\n",
    "\n",
    "    # train_data2[\"文本类别\"]=item\n",
    "\n",
    "    tmp['text_1']=train_data2[item].astype(str)\n",
    "\n",
    "    # tmp['text_2']= train_data2[\"text\"].astype(str)\n",
    "\n",
    "    tmp['label_1']=\"其它\"\n",
    "\n",
    "    \n",
    "    train_data = pd.concat([train_data,tmp]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# train_data['label_2'] = label_2.fit_transform(train_lstm_input['资金来源'])\n",
    "# train_data['label_3'] = label_3.fit_transform(train_lstm_input['实际购买公司和上市公司关系'])\n",
    "# train_data['label_4'] = label_4.fit_transform(train_lstm_input['买卖方是否有关联关系'])\n",
    "train_data\n",
    "\n",
    "train_src=[]\n",
    "for text,label in train_data[[\"text_1\",\"label_1\"]].values:\n",
    "    train_src.append([label,text])\n",
    "\n",
    "\n",
    "grocery=Grocery(\"productOrcounter\")\n",
    "\n",
    "\n",
    "grocery.train(train_src)\n",
    "\n",
    "grocery.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'理财产品': 0.5882297461996445,\n '发行方': 0.22094697741834643,\n '其它': -0.809176723618003}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "grocery.predict(\"浦发银行利多多\").dec_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理财信息字段整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from src.time_extractor import TimeFinder\n",
    "import datetime\n",
    "\n",
    "data_file=pl.Path(r\"D:\\Work\\数据挖掘\\baseline_青青草原我的家\\2_test_result.csv\")\n",
    "\n",
    "data_df=pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=data_df[[\"sample_id\",\"理财产品名称\",\"时间\",\"认购金额\",\"产品发行方名称\",\"实际购买公司名称\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 3734/3734 [00:42<00:00, 87.70it/s]\n"
    }
   ],
   "source": [
    "\n",
    "result_dict={}\n",
    "result_dict[\"sample_id\"]=[]\n",
    "result_dict[\"columns\"]=[]\n",
    "result_dict[\"product_df\"]=[]\n",
    "for sample_id in tqdm(data_df[\"sample_id\"].unique()):\n",
    "    results_df=None\n",
    "    tmp_df=data_df[data_df[\"sample_id\"]==sample_id][[\"理财产品名称\",\"时间\",\"认购金额\",\"产品发行方名称\",\"实际购买公司名称\"]]\n",
    "    table_column=pd.DataFrame(list(tmp_df.columns)).T.reset_index(drop=True).loc[0]\n",
    "    product_df=pd.DataFrame()\n",
    "    product_df[[0,1,2,3,4]]=tmp_df\n",
    "    product_df[0]=product_df[0].astype(str)\n",
    "    product_df[1]=product_df[1].astype(str)\n",
    "    product_df[2]=product_df[2].astype(str)\n",
    "    product_df[3]=product_df[3].astype(str)\n",
    "    product_df[4]=product_df[4].astype(str)\n",
    "    results_df = product_df if results_df is None else pd.concat([results_df,product_df])\n",
    "    result_dict[\"sample_id\"].append(sample_id)\n",
    "    result_dict[\"columns\"].append(table_column)\n",
    "    result_dict[\"product_df\"].append(results_df)\n",
    "\n",
    "result_dict=pd.DataFrame(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 3734/3734 [06:48<00:00,  9.13it/s]\n"
    }
   ],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    " \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def judge_type(columns):\n",
    "    type_index=[]#1:产品名,2:金额,3:发行方，4:期限\n",
    "    columns=columns.map(lambda x:x.replace(\"（\",\"(\").replace(\"）\",\")\"))\n",
    "    product_name_pos_words=[\"产品名称\",\"产品名册\",\"产品名\",\"理财产品\",\"项目名\",\"回购名\",\"回购品\",\"标的名\",\"金融产\",\"投资项\"]#\"存款种类\",\"基金类型\"#不能为空\n",
    "    # product_name_neg_words=[\"编号\",\"代码\"]\n",
    "    amt_pos_words=[\"存款金\",\"认购金\",\"投资金\",\"投入金\",\"受托金\",\"理财金\",\"金额\",\"（元\",\"(元\",\"(万元\",\"（万元\",\"(亿元\",\"（亿元\",\"人民币\",\"投资规\",\"认购规\",\"存款规\",\"投入规\",\"理财规\"]\n",
    "    counter_name_pos_words=[\"受托方\",\"银行机\",\"机构名\",\"合作方名\",\"合作银\",\"合作机\",\"受托人\",\"发行主\",\"签约方\",\"协议方\",\"受托机\",\"受托银\",\"认购银\",\"签约银\",\"签约机\",\"协议机\",\"发生主\",\"存放银\",\"存款银\",\"存款机\",\"存放机\",\"购买银\",\"购买机\",\"管理人\",\"管理银\",\"管理机\",\"银行名\",\"发行机\",\"发行主\",\"发行人\",\"对手方\",\"开户银\",\"开户行\",\"开户机\"]#可以为空\n",
    "    time_length_pos_words=[\"期限\",\"(天)\",\"持有时间\"]\n",
    "    for words in product_name_pos_words:\n",
    "        judge_flag=[]\n",
    "        columns.map(lambda x:judge_flag.append(fuzz.partial_ratio(words,x)==100))\n",
    "        # columns.map(lambda x:judge_flag.append(fuzz.partial_ratio(words,x)==0))\n",
    "        if True in judge_flag:\n",
    "            type_index.append(judge_flag.index(True))\n",
    "            break\n",
    "    if(len(type_index)==0):\n",
    "        for words in [\"种类\",\"类型\",\"类别\"]:\n",
    "            judge_flag=[]\n",
    "            columns.map(lambda x:judge_flag.append(fuzz.partial_ratio(words,x)==100))\n",
    "            # columns.map(lambda x:judge_flag.append(fuzz.partial_ratio(words,x)==0))\n",
    "            if True  in judge_flag:\n",
    "                type_index.append(judge_flag.index(True))\n",
    "                break\n",
    "        if(len(type_index)==0):\n",
    "            type_index.append(-1)\n",
    "        \n",
    "\n",
    "    for words in amt_pos_words:\n",
    "        judge_flag=[]\n",
    "        columns.map(lambda x:judge_flag.append(fuzz.partial_ratio(words,x)==100))\n",
    "        if True  in judge_flag:\n",
    "            type_index.append(judge_flag.index(True))\n",
    "            break\n",
    "    if(len(type_index)==1):\n",
    "        type_index.append(-1)\n",
    "    \n",
    "    for words in counter_name_pos_words:\n",
    "        judge_flag=[]\n",
    "        columns.map(lambda x:judge_flag.append(fuzz.partial_ratio(words,x)==100))\n",
    "        if True  in judge_flag:\n",
    "            type_index.append(judge_flag.index(True))\n",
    "            break\n",
    "    if(len(type_index)==2):\n",
    "        type_index.append(-1)\n",
    "    \n",
    "    for words in time_length_pos_words:\n",
    "        judge_flag=[]\n",
    "        columns.map(lambda x:judge_flag.append(fuzz.partial_ratio(words,x)==100))\n",
    "        if True  in judge_flag:\n",
    "            type_index.append(judge_flag.index(True))\n",
    "            break\n",
    "    if(len(type_index)==3):\n",
    "        type_index.append(-1)\n",
    "    \n",
    "    \n",
    "    return type_index\n",
    "def get_answer_matrix(result_matrix,sample_id=None):\n",
    "\n",
    "    temp_single={}\n",
    "    temp_single['认购日期'] = []\n",
    "    temp_single['产品起息日'] = []\n",
    "    temp_single['产品到息日'] = []\n",
    "    temp_single['产品期限'] = []\n",
    "    temp_single['认购金额(万元)'] = []\n",
    "    temp_single['产品发行方名称'] = []\n",
    "    temp_single['理财产品名称'] = []\n",
    "    temp_single['sample_id'] = []\n",
    "\n",
    "    temp_single[\"实际购买公司名称\"]=[]\n",
    "    \n",
    "\n",
    "    if(sample_id is not None):\n",
    "        result_matrix=result_matrix[result_matrix[\"sample_id\"]==sample_id]\n",
    "    for sample_id,columns,product_df in tqdm(result_matrix[[\"sample_id\",\"columns\",\"product_df\"]].values):\n",
    "        \n",
    "        type_index=judge_type(columns)\n",
    "        # product_df\n",
    "        # columns\n",
    "        # type_index\n",
    "        for index in product_df.index:\n",
    "            tmp_df=product_df.loc[index]\n",
    "            if(len(tmp_df.shape) ==2 ):\n",
    "                tmp_df=tmp_df.reset_index(drop=True).loc[0]\n",
    "            product_name=\"\"\n",
    "            amt=\"\"\n",
    "            counter_name=\"\"\n",
    "            pur_dt=\"\"\n",
    "            val_dt=\"\"\n",
    "            coupon_dt=\"\"\n",
    "            time_limit=\"\"\n",
    "            #产品名\n",
    "            if(type_index[0]!=-1):\n",
    "                if (str(grocery.predict(tmp_df.loc[type_index[0]])) == \"理财产品\"):\n",
    "                    product_name=tmp_df.loc[type_index[0]]\n",
    "            else:\n",
    "                candidate_list={}\n",
    "                candidate_list[\"理财产品\"]=[]\n",
    "                candidate_list[\"发行方\"]=[]\n",
    "                candidate_list[\"其它\"]=[]\n",
    "                candidate_list[\"购买公司\"]=[]\n",
    "                for each_word in tmp_df.head(1):\n",
    "                    if not (is_number(each_word)):\n",
    "                        candidate_list[str(grocery.predict(each_word))].append(each_word)\n",
    "                if(len(candidate_list[\"理财产品\"])!=0):\n",
    "                    product_name=candidate_list[\"理财产品\"][0]\n",
    "            #金额\n",
    "            if(type_index[1]!=-1):\n",
    "                amt=tmp_df.loc[type_index[1]].replace(\"（\",\"\").replace(\"）\",\"\").replace(\"(\",\"\").replace(\"(\",\"\").replace(\"元\",\"\").replace(\"圆\",\"\")\n",
    "                type_amt=0\n",
    "                if(\"万\" in amt or \"万\" in columns.loc[type_index[1]]):\n",
    "                    type_amt=1\n",
    "                if(\"亿\" in amt or \"亿\" in columns.loc[type_index[1]]):\n",
    "                    type_amt=2\n",
    "                amt=re.sub(\"[^0-9.]\",\"\",amt)\n",
    "                amt=re.sub(\"[^0-9.]\",\"\",amt)\n",
    "                if(is_number(amt)):\n",
    "                    amt=float(amt)\n",
    "                    if(type_amt==0 and amt/10000 >float(50)):\n",
    "                        amt/=10000\n",
    "                    if(type_amt==2):\n",
    "                        amt*=10000\n",
    "                # print(amt)\n",
    "            else:\n",
    "                candidate_list=[]\n",
    "                value_list=list(tmp_df)\n",
    "                for item in value_list:\n",
    "                    tmp=str(item).replace(\"（\",\"\").replace(\"）\",\"\").replace(\"(\",\"\").replace(\"(\",\"\").replace(\"元\",\"\").replace(\"圆\",\"\").replace(\"亿\",\"\").replace(\"万\",\"\")\n",
    "                    tmp=re.sub(\"[^0-9.]*额[^0-9.]*\",\"\",tmp)\n",
    "                    tmp=re.sub(\"[^0-9.]*币[^0-9.]*\",\"\",tmp)\n",
    "                    if(is_number(tmp)):\n",
    "                        candidate_list.append(float(tmp))\n",
    "\n",
    "                if len(candidate_list)>0:\n",
    "                    real_tmp=sorted(candidate_list,reverse=True)[0]\n",
    "\n",
    "                    for item in value_list:\n",
    "                        tmp=str(item)\n",
    "                        tmp=re.sub(\"[^0-9.]*额[^0-9.]*\",\"\",tmp)\n",
    "                        tmp=re.sub(\"[^0-9.]*币[^0-9.]*\",\"\",tmp)\n",
    "                        if(is_number(tmp) and float(tmp)==real_tmp):\n",
    "                            amt=item\n",
    "                            type_amt=0\n",
    "                        else:\n",
    "                            continue\n",
    "                        if(\"万\" in amt ):\n",
    "                            type_amt=1\n",
    "                        if(\"亿\" in amt ):\n",
    "                            type_amt=2\n",
    "                        amt=re.sub(\"[^0-9.]\",\"\",amt)\n",
    "                        if(is_number(amt)):\n",
    "                            amt=float(amt)\n",
    "                            # print(amt)\n",
    "                            if(type_amt==0 and amt/10000 >float(50)):\n",
    "                                amt/=10000\n",
    "                            if(type_amt==2):\n",
    "                                amt*=10000\n",
    "                        if(amt !=\"\" or amt!=np.nan):\n",
    "                            break\n",
    "            #发行方\n",
    "            if(type_index[2]!=-1):\n",
    "                if (str(grocery.predict(tmp_df.loc[type_index[2]])) == \"发行方\"):\n",
    "                    counter_name=tmp_df.loc[type_index[2]]\n",
    "            else:\n",
    "                candidate_list={}\n",
    "                candidate_list[\"理财产品\"]=[]\n",
    "                candidate_list[\"发行方\"]=[]\n",
    "                candidate_list[\"其它\"]=[]\n",
    "                candidate_list[\"购买公司\"]=[]\n",
    "                for each_word in tmp_df:\n",
    "                    if not (is_number(each_word)):\n",
    "                        each_word=each_word.replace(\"^\",\"\").replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                        candidate_list[str(grocery.predict(each_word))].append(each_word)\n",
    "                # print(candidate_list)\n",
    "                if(len(candidate_list[\"发行方\"])!=0):\n",
    "                    counter_name=sorted(candidate_list[\"发行方\"],reverse=True)[0]\n",
    "            \n",
    "            #期限\n",
    "            if(type_index[3]!=-1):\n",
    "                text=str(tmp_df.loc[type_index[3]])\n",
    "                # print(text)\n",
    "                a=re.search(\"\\d+?[天]+?\",text)\n",
    "                if (a is None):\n",
    "                    a=re.search(\"\\d+?[个]+[月]+?\",text)\n",
    "                if a is None:\n",
    "                    a=re.search(\"[^\\d]\\d[年]+?\",text)\n",
    "                    if(a is not None):\n",
    "                        a=re.search(\"\\d[年]+?\",a.group())\n",
    "                if a is None:\n",
    "                    a=re.search(\"^\\d[年]+?\",text)\n",
    "                if a is not None:\n",
    "                    time_limit=a.group().replace(\"（\",\"\").replace(\"）\",\"\").replace(\"(\",\"\").replace(\"(\",\"\")\n",
    "                else:\n",
    "                    if(is_number(text) and type(text) is not float):\n",
    "                        time_limit=str(text)+\"天\"\n",
    "                        # print(time_limit)\n",
    "                    else:\n",
    "                        time_limit=\"\"\n",
    "\n",
    "            #三个日期\n",
    "            # tmp_df\n",
    "            value_list=[]\n",
    "            noshow=tmp_df.map(lambda x:value_list.append(str(x)))\n",
    "            sum_value=(\" and \").join(i for i in value_list)\n",
    "            t = TimeFinder()\n",
    "            time_all = t.find_time(sum_value)\n",
    "            # print(time_all)\n",
    "            if(time_all is not None):\n",
    "                time_all=sorted(list(set(time_all)),reverse=True)\n",
    "                # print(len(time_all))\n",
    "                # print(sum_value)\n",
    "                # print(product_name)\n",
    "                if(len(time_all)==1):\n",
    "                    pur_dt=time_all[0]\n",
    "                    val_dt=pur_dt\n",
    "                elif(len(time_all)==2):\n",
    "                    # time_all=sorted(list(set(time_all)),reverse=True)\n",
    "                    if(re.search(\"随时\",sum_value) is not None or re.search(\"工作日\",sum_value)):\n",
    "                        time_limit=\"\"\n",
    "                        pur_dt=time_all[1]\n",
    "                        val_dt=time_all[0]\n",
    "                        coupon_dt = \"\"\n",
    "                    else:\n",
    "                        pur_dt=time_all[1]\n",
    "                        val_dt=time_all[1]\n",
    "                        coupon_dt = time_all[0]\n",
    "                        try:\n",
    "                            # 相减\n",
    "                            if(type_index[3]==-1 or time_limit==\"\"):\n",
    "                                d1 = datetime.datetime.strptime(val_dt, '%Y-%m-%d')\n",
    "                                d2 = datetime.datetime.strptime(coupon_dt, '%Y-%m-%d')\n",
    "                                d = d2 - d1\n",
    "                                time_limit = str(d.days) + '天'\n",
    "                        except Exception:\n",
    "                            coupon_dt = \"\"\n",
    "                            time_limit = \"\"\n",
    "                elif(len(time_all)==3):\n",
    "                        # print(time_all)\n",
    "                        pur_dt=time_all[2]\n",
    "                        val_dt=time_all[1]\n",
    "                        coupon_dt = time_all[0]\n",
    "                        try:\n",
    "                            # 相减\n",
    "                            d1 = datetime.datetime.strptime(pur_dt, '%Y-%m-%d')\n",
    "                            d2 = datetime.datetime.strptime(val_dt, '%Y-%m-%d')\n",
    "                            d = d2 - d1\n",
    "                            if str(d.days)==\"1\":\n",
    "                                d1 = datetime.datetime.strptime(val_dt, '%Y-%m-%d')\n",
    "                                d2 = datetime.datetime.strptime(coupon_dt, '%Y-%m-%d')\n",
    "                                d = d2 - d1\n",
    "                                time_limit=str(d.days)+\"天\"\n",
    "                            else:\n",
    "                                pur_dt=time_all[2]\n",
    "                                val_dt=pur_dt\n",
    "                                coupon_dt=\"\"\n",
    "                        except Exception:\n",
    "                            coupon_dt = \"\"\n",
    "                            time_limit = \"\"\n",
    "                elif(len(time_all)>4):\n",
    "                        time_all=sorted(time_all)\n",
    "                        pur_dt=time_all[0]\n",
    "                        val_dt=\"\"\n",
    "                        coupon_dt=\"\"\n",
    "                if pur_dt!=\"\" and coupon_dt==\"\" and time_limit!=\"\":\n",
    "                    try:\n",
    "                        coupon_dt=datetime.datetime.strftime(datetime.datetime.strptime(pur_dt, '%Y-%m-%d')+datetime.timedelta(days=int(re.search(\"\\d*\",time_limit).group())), '%Y-%m-%d')\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            temp_single['认购日期'].append(pur_dt)\n",
    "            temp_single['产品起息日'].append(val_dt)\n",
    "            temp_single['产品到息日'].append(coupon_dt)\n",
    "            temp_single['产品期限'] .append(time_limit)\n",
    "            temp_single['认购金额(万元)'].append(amt)\n",
    "            temp_single['产品发行方名称'] .append(counter_name.replace(\" \",\"\"))\n",
    "            temp_single['理财产品名称'] .append(product_name)\n",
    "            temp_single['sample_id'].append(sample_id)\n",
    "\n",
    "            temp_single[\"实际购买公司名称\"].append(tmp_df[4])\n",
    "        \n",
    "    temp_single=pd.DataFrame(temp_single)\n",
    "    return temp_single\n",
    "\n",
    "val_temp_single=get_answer_matrix(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_temp_single.to_excel(\"val_text_result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.06003647075326134"
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "  def get_F1(val_pred, val_true):\n",
    "      val_pred = list(val_pred)\n",
    "      val_true = list(val_true)\n",
    "      curr = list(set(val_pred).intersection(set(val_true)))\n",
    "      R = len(curr)/len(val_true)\n",
    "      P = len(curr)/len(val_pred)\n",
    "      return 2*P*R/(P+R)\n",
    "\n",
    "r = pd.merge(val_df[['sample_id']], train_outputs, on='sample_id', how='left')\n",
    "val_true = r['sample_id'].astype(str) + r['理财产品名称'].astype(str) + r['认购金额(万元)'].astype(str)+ r['认购日期'].astype(str) + r['产品起息日'].astype(str)+ r['产品到息日'].astype(str)+ r['产品期限'].astype(str)+r['产品发行方名称'].astype(str)+r[\"实际购买公司名称\"].astype(str)\n",
    "# r.to_excel(\"result_after_drop.xlsx\",index=None)\n",
    "  \n",
    "r=val_temp_single\n",
    "\n",
    "\n",
    "val_pred = r['sample_id'].astype(str) + r['理财产品名称'].astype(str) + r['认购金额(万元)'].astype(str) + r['认购日期'].astype(str) + r['产品起息日'].astype(str)+ r['产品到息日'].astype(str) + r['产品期限'].astype(str)+r['产品发行方名称'].astype(str)+r[\"实际购买公司\"].astype(str)\n",
    "score = get_F1(val_pred, val_true)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5016, 8)"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "r[r[\"认购金额(万元)\"]==\"\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(judge_title_result,time_list,gm_list,result_matrix):\n",
    "    # tmp_result=pd.merge(time_list,gm_list,on=[\"sample_id\"])\n",
    "    # tmp_result[\"sample_id\"]=tmp_rersult[\"sample_id\"].astype(str)\n",
    "    r=result_matrix.fillna(\"\").reset_index(drop=True)\n",
    "    i=0\n",
    "    i_list=[]\n",
    "    r[\"sample_id\"]=r[\"sample_id\"].astype(str)\n",
    "    result=pd.merge(time_list,r,on=[\"sample_id\"]).reset_index(drop=True)\n",
    "    for index in r.index:\n",
    "        if r.loc[index].dropna().shape[0]<=5 or type(r.loc[index][\"理财产品名称\"]) is float or len(r.loc[index][\"理财产品名称\"])<2:\n",
    "            i_list.append(i)\n",
    "        i+=1\n",
    "    r=r.drop(i_list)\n",
    "    r=r.fillna(\"\").applymap(lambda x:str(x).replace(\" \",\"\"))\n",
    "    # r=drop_judge(judge_title_result,r)\n",
    "\n",
    "\n",
    "    \n",
    "    return result\n",
    "val_temp_single[\"sample_id\"]=val_temp_single[\"sample_id\"].astype(str)\n",
    "test_time[\"sample_id\"]=test_time[\"sample_id\"].astype(str)\n",
    "val_result=get_result(None,test_time,test_gm,val_temp_single)\n",
    "# test_result=get_result(None,test_time,test_gm,test_temp_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            公告日期 sample_id        认购日期       产品起息日       产品到息日  产品期限 认购金额(万元)  \\\n0     2016-10-27     11190  2016-10-26  2016-10-26                      24000   \n1     2016-07-28     11191  2016-06-28  2016-06-28                       1000   \n2     2016-07-28     11191  2016-07-01  2016-07-01                      11500   \n3     2016-07-28     11191  2016-07-27  2016-07-27                       1000   \n4     2016-07-28     11191  2016-07-27  2016-07-27  2016-08-24   28天      500   \n...          ...       ...         ...         ...         ...   ...      ...   \n5364  2016-03-02     22363  2015-10-26  2015-10-26                        600   \n5365  2016-03-02     22363  2016-03-02  2016-03-02  2016-06-08   98天     1000   \n5366  2018-08-21     22365  2018-08-17  2018-08-17  2019-02-15    2天    10000   \n5367  2017-02-06     22369  2017-02-04  2017-02-04  2017-03-03   27天     5500   \n5368  2018-05-04     22370                                      nan天    10000   \n\n               产品发行方名称                 理财产品名称        实际购买公司名称  \n0               中国工商银行        无固定期限超短期人民币理财产品  北京京西文化旅游股份有限公司  \n1               中国建设银行      中国建设银行乾元-日鑫月溢理财产品  北京京西文化旅游股份有限公司  \n2                 包商银行      包商银行企业鑫喜16005理财产品  北京京西文化旅游股份有限公司  \n3                 南京银行  “珠联璧合安享系列-季安享”人民币理财产品  北京京西文化旅游股份有限公司  \n4                 交通银行   “蕴通财富·稳得利”28天周期型理财产品  北京京西文化旅游股份有限公司  \n...                ...                    ...             ...  \n5364                         交通银行“蕴通财富•日增利S款”  南京全信传输科技股份有限公司  \n5365              南京银行       南京银行“珠联璧合-季稳鑫1号”  南京全信传输科技股份有限公司  \n5366        盛京银行大连星海支行  盛京银行单位结构性存款2018年第106期  大连派思燃气系统股份有限公司  \n5367        兴业银行股份有限公司    “兴业金雪球—优先2号”人民币理财产品   安徽安德利百货股份有限公司  \n5368  中国建设银行股份有限公司南平分行                  结构性存款  福建南平太阳电缆股份有限公司  \n\n[5369 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>公告日期</th>\n      <th>sample_id</th>\n      <th>认购日期</th>\n      <th>产品起息日</th>\n      <th>产品到息日</th>\n      <th>产品期限</th>\n      <th>认购金额(万元)</th>\n      <th>产品发行方名称</th>\n      <th>理财产品名称</th>\n      <th>实际购买公司名称</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-10-27</td>\n      <td>11190</td>\n      <td>2016-10-26</td>\n      <td>2016-10-26</td>\n      <td></td>\n      <td></td>\n      <td>24000</td>\n      <td>中国工商银行</td>\n      <td>无固定期限超短期人民币理财产品</td>\n      <td>北京京西文化旅游股份有限公司</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-07-28</td>\n      <td>11191</td>\n      <td>2016-06-28</td>\n      <td>2016-06-28</td>\n      <td></td>\n      <td></td>\n      <td>1000</td>\n      <td>中国建设银行</td>\n      <td>中国建设银行乾元-日鑫月溢理财产品</td>\n      <td>北京京西文化旅游股份有限公司</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-07-28</td>\n      <td>11191</td>\n      <td>2016-07-01</td>\n      <td>2016-07-01</td>\n      <td></td>\n      <td></td>\n      <td>11500</td>\n      <td>包商银行</td>\n      <td>包商银行企业鑫喜16005理财产品</td>\n      <td>北京京西文化旅游股份有限公司</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-07-28</td>\n      <td>11191</td>\n      <td>2016-07-27</td>\n      <td>2016-07-27</td>\n      <td></td>\n      <td></td>\n      <td>1000</td>\n      <td>南京银行</td>\n      <td>“珠联璧合安享系列-季安享”人民币理财产品</td>\n      <td>北京京西文化旅游股份有限公司</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-07-28</td>\n      <td>11191</td>\n      <td>2016-07-27</td>\n      <td>2016-07-27</td>\n      <td>2016-08-24</td>\n      <td>28天</td>\n      <td>500</td>\n      <td>交通银行</td>\n      <td>“蕴通财富·稳得利”28天周期型理财产品</td>\n      <td>北京京西文化旅游股份有限公司</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5364</th>\n      <td>2016-03-02</td>\n      <td>22363</td>\n      <td>2015-10-26</td>\n      <td>2015-10-26</td>\n      <td></td>\n      <td></td>\n      <td>600</td>\n      <td></td>\n      <td>交通银行“蕴通财富•日增利S款”</td>\n      <td>南京全信传输科技股份有限公司</td>\n    </tr>\n    <tr>\n      <th>5365</th>\n      <td>2016-03-02</td>\n      <td>22363</td>\n      <td>2016-03-02</td>\n      <td>2016-03-02</td>\n      <td>2016-06-08</td>\n      <td>98天</td>\n      <td>1000</td>\n      <td>南京银行</td>\n      <td>南京银行“珠联璧合-季稳鑫1号”</td>\n      <td>南京全信传输科技股份有限公司</td>\n    </tr>\n    <tr>\n      <th>5366</th>\n      <td>2018-08-21</td>\n      <td>22365</td>\n      <td>2018-08-17</td>\n      <td>2018-08-17</td>\n      <td>2019-02-15</td>\n      <td>2天</td>\n      <td>10000</td>\n      <td>盛京银行大连星海支行</td>\n      <td>盛京银行单位结构性存款2018年第106期</td>\n      <td>大连派思燃气系统股份有限公司</td>\n    </tr>\n    <tr>\n      <th>5367</th>\n      <td>2017-02-06</td>\n      <td>22369</td>\n      <td>2017-02-04</td>\n      <td>2017-02-04</td>\n      <td>2017-03-03</td>\n      <td>27天</td>\n      <td>5500</td>\n      <td>兴业银行股份有限公司</td>\n      <td>“兴业金雪球—优先2号”人民币理财产品</td>\n      <td>安徽安德利百货股份有限公司</td>\n    </tr>\n    <tr>\n      <th>5368</th>\n      <td>2018-05-04</td>\n      <td>22370</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>nan天</td>\n      <td>10000</td>\n      <td>中国建设银行股份有限公司南平分行</td>\n      <td>结构性存款</td>\n      <td>福建南平太阳电缆股份有限公司</td>\n    </tr>\n  </tbody>\n</table>\n<p>5369 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "val_result\n",
    "val_result.to_excel(\"text_test_2210_result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'产品发行方名称'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-d305ffba78bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_df2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sample_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"理财产品名称\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"产品发行方名称\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"实际购买公司名称\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sample_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"理财产品名称\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"产品发行方名称\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"实际购买公司名称\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdafa_df3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_df1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_df2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sample_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"理财产品名称\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"产品发行方名称\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[1;32m---> 74\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1018\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1019\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1558\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1560\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '产品发行方名称'"
     ]
    }
   ],
   "source": [
    "data_df1=val_result.drop(labels=[\"产品发行方名称\"],axis=1)\n",
    "data_df2=pd.DataFrame()\n",
    "data_df2[[\"sample_id\",\"理财产品名称\",\"产品发行方名称\",\"实际购买公司名称\"]]=data_df[[\"sample_id\",\"理财产品名称\",\"产品发行方名称\",\"实际购买公司名称\"]]\n",
    "dafa_df3=pd.merge(data_df1,data_df2,on=[\"sample_id\",\"理财产品名称\",\"产品发行方名称\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检验筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.merge(val_df[['sample_id']], train_outputs, on='sample_id', how='left')\n",
    "b=val_result\n",
    "b[\"sample_id\"]=b[\"sample_id\"].astype(str)\n",
    "b[\"认购金额(万元)\"]=b[\"认购金额(万元)\"].astype(str)\n",
    "a[\"sample_id\"]=a[\"sample_id\"].astype(str)\n",
    "a[\"认购金额(万元)\"]=b[\"认购金额(万元)\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=pl.Path(\"test_result.csv\")\n",
    "pd.read_csv(c,encoding=\"gbk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_temp_single.to_csv(\"val_txt_result.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_excel(\"result_after_drop.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=val_temp_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"认购金额(万元)\"]=c[\"认购金额(万元)\"].astype(str)\n",
    "d[\"认购金额(万元)\"]=d[\"认购金额(万元)\"].astype(str)\n",
    "c_d_df=pd.merge(c,d,on=[\"理财产品名称\",\"认购金额(万元)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_d_df.to_excel(\"c_d.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         认购日期_x     产品起息日_x     产品到息日_x 产品期限_x 认购金额(万元)  \\\n0    2018-09-30  2018-09-30                     19000.0   \n1    2018-09-30  2018-09-30                     19000.0   \n2    2018-10-09  2018-10-09  2018-12-28    80天  12000.0   \n3    2018-10-09  2018-10-09  2018-12-28    80天  12000.0   \n4    2019-03-07  2019-03-07  2019-04-16    40天   1000.0   \n..          ...         ...         ...    ...      ...   \n694  2018-10-26  2018-10-26  2019-02-01    98天   1500.0   \n695  2018-10-26  2018-10-26  2019-02-01    98天   1500.0   \n696  2018-07-05  2018-07-05  2019-01-03     2天   4800.0   \n697  2018-12-14  2018-12-14  2019-12-11   362天   7000.0   \n698  2018-12-14  2018-12-14  2019-12-11   362天   7000.0   \n\n                 产品发行方名称_x                                 理财产品名称  \\\n0         中国民生银行股份有限公司沈阳分行                中银保本理财-人民币按期开放【CNYAQKF】   \n1         中国民生银行股份有限公司沈阳分行                中银保本理财-人民币按期开放【CNYAQKF】   \n2         中国民生银行股份有限公司沈阳分行                   挂钩利率结构性存款SDGA180883D   \n3         中国民生银行股份有限公司沈阳分行                   挂钩利率结构性存款SDGA180883D   \n4    中国民生银行股份有限公司长沙分行侯家塘支行                              挂钩指数结构性存款   \n..                     ...                                    ...   \n694       中信银行股份有限公司南京江北支行  中信理财之共赢利率结构22496期人民币结构性存款产品-C189T0196   \n695       中信银行股份有限公司南京江北支行  中信理财之共赢利率结构22496期人民币结构性存款产品-C189T0196   \n696             江苏银行南京龙江支行          江苏银行“聚宝财富宝溢融”人民币开放式B6机构27理财产品   \n697         华夏银行股份有限公司宁波分行                 华夏银行慧盈人民币单位结构性存款产品0243   \n698         华夏银行股份有限公司宁波分行                 华夏银行慧盈人民币单位结构性存款产品0243   \n\n     sample_id_x           实际购买公司      认购日期_y     产品起息日_y     产品到息日_y 产品期限_y  \\\n0          10447       桃李面包股份有限公司  2018-10-08  2018-10-08  2018-12-28    81天   \n1          10447       桃李面包股份有限公司  2018-10-08  2018-10-08  2018-12-28    81天   \n2          10447       桃李面包股份有限公司  2018-10-09  2018-10-09  2018-12-28    80天   \n3          10447       桃李面包股份有限公司  2018-10-09  2018-10-09  2018-12-28    80天   \n4           9111       喜爱集团股份有限公司  2019-03-07  2019-03-07  2019-04-16    40天   \n..           ...              ...         ...         ...         ...    ...   \n694         4235     基蛋生物科技股份有限公司  2018-10-26  2018-10-26  2019-02-01    98天   \n695         4235     基蛋生物科技股份有限公司  2018-10-26  2018-10-26  2019-02-01    98天   \n696         4247     基蛋生物科技股份有限公司  2018-07-05  2018-07-05  2019-01-03   182天   \n697         8737  浙江省围海建设集团股份有限公司  2018-12-14  2018-12-14  2019-12-11   362天   \n698         8737  浙江省围海建设集团股份有限公司  2018-12-14  2018-12-14  2019-12-11   362天   \n\n                 产品发行方名称_y  sample_id_y  \n0                      NaN        10447  \n1                      NaN        10444  \n2                      NaN        10447  \n3                      NaN        10445  \n4    中国民生银行股份有限公司长沙分行侯家塘支行         9110  \n..                     ...          ...  \n694       中信银行股份有限公司南京江北支行         4234  \n695       中信银行股份有限公司南京江北支行         4235  \n696             江苏银行南京龙江支行         4247  \n697         华夏银行股份有限公司宁波分行         8735  \n698         华夏银行股份有限公司宁波分行         8733  \n\n[699 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>认购日期_x</th>\n      <th>产品起息日_x</th>\n      <th>产品到息日_x</th>\n      <th>产品期限_x</th>\n      <th>认购金额(万元)</th>\n      <th>产品发行方名称_x</th>\n      <th>理财产品名称</th>\n      <th>sample_id_x</th>\n      <th>实际购买公司</th>\n      <th>认购日期_y</th>\n      <th>产品起息日_y</th>\n      <th>产品到息日_y</th>\n      <th>产品期限_y</th>\n      <th>产品发行方名称_y</th>\n      <th>sample_id_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-09-30</td>\n      <td>2018-09-30</td>\n      <td></td>\n      <td></td>\n      <td>19000.0</td>\n      <td>中国民生银行股份有限公司沈阳分行</td>\n      <td>中银保本理财-人民币按期开放【CNYAQKF】</td>\n      <td>10447</td>\n      <td>桃李面包股份有限公司</td>\n      <td>2018-10-08</td>\n      <td>2018-10-08</td>\n      <td>2018-12-28</td>\n      <td>81天</td>\n      <td>NaN</td>\n      <td>10447</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-09-30</td>\n      <td>2018-09-30</td>\n      <td></td>\n      <td></td>\n      <td>19000.0</td>\n      <td>中国民生银行股份有限公司沈阳分行</td>\n      <td>中银保本理财-人民币按期开放【CNYAQKF】</td>\n      <td>10447</td>\n      <td>桃李面包股份有限公司</td>\n      <td>2018-10-08</td>\n      <td>2018-10-08</td>\n      <td>2018-12-28</td>\n      <td>81天</td>\n      <td>NaN</td>\n      <td>10444</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-10-09</td>\n      <td>2018-10-09</td>\n      <td>2018-12-28</td>\n      <td>80天</td>\n      <td>12000.0</td>\n      <td>中国民生银行股份有限公司沈阳分行</td>\n      <td>挂钩利率结构性存款SDGA180883D</td>\n      <td>10447</td>\n      <td>桃李面包股份有限公司</td>\n      <td>2018-10-09</td>\n      <td>2018-10-09</td>\n      <td>2018-12-28</td>\n      <td>80天</td>\n      <td>NaN</td>\n      <td>10447</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-10-09</td>\n      <td>2018-10-09</td>\n      <td>2018-12-28</td>\n      <td>80天</td>\n      <td>12000.0</td>\n      <td>中国民生银行股份有限公司沈阳分行</td>\n      <td>挂钩利率结构性存款SDGA180883D</td>\n      <td>10447</td>\n      <td>桃李面包股份有限公司</td>\n      <td>2018-10-09</td>\n      <td>2018-10-09</td>\n      <td>2018-12-28</td>\n      <td>80天</td>\n      <td>NaN</td>\n      <td>10445</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-03-07</td>\n      <td>2019-03-07</td>\n      <td>2019-04-16</td>\n      <td>40天</td>\n      <td>1000.0</td>\n      <td>中国民生银行股份有限公司长沙分行侯家塘支行</td>\n      <td>挂钩指数结构性存款</td>\n      <td>9111</td>\n      <td>喜爱集团股份有限公司</td>\n      <td>2019-03-07</td>\n      <td>2019-03-07</td>\n      <td>2019-04-16</td>\n      <td>40天</td>\n      <td>中国民生银行股份有限公司长沙分行侯家塘支行</td>\n      <td>9110</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>694</th>\n      <td>2018-10-26</td>\n      <td>2018-10-26</td>\n      <td>2019-02-01</td>\n      <td>98天</td>\n      <td>1500.0</td>\n      <td>中信银行股份有限公司南京江北支行</td>\n      <td>中信理财之共赢利率结构22496期人民币结构性存款产品-C189T0196</td>\n      <td>4235</td>\n      <td>基蛋生物科技股份有限公司</td>\n      <td>2018-10-26</td>\n      <td>2018-10-26</td>\n      <td>2019-02-01</td>\n      <td>98天</td>\n      <td>中信银行股份有限公司南京江北支行</td>\n      <td>4234</td>\n    </tr>\n    <tr>\n      <th>695</th>\n      <td>2018-10-26</td>\n      <td>2018-10-26</td>\n      <td>2019-02-01</td>\n      <td>98天</td>\n      <td>1500.0</td>\n      <td>中信银行股份有限公司南京江北支行</td>\n      <td>中信理财之共赢利率结构22496期人民币结构性存款产品-C189T0196</td>\n      <td>4235</td>\n      <td>基蛋生物科技股份有限公司</td>\n      <td>2018-10-26</td>\n      <td>2018-10-26</td>\n      <td>2019-02-01</td>\n      <td>98天</td>\n      <td>中信银行股份有限公司南京江北支行</td>\n      <td>4235</td>\n    </tr>\n    <tr>\n      <th>696</th>\n      <td>2018-07-05</td>\n      <td>2018-07-05</td>\n      <td>2019-01-03</td>\n      <td>2天</td>\n      <td>4800.0</td>\n      <td>江苏银行南京龙江支行</td>\n      <td>江苏银行“聚宝财富宝溢融”人民币开放式B6机构27理财产品</td>\n      <td>4247</td>\n      <td>基蛋生物科技股份有限公司</td>\n      <td>2018-07-05</td>\n      <td>2018-07-05</td>\n      <td>2019-01-03</td>\n      <td>182天</td>\n      <td>江苏银行南京龙江支行</td>\n      <td>4247</td>\n    </tr>\n    <tr>\n      <th>697</th>\n      <td>2018-12-14</td>\n      <td>2018-12-14</td>\n      <td>2019-12-11</td>\n      <td>362天</td>\n      <td>7000.0</td>\n      <td>华夏银行股份有限公司宁波分行</td>\n      <td>华夏银行慧盈人民币单位结构性存款产品0243</td>\n      <td>8737</td>\n      <td>浙江省围海建设集团股份有限公司</td>\n      <td>2018-12-14</td>\n      <td>2018-12-14</td>\n      <td>2019-12-11</td>\n      <td>362天</td>\n      <td>华夏银行股份有限公司宁波分行</td>\n      <td>8735</td>\n    </tr>\n    <tr>\n      <th>698</th>\n      <td>2018-12-14</td>\n      <td>2018-12-14</td>\n      <td>2019-12-11</td>\n      <td>362天</td>\n      <td>7000.0</td>\n      <td>华夏银行股份有限公司宁波分行</td>\n      <td>华夏银行慧盈人民币单位结构性存款产品0243</td>\n      <td>8737</td>\n      <td>浙江省围海建设集团股份有限公司</td>\n      <td>2018-12-14</td>\n      <td>2018-12-14</td>\n      <td>2019-12-11</td>\n      <td>362天</td>\n      <td>华夏银行股份有限公司宁波分行</td>\n      <td>8733</td>\n    </tr>\n  </tbody>\n</table>\n<p>699 rows × 15 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "c_d_df"
   ]
  }
 ]
}