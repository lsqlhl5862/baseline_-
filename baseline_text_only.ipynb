{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关包\n",
    "import os\n",
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from io import StringIO\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from tqdm.autonotebook import *\n",
    "import pdfplumber\n",
    "import collections\n",
    "tqdm.pandas()\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from tgrocery import Grocery\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id       认购日期        理财产品名称     产品发行方名称    理财类型  认购金额(万元)  \\\n0          1 2019-03-27         汇聚金1号  中融国际信托有限公司      信托   10000.0   \n1          1 2019-03-27  招商银行步步生金8699        招商银行  银行理财产品     200.0   \n\n       产品起息日      产品到息日  产品期限  资金来源    实际购买公司名称 实际购买公司和上市公司关系 买卖方是否有关联关系  \\\n0 2019-03-27 2019-09-23  180天  自有资金  恒生电子股份有限公司          公司本身          否   \n1 2019-03-27        NaT   NaN  自有资金  恒生电子股份有限公司          公司本身          否   \n\n        公告日期  \n0 2019-04-25  \n1 2019-04-25  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>认购日期</th>\n      <th>理财产品名称</th>\n      <th>产品发行方名称</th>\n      <th>理财类型</th>\n      <th>认购金额(万元)</th>\n      <th>产品起息日</th>\n      <th>产品到息日</th>\n      <th>产品期限</th>\n      <th>资金来源</th>\n      <th>实际购买公司名称</th>\n      <th>实际购买公司和上市公司关系</th>\n      <th>买卖方是否有关联关系</th>\n      <th>公告日期</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2019-03-27</td>\n      <td>汇聚金1号</td>\n      <td>中融国际信托有限公司</td>\n      <td>信托</td>\n      <td>10000.0</td>\n      <td>2019-03-27</td>\n      <td>2019-09-23</td>\n      <td>180天</td>\n      <td>自有资金</td>\n      <td>恒生电子股份有限公司</td>\n      <td>公司本身</td>\n      <td>否</td>\n      <td>2019-04-25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2019-03-27</td>\n      <td>招商银行步步生金8699</td>\n      <td>招商银行</td>\n      <td>银行理财产品</td>\n      <td>200.0</td>\n      <td>2019-03-27</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>自有资金</td>\n      <td>恒生电子股份有限公司</td>\n      <td>公司本身</td>\n      <td>否</td>\n      <td>2019-04-25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id                  file_path  \\\n0          1  datasets/train_data/1.PDF   \n1          2  datasets/train_data/2.PDF   \n\n                                                text  \\\n0  ['                                            ...   \n1  ['                                            ...   \n\n                                               tabel  \n0  [[['', None, None, '', None, None, '', None, N...  \n1  [[['', None, None, '', None, None, '', None, N...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>file_path</th>\n      <th>text</th>\n      <th>tabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>datasets/train_data/1.PDF</td>\n      <td>['                                            ...</td>\n      <td>[[['', None, None, '', None, None, '', None, N...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>datasets/train_data/2.PDF</td>\n      <td>['                                            ...</td>\n      <td>[[['', None, None, '', None, None, '', None, N...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id                     file_path  \\\n0      11188  datasets/test_data/11188.PDF   \n1      11189  datasets/test_data/11189.PDF   \n\n                                                text tabel  \n0  ['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...    []  \n1  ['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...    []  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>file_path</th>\n      <th>text</th>\n      <th>tabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11188</td>\n      <td>datasets/test_data/11188.PDF</td>\n      <td>['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11189</td>\n      <td>datasets/test_data/11189.PDF</td>\n      <td>['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# 数据准备(train_output文件中格式有点问题，需要提前用excel或者wps打开然后另存为excel文件)\n",
    "train_outputs = pd.read_excel('datasets/train_output.xlsx')\n",
    "\n",
    "# 获取pdf中文字和表格\n",
    "def extract_pdf_content(pdf_path):\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for index_page in np.arange(0, len(pdf.pages), 1):\n",
    "            # 读取多页\n",
    "            page = pdf.pages[index_page]   # 第n页的信息\n",
    "            text = page.extract_text()\n",
    "            text_list.append(text)\n",
    "            table = page.extract_tables()\n",
    "            for t in table:\n",
    "                table_list.append(t)\n",
    "    return text_list, table_list\n",
    "\n",
    "def get_dir_file(path):\n",
    "    '''\n",
    "    输入文件夹位置，输出整理好的dataframe\n",
    "    '''\n",
    "    path_list = os.listdir(path)\n",
    "    id_list = []\n",
    "    file_path_list = []\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    for i in tqdm(path_list):\n",
    "        if '.PDF' in i:\n",
    "            file_path = path + i\n",
    "            id_list.append(int(i.split('.')[0]))\n",
    "            file_path_list.append(file_path)\n",
    "            try:\n",
    "                text_temp, table_temp = extract_pdf_content(file_path)\n",
    "            except Exception:\n",
    "                print('此pdf无法读取')\n",
    "                text_temp, table_temp = [], []\n",
    "            text_list.append(text_temp)\n",
    "            table_list.append(table_temp)\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df['sample_id'] = id_list\n",
    "    df['file_path'] = file_path_list\n",
    "    df['text'] = text_list\n",
    "    df['tabel'] = table_list\n",
    "    df = df.sort_values('sample_id')\n",
    "    return df\n",
    "\n",
    "# 文件处理太慢，可持续化保存文件\n",
    "train_path = 'datasets/train.csv'\n",
    "if os.path.exists(train_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "else:\n",
    "    train_df = get_dir_file('datasets/train_data/')\n",
    "    train_df.to_csv(train_path,index=False)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "\n",
    "test_path =  'datasets/test.csv'\n",
    "if os.path.exists(test_path):\n",
    "    test_df = pd.read_csv(test_path)\n",
    "else:\n",
    "    test_df = get_dir_file('datasets/test_data/')\n",
    "    test_df.to_csv(test_path,index=False)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "train_outputs.head(2)\n",
    "train_df.head(2)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造训练集验证集\n",
    "train_df = train_df.sample(frac=1, random_state=1017)\n",
    "\n",
    "val_df = train_df[:1800]\n",
    "# val_df = train_df[:1800].head(20)\n",
    "# train_df = train_df[1800:].head(20)\n",
    "# test_df=test_df.head(20)\n",
    "\n",
    "train_outputs[\"sample_id\"]=train_outputs[\"sample_id\"].astype(str)\n",
    "val_df[\"sample_id\"]=val_df[\"sample_id\"].astype(str)\n",
    "# train_df[\"sample_id\"]=train_df[\"sample_id\"].astype(str)\n",
    "# test_df[\"sample_id\"]=test_df[\"sample_id\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有效文本挖掘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:58<00:00, 30.95it/s]\n"
    }
   ],
   "source": [
    "#text=text.replace(r'[ ]+',' ').replace('\\r','^')\n",
    "def get_title(text):\n",
    "    global title_num_char\n",
    "    title_list=[]\n",
    "    title_type_list=[]\n",
    "    text_start_iter_list=[]\n",
    "    text_end_iter_list=[]\n",
    " \n",
    "    for item in title_num_char:\n",
    "        pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5 ()\\[\\]（）【】：:]*?[\\^]\")\n",
    "        #pattern = re.compile(item+r\"[ ]*?[^ ]+?[ ]\")\n",
    "        #pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5 ()[]（）【】][]\")#*?[\\^]\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(1)\n",
    "            text_end_iter_list.append(i.span(0)[1])\n",
    "\n",
    "    # for item in title_list:\n",
    "    for item in s_title_num_char:\n",
    "        # pattern = re.compile(item+r\"[ ]*?[ ]*?[\\d][^ ]+?:?[ ]?\") \n",
    "        # pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5\\^ ]*\")\n",
    "        # pattern = re.compile(item+'[0-9\\u4e00-\\u9fa5()[]（）【】*?[\\^]]')*?[\\^]\n",
    "    #    pattern = re.compile(item+r\"[\\d]*?\\u4e00-\\u9fa5+[ ]\")\n",
    "        pattern = re.compile(item+\"[0-9A-Za-z\\u4e00-\\u9fa5 ()\\[\\]（）【】：:]*?[ ][\\^]\")\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(1)\n",
    "            text_end_iter_list.append(i.span(0)[1])\n",
    "\n",
    "    title_list.append(\"引言\")\n",
    "    title_type_list.append(1)\n",
    "    text_start_iter_list.append(0)\n",
    "    text_end_iter_list.append(0)\n",
    "\n",
    "    result_df=pd.DataFrame([title_list,title_type_list,text_start_iter_list,text_end_iter_list]).T.sort_values(by=2).reset_index(drop=True)\n",
    "    # print(result_df)\n",
    "    return result_df\n",
    "\n",
    "def get_title_text(text,title_df):\n",
    "    # print(title_df)\n",
    "    title_1_df=title_df[title_df[1]==1]\n",
    "    text_iter_list=[]\n",
    "    text_list=[]\n",
    "    # print(title_1_df)\n",
    "    for iter1,iter2 in title_1_df[[2,3]].values:\n",
    "        # print(iter1)\n",
    "        if(len(text_iter_list)!=0):\n",
    "            text_iter_list.append(iter1)\n",
    "        text_iter_list.append(iter2)\n",
    "    # text_iter_list.append(text_iter_list[len(text_iter_list)-1])\n",
    "    text_iter_list.append(len(text))\n",
    "    for index in range(int(len(text_iter_list)/2)):\n",
    "        text_list.append(text[text_iter_list[2*index]:text_iter_list[2*index+1]])\n",
    "    \n",
    "    title_1_df[4]=text_list\n",
    "\n",
    "    return title_1_df.reset_index(drop=True)\n",
    "\n",
    "#from fuzzywuzzy import fuzz\n",
    "def judge_title(sample_id=0,text=r\"test\\n\"):\n",
    "    # print(text)\n",
    "    text=text.replace(r\"\\n\",\"^\").replace(r'[ ]+',' ')\n",
    "    title_df=get_title(text)\n",
    "    title_df[\"sample_id\"]=[sample_id for x in range(title_df.shape[0])]\n",
    "    # print(title_df)`\n",
    "    title_1_df=get_title_text(text,title_df)[[\"sample_id\",0,1,2,3,4]]\n",
    "\n",
    "    \n",
    "\n",
    "    global val_df\n",
    "    global train_outputs\n",
    "    val_true_name=train_outputs[train_outputs[\"sample_id\"]==sample_id][\"理财产品名称\"]\n",
    "    \n",
    "    index=0\n",
    "    neg_index=[]\n",
    "    for title_des in title_1_df[0].values:\n",
    "        for item in title_neg_words:\n",
    "            if re.search(item,title_des) is not None:\n",
    "                neg_index.append(index)\n",
    "                break\n",
    "        index+=1\n",
    "\n",
    "\n",
    "    return title_1_df.drop(neg_index)\n",
    "    # print(title_list)\n",
    "\n",
    "def get_judge_title_result(val_df):\n",
    "\n",
    "    judge_title_result=None\n",
    "\n",
    "\n",
    "    for sample_id,text in tqdm(val_df[[\"sample_id\",\"text\"]].values):\n",
    "        # print(sample_id)\n",
    "        # print(text)\n",
    "        judge_title_result= judge_title(sample_id,text) if judge_title_result is None else pd.concat([judge_title_result,judge_title(sample_id,text)])\n",
    "\n",
    "        judge_title_result[\"sample_id\"]=judge_title_result[\"sample_id\"].astype(str)        \n",
    "    return judge_title_result\n",
    "\n",
    "title_num_char=[\"一、\",\"二、\",\"三、\",\"四、\",\"五、\",\"六、\",\"七、\",\"八、\",\"九、\",\"十、\",\"十一、\",\"十二、\",\"十三、\",\"十四、\",\"十五、\"]\n",
    "s_title_num_char=[\"（一）\",\"（二）\",\"（三）\",\"（四）\",\"（五）\",\"（六）\",\"（七）\",\"（八）\",\"（九）\",\"（十）\",\"（十一）\",\"（十二）\",\"（十三）\",\"（十四）\",\"（十五）\"]\n",
    "s_title_num_char.extend([\"[(]一[)]\",\"[(]二[)]\",\"[(]三[)]\",\"[(]四[)]\",\"[(]五[)]\",\"[(]六[)]\",\"[(]七[)]\",\"[(]八[)]\",\"[(]九[)]\",\"[(]十[)]\",\"[(]十一[)]\",\"[(]十二[)]\",\"[(]十三[)]\",\"[(]十四[)]\",\"[(]十五[)]\"])\n",
    "\n",
    "title_pos_words=[]\n",
    "title_neg_words=[]\n",
    "title_neg_words=[\"备查\",\"日前\",\"过去\",\"履行\",\"审批\",\"程序\",\"风险\",\"措施\",\"影响\",\"累计\",\"赎回\",\"到期[^日].*[^2][^0]\",\"到期.{0,2}[/^]\",\"截至\",\"意见\",\"十二个月内\",\"公告前\",\"报备文件\",\"前期\"]\n",
    "\n",
    "val_judge_title_result=get_judge_title_result(val_df)\n",
    "# train_judge_title_result=get_judge_title_result(train_df)\n",
    "# test_judge_title_result=get_judge_title_result(test_df)\n",
    "# judge_title_result.to_excel(\"训练集段落标题分类结果.xlsx\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:12<00:00, 147.52it/s]\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_judge_title_result' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-275d19fd7573>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mval_content_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_content_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_judge_title_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mtrain_content_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_content_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_judge_title_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mtest_content_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_content_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_judge_title_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_judge_title_result' is not defined"
     ]
    }
   ],
   "source": [
    "###9月11日\n",
    "#val_judge_title_result.head(100)\n",
    "def get_content_df(val_judge_title_result):\n",
    "    sample_id=val_judge_title_result['sample_id'].drop_duplicates() \n",
    "    text_list=[]\n",
    "    text_sampleid_list=[]\n",
    "    content_df=pd.DataFrame()\n",
    "    for i in tqdm(sample_id):\n",
    "        text_df=val_judge_title_result[val_judge_title_result['sample_id']==i]\n",
    "    #  text_df.iloc[0,5]\n",
    "        #text_df\n",
    "        n=len(text_df)\n",
    "        text_sampleid_list.append(i)\n",
    "        text=''\n",
    "        for y in range(0,n):\n",
    "            text=text+text_df.iloc[y,1]+text_df.iloc[y,5]\n",
    "            text=re.sub(\"[ ]+\",\" \",text).replace(\"（\",\"(\").replace(\"）\",\")\")\n",
    "        #text\n",
    "        text_list.append(text)\n",
    "    content_df[\"sample_id\"]=text_sampleid_list\n",
    "    content_df[\"text\"]=text_list\n",
    "    return content_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "val_content_df=get_content_df(val_judge_title_result)\n",
    "train_content_df=get_content_df(train_judge_title_result)\n",
    "test_content_df=get_content_df(test_judge_title_result)\n",
    "\n",
    "val_content_df=pd.merge(val_content_df,val_df[[\"sample_id\",\"tabel\"]],on=\"sample_id\")\n",
    "# train_content_df=pd.merge(train_content_df,train_df[[\"sample_id\",\"tabel\"]],on=\"sample_id\")\n",
    "# test_content_df=pd.merge(test_content_df,test_df[[\"sample_id\",\"tabel\"]],on=\"sample_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名称提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######计算文本位置长度#############\n",
    "def len_count(my_list,my_str):\n",
    "    my_len=0\n",
    "    for i in my_list:\n",
    "        my_len=my_len+len(i)\n",
    "    my_len=my_len+(len(my_list)-1)*len(my_str)\n",
    "    return my_len\n",
    "\n",
    "\n",
    "######基于冒号做文本拼接与分割####效果优\n",
    "def maohao_cat(text):\n",
    "    text=text.replace(r\"\\n\",\"^\")\n",
    "    text=text.replace(r\"', '\",\"^\")\n",
    "    text=text.replace(' ','')\n",
    "    text=text.replace('（','(').replace('）',')').replace('；','^')     ###############;直接去掉,有极个别答案(答案中出现了引号)将会收到负反馈，多数正反馈\n",
    "    text=re.sub('\\^[1-9]\\^','^',text)\n",
    "    text=re.sub('\\^\\-[1-9]\\-\\^','^',text)\n",
    "    text=re.sub(\"[（][^）]*?[\\^]*$\",'',text)\n",
    "    text=re.sub('[，]*$','',text)\n",
    "    pos_word=[\"名称\",\"期限\",\"年\",\"月\",\"日\",\"时间\",\"产品\",\"资金\",\"金额\",\"天\",\"来源\",\"总额\",\"类型\",\"元\",\"关系\",\"无关\",\"不存在关\"]\n",
    "    if '^' not in text:\n",
    "        return \n",
    "    my_list=text.split(\"^\")\n",
    "    my_str=''\n",
    "    str_list=[]\n",
    "    # for i in my_list:\n",
    "    #     if \"：\" not in i and \":\" not in i and \"无关\" not in i and \"不存在关\" not in i and \"名称\" not in my_str:\n",
    "    #         my_str=my_str+i\n",
    "    #         # if len(i)<=6:\n",
    "    #         #     str_list.append(my_str)      #############解决最后一行被后函数因字数过长舍弃的办法\n",
    "    #         #     continue\n",
    "    #     else:\n",
    "    #         str_list.append(my_str)\n",
    "    #         my_str=i\n",
    "    \n",
    "    for i in my_list:\n",
    "        if \"：\" not in i and \":\" not in i and len(re.sub('[^\\u4e00-\\u9fa5]*','',i))<5:\n",
    "            my_str=my_str+i\n",
    "            # if \"不存在关\" in my_str:\n",
    "            #     str_list.append(my_str)\n",
    "            #     my_str=''\n",
    "            # if len(i)<=6:\n",
    "            #     str_list.append(my_str)      #############解决最后一行被后函数因字数过长舍弃的办法\n",
    "            #     continue\n",
    "        else:\n",
    "            str_list.append(my_str)\n",
    "            my_str=i\n",
    "    \n",
    "    str_list.append(my_str)\n",
    "    # print(my_list)\n",
    "    # print('-----')\n",
    "    # print(str_list)\n",
    "    # print('-----')\n",
    "    cat_text=''\n",
    "    # print(str_list)\n",
    "    for i in str_list:\n",
    "        cat_text=cat_text+i+r'^'\n",
    "        # print(cat_text)\n",
    "    # print(cat_text.replace(r'^','\\n'))\n",
    "    return cat_text\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######寻找文本中的答案##############\n",
    "####以如下及冒号行做切片#############\n",
    "def wjc_spl(text):\n",
    "    spl1=[]      ###如下切片\n",
    "    maohao=3  ####设定冒号出现次数阈值\n",
    "    zishu=30   ####设定单行冒号后字数阈值\n",
    "    my_str=\"\"\n",
    "    text=maohao_cat(text)    #########调用函数做text正规化\n",
    "    spl2=[]      ###行切片\n",
    "    spl3=[]\n",
    "    neg_word=[]\n",
    "    pos_word=[\"名称\",\"期限\",\"年\",\"月\",\"日\",\"时间\",\"产品\",\"资金\",\"金额\",\"天\",\"来源\",\"总额\",\"类型\",\"元\",\"关系\",\"额\",\"金\",\"受托\",\"签约银行\"]\n",
    "    # pos_word=[\"名称\"]\n",
    "    # print(len(text))\n",
    "    if text==None:\n",
    "        return -1,-1,-1\n",
    "    text=text.replace(r\"\\n\",\"^\")\n",
    "    # print(len(text))\n",
    "    text=text.replace(r\"', '\",\"^\")    ######解决换页符被置为', '的问题\n",
    "    # print(len(text))\n",
    "    text=text.replace(' ','')\n",
    "    text=text.replace('（','(').replace('）',')').replace(':','：').replace('如^下：','如下：').replace('如下^：','如下：')\n",
    "    # print(len(text))\n",
    "    # print(text[:10000])\n",
    "    if \"如下：\" not in text:\n",
    "        return -1,-1,-1\n",
    "    else:\n",
    "        move=[]\n",
    "        spl1=text.split(\"如下：\")   #####首次切割####\n",
    "        # print(len_count(spl1,'如下：'))\n",
    "        # print(len(spl1[0])+len(spl1[1]))\n",
    "        my_len=len(spl1[0])+len('如下：')\n",
    "        spl1=spl1[1:]              ######第一次如下前的内容不关心##########\n",
    "        len_list=[]\n",
    "        tag1=[]\n",
    "        # print(spl1)\n",
    "        for i in spl1:\n",
    "            len_list.append(len(i))\n",
    "            if i.count(\"：\")<=maohao:\n",
    "                # print('aaaaaaa',len(len_list))\n",
    "                tag1.append(len(len_list))\n",
    "                move.append(i)\n",
    "        # move=list(set(move))\n",
    "        for x in move:\n",
    "            # print('pppppppppppppppppppppppppppp')\n",
    "            # print(x)\n",
    "            spl1.remove(x)    ####去除冒号过少的部分切片\n",
    "                \n",
    "        # print(my_len+0)\n",
    "        # print(spl1)\n",
    "        for i in spl1:\n",
    "            test=i.split('^')\n",
    "            #print(test[10])\n",
    "            for j in test:\n",
    "                spl2.append(j)\n",
    "            \n",
    "        # print(spl2[100])\n",
    "        move=[]\n",
    "        for i in spl2:\n",
    "            #print(i)\n",
    "            if i.count(\"：\")!=1 and i.count(\":\")!=1:\n",
    "                # print(i.count(\"：\"))\n",
    "                move.append(i)    ####以行做切片，去除单行里非只有一个冒号的行\n",
    "        for x in move:\n",
    "            # print(x)\n",
    "            spl2.remove(x)\n",
    "        # print(spl2[0])\n",
    "        move=[]\n",
    "        for i in spl2:\n",
    "            judge1=re.sub('[a-zA-Z]','',i.split(\"：\")[-1])\n",
    "            judge1=re.sub(r\"\\d\",'',judge1)\n",
    "            judge1=re.sub(r'”','',judge1)\n",
    "            judge1=re.sub(r'“','',judge1)\n",
    "            judge1=re.sub(r'（','',judge1)\n",
    "            judge1=re.sub(r'）','',judge1)\n",
    "            # print(len(judge1))\n",
    "            if len(judge1)>=zishu or len(judge1)<1:     #######去除冒号后关心字段所提中文内容过长或过短的行\n",
    "                move.append(i)\n",
    "                # print(i)\n",
    "        for x in move:\n",
    "            # print(x)\n",
    "            spl2.remove(x)\n",
    "        # print(spl2)\n",
    "        move=[]\n",
    "        # print(spl2)\n",
    "        # print('-----------')\n",
    "\n",
    "        # print(spl2)\n",
    "        if spl2==[]:\n",
    "            # print('该文本变量做行切片结果为空')\n",
    "            return -1,-1,-1\n",
    "\n",
    "        for i in spl2:\n",
    "            x=0\n",
    "            for j in pos_word:\n",
    "                judge2=i.split(\"：\")[0]      ########舍弃冒号前（分类字段）不包含pos_word的行\n",
    "                if j not in judge2:\n",
    "                    x=x+1\n",
    "                if x==len(pos_word):\n",
    "                    # print(i)\n",
    "                    move.append(i)\n",
    "            new_move=list(set(move))\n",
    "            # print(new_move)\n",
    "        for x in new_move:\n",
    "            # print(x)\n",
    "            spl2.remove(x)\n",
    "            \n",
    "        # print(spl2)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    tag1=0\n",
    "    key_pos_word=['名称']                 ############计算一个pdf生成的dataframe一共需要几行，及每行需要多少列###########\n",
    "    x=1\n",
    "    ele_times=[]\n",
    "    judge3=0\n",
    "    for i in spl2:\n",
    "        for j in key_pos_word:\n",
    "            if j not in i:\n",
    "                x=x+1                     ############若不含名称字段则结果会是实际+1###############\n",
    "            else:\n",
    "                ele_times.append(x)\n",
    "                x=1\n",
    "    \n",
    "            # print(i)\n",
    "            # print(x)\n",
    "    ele_times.append(x)\n",
    "\n",
    "    \n",
    "    # print(ele_times)\n",
    "    if len(ele_times)>1:\n",
    "        mo_times=ele_times[0]+ele_times[-1]-1\n",
    "        # print(type(mo_times))\n",
    "        ele_times=ele_times[1:-1]\n",
    "        ele_times.append(mo_times)\n",
    "    else:\n",
    "        test=0\n",
    "        # print(len(spl2))\n",
    "        # print(ele_times[0])\n",
    "        if len(ele_times)==1 and ele_times[0]==len(spl2)+1:\n",
    "            # print(\"不含名称字段\")                              ##############此处需处理，或者返回一个标记以后处理  冒号行不包含名称字段的情况\n",
    "            tag1=1\n",
    "    \n",
    "\n",
    "    ele_times1=ele_times\n",
    "    # print(ele_times)\n",
    "    # print(type(ele_times))\n",
    "\n",
    "    tag2=0\n",
    "    key_pos_word=['金额']                 ############计算一个pdf生成的dataframe一共需要几行，及每行需要多少列###########\n",
    "    x=1\n",
    "    ele_times=[]\n",
    "    judge3=0\n",
    "    for i in spl2:\n",
    "        for j in key_pos_word:\n",
    "            if j not in i:\n",
    "                x=x+1                     ############若不含金额字段则结果会是实际+1###############\n",
    "            else:\n",
    "                ele_times.append(x)\n",
    "                x=1\n",
    "    \n",
    "            # print(i)\n",
    "            # print(x)\n",
    "    ele_times.append(x)\n",
    "    # print(ele_times)\n",
    "    if len(ele_times)>1:\n",
    "        mo_times=ele_times[0]+ele_times[-1]-1\n",
    "        # print(type(mo_times))\n",
    "        ele_times=ele_times[1:-1]\n",
    "        ele_times.append(mo_times)\n",
    "    else:\n",
    "        test=0\n",
    "        # print(len(spl2))\n",
    "        # print(ele_times[0])\n",
    "        if len(ele_times)==1 and ele_times[0]==len(spl2)+1:\n",
    "            # print(\"不含金额字段\")                              ##############此处需处理，或者返回一个标记以后处理  冒号行不包含金额字段的情况\n",
    "            tag2=1\n",
    "    \n",
    "    ele_times2=ele_times\n",
    "    # print(ele_times2)\n",
    "\n",
    "    # print('---')\n",
    "\n",
    "    \n",
    "\n",
    "    if len(spl2)<=2:\n",
    "        return -1,-1,-1\n",
    "\n",
    "    \n",
    "\n",
    "    # print(ele_times2)\n",
    "    # if len(spl2)==1 and spl2[0]=='':\n",
    "    #     return\n",
    "    # if len(spl2)==1:\n",
    "    #     spl2[0].replace(' ','')\n",
    "   \n",
    "    return spl2,ele_times1,tag1     ######仅返回“关心”的行切片    #############注意返回变量可能造成函数无法执行\n",
    "\n",
    "\n",
    "\n",
    "def cut_list(text):\n",
    "    spl2,ele_times1,tag1=wjc_spl(text)\n",
    "    # print(spl2)\n",
    "    # print(ele_times1)\n",
    "    # print(tag1)\n",
    "    my_list=[]\n",
    "    if tag1==0:\n",
    "        for i in ele_times1:\n",
    "            # print(i)\n",
    "            get=spl2[0:i]\n",
    "            my_list.append(get)\n",
    "            spl2=spl2[i:]\n",
    "    else:\n",
    "        return 0\n",
    "    # print(my_list)\n",
    "    return my_list\n",
    "\n",
    "\n",
    "\n",
    "def get_mc(text):\n",
    "    # my_list=cut_list(text)\n",
    "    mc_list=[]\n",
    "    my_list=cut_list(text)\n",
    "    if my_list==0:\n",
    "        return \n",
    "    else:\n",
    "        my_list=cut_list(text)\n",
    "\n",
    "        for i in my_list:\n",
    "            this_str=i[0]\n",
    "            if \"名\" not in this_str or \"受托方\" in this_str or \"公司名称\" in this_str:\n",
    "                continue\n",
    "            index=this_str.index(\"：\")\n",
    "            this_str=this_str[index+1:].replace('。','').replace('；','').replace(';','').replace('、','')\n",
    "            mc_list.append(this_str)\n",
    "            # print(mc_list)\n",
    "    if mc_list ==[]:\n",
    "        return\n",
    "    return mc_list\n",
    "\n",
    "\n",
    "\n",
    "def spl2_iswm(text):\n",
    "    spl2,ele_times1,tag1=wjc_spl(text)\n",
    "    # print(spl2)\n",
    "    # print(ele_times1)\n",
    "    # print(tag1)\n",
    "    my_list=[]\n",
    "    if tag1==1:\n",
    "        return \"无名称\"\n",
    "    else:\n",
    "        return \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 位置定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到关键字在文本中的位置\n",
    "def find_pos_in_text(text, keys, sample_id = 0):\n",
    "    ret = []\n",
    "\n",
    "    if not keys or len(keys) == 0 or not text:\n",
    "        return None\n",
    "\n",
    "    textWithArrow = re.sub(' +', ' ', text).replace(r'\\n', '^').replace(' ', '^')\n",
    "    textWithoutWhite = textWithArrow.replace('^', '')\n",
    "\n",
    "    # 每个非空词的前缀空格个数\n",
    "    seq, totalSpace = 0, 0\n",
    "    preleadingSpaceDict = collections.defaultdict(int)\n",
    "    for i in range(len(textWithArrow)):\n",
    "        if (textWithArrow[i]) == '^':\n",
    "            totalSpace += 1\n",
    "            preleadingSpaceDict[seq] = totalSpace\n",
    "        else:\n",
    "            preleadingSpaceDict[seq] = totalSpace\n",
    "            seq += 1        \n",
    "\n",
    "    for key in keys:\n",
    "        nkey = str(key).replace('(', r'\\(').replace(')', r'\\)').replace('[', r'\\[').replace(']', r'\\]')\n",
    "        for it in re.finditer(nkey, textWithoutWhite):\n",
    "            ret.append([key, it.span()[0]+preleadingSpaceDict[it.span()[0]], \\\n",
    "                it.span()[1]+preleadingSpaceDict[it.span()[1]], sample_id])\n",
    "\n",
    "    if not len(ret):\n",
    "        return None\n",
    "\n",
    "    ret.sort(key = lambda x: x[1])\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理财名称提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [01:16<00:00, 23.46it/s]\n"
    }
   ],
   "source": [
    "def get_product_text(val_content_df):\n",
    "    result_df=None\n",
    "    for sample_id,text in tqdm(val_content_df[[\"sample_id\",\"text\"]].values):\n",
    "        mc_list=get_mc(text)\n",
    "        if mc_list is not None:\n",
    "            mc_list=list(set(mc_list))\n",
    "            # print(mc_list)\n",
    "        # print(\"-----------\")\n",
    "        # sample_id\n",
    "        tmp_df=pd.DataFrame(find_pos_in_text(text,mc_list),columns=[0,1,2,3])\n",
    "        tmp_df[[0,1,2,3]]=tmp_df[[0,3,1,2]]\n",
    "        tmp_df[1]=1\n",
    "        tmp_df[3]=tmp_df[2]\n",
    "        tmp_df[\"sample_id\"]=sample_id\n",
    "        result_df=get_title_text(text,tmp_df) if result_df is None else pd.concat([result_df,get_title_text(text,tmp_df)])\n",
    "    return result_df.reset_index(drop=True)\n",
    "    \n",
    "val_product_text=get_product_text(val_content_df)\n",
    "# train_product_text=get_product_text(train_content_df)\n",
    "# test_product_text=get_product_text(test_content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.34086359736917354"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "  def get_F1(val_pred, val_true):\n",
    "      val_pred = list(val_pred)\n",
    "      val_true = list(val_true)\n",
    "      curr = list(set(val_pred).intersection(set(val_true)))\n",
    "      R = len(curr)/len(val_true)\n",
    "      P = len(curr)/len(val_pred)\n",
    "      return 2*P*R/(P+R)\n",
    "\n",
    "  r = pd.merge(val_df[['sample_id']], train_outputs, on='sample_id', how='left')\n",
    "  val_true = r['sample_id'].astype(str) + r['理财产品名称'].astype(str)\n",
    "    # r.to_excel(\"result_after_drop.xlsx\",index=None)\n",
    "  r=val_product_text.drop_duplicates(subset=[\"sanple_id\",0])\n",
    "\n",
    "  val_pred = r['sanple_id'].astype(str) + r[0].astype(str)\n",
    "  score = get_F1(val_pred, val_true)\n",
    "  score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'1837', '9967', '3622', '3982', '5288', '5614', '9329', '125', '3327', '5227', '2430', '2547', '7465', '185', '1328', '5107', '1852', '3993', '11025', '1009', '7203', '10803', '8099', '3979', '9399', '3319', '10446', '7617', '5126', '4185', '9129', '3052', '10031', '2549', '1713', '1238', '10120', '5592', '6486', '5128', '4107', '5447', '1464', '2410', '1234', '1832', '6492', '7751', '7124', '3245', '8404', '5575', '8115', '8618', '7152', '953', '1789', '7505', '5116', '6697', '10122', '4522', '1783', '1172', '7748', '10121', '7175', '1982', '4972', '6842', '5596', '5135', '6706', '1755', '7600', '3605', '4275', '3983', '4420', '5226', '3989', '3604', '3089', '10105', '3945', '3961', '7204', '10974', '3247', '10177', '1631', '1070', '4261', '3974', '4202', '6840', '7618', '10460', '7182', '4406', '10131', '2565', '9652', '6966', '5891', '9330', '6684', '1606', '6863', '9369', '9143', '6780', '1814', '9181', '1810', '5173', '4147', '8525', '7880', '10183', '8441', '7149', '5188', '10456', '1821', '5613', '10174', '1799', '3114', '7591', '5223', '10777', '1677', '4568', '7753', '1255', '1245', '6215', '9318', '1123', '1914', '3243', '8281', '8927', '7593', '10106', '4160', '5398', '4526', '1592', '10115', '4187', '1638', '9216', '4521', '5071', '9634', '1825', '9210', '10020', '1655', '9219', '4127', '1815', '3987', '5006', '930', '10137', '1743', '7354', '9345', '5205', '5402', '1752', '7343', '10034', '5151', '5220', '8986', '2777', '184', '1779', '4504', '6207', '8381', '5098', '1561', '2537', '9214', '8951', '5190', '4988', '9444', '8992', '10027', '7405', '8612', '6431', '4571', '1775', '3599', '1312', '3624', '2412', '1488', '5092', '9992', '3967', '3988', '6439', '8477', '5579', '10412', '1868', '10208', '5622', '10454', '4170', '7278', '9547', '5240', '6843', '3997', '2533', '1566', '3249', '8519', '7210', '1584', '10021', '1709', '2654', '3761', '5085', '10217', '10453', '4969', '3200', '4980', '5097', '5250', '1647', '8422', '3242', '4552', '6386', '2390', '4546', '9639', '4174', '2498', '7197', '6700', '4631', '1244', '5252', '8408', '1242', '9635', '2566', '2557', '2778', '3417', '3969', '4106', '4639', '1803', '3603', '3581', '5396', '1959', '963', '1219', '4564', '1656', '5903', '7252', '8438', '3618', '7832', '1653', '943', '1984', '6113', '2949', '7263', '4057', '10933', '4549', '5110', '2880', '7740', '5130', '1806', '4525', '2414', '3415', '2744', '8620', '4120', '8973', '1226', '4989', '9366', '5175', '2457', '1202', '7264', '4139', '2090', '2779', '8631', '6389', '10789', '3087', '8126', '8392', '9833', '7828', '4255', '2474', '6563', '3043', '2765', '2782', '5192', '1769', '1249', '1215', '3084', '8437', '9334', '6029', '4993', '7202', '5583', '4188', '4172', '9706', '960', '2946', '9430', '10017', '1952', '1642', '1167', '5150', '5438', '6837', '7199', '1361', '3626', '8439', '10459', '1867', '959', '10796', '3236', '10176', '5202', '1675', '5154', '3606', '10793', '9131', '1222', '11113', '3600', '7882', '9363', '2405', '1173', '5008', '3589', '954', '5587', '8985', '9328', '41', '6471', '1757', '2424', '3773', '10423', '35', '3097', '5153', '1844', '2083', '2527', '118', '3777', '11039', '4171', '9642', '5419', '5277', '8116', '4538', '4151', '2668', '4165', '8430', '4533', '3111', '1781', '4266', '5104', '4210', '9541', '1574', '10188', '5598', '8967'}\n"
    }
   ],
   "source": [
    "a=val_product_text.drop_duplicates(subset=[\"sanple_id\",0])\n",
    "\n",
    "b=\"lhl\\验证集row数量对比.xlsx\"\n",
    "b=pd.read_excel(b).reset_index(drop=True)\n",
    "b[\"sample_id\"]=b[\"sample_id\"].astype(str)\n",
    "b=b[b[\"实际\"]<=4]\n",
    "a=set(list(pd.merge(a,b,left_on=\"sanple_id\",right_on=\"sample_id\")[\"sample_id\"].values))\n",
    "b=set(list(b[\"sample_id\"].values))\n",
    "print(b.difference(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理财名称所属文本提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理财信息字段提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理财信息字段整合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检验筛选"
   ]
  }
 ]
}