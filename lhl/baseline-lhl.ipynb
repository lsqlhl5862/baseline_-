{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关包\n",
    "import os\n",
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from io import StringIO\n",
    "from datetime import datetime \n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from tqdm.autonotebook import *\n",
    "import pdfplumber\n",
    "tqdm.pandas()\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF解析原始数据 \n",
    "## 加载数据并采用pdfplumber抽取PDF中的文字和表格\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id       认购日期        理财产品名称     产品发行方名称    理财类型  认购金额(万元)  \\\n0          1 2019-03-27         汇聚金1号  中融国际信托有限公司      信托   10000.0   \n1          1 2019-03-27  招商银行步步生金8699        招商银行  银行理财产品     200.0   \n\n       产品起息日      产品到息日  产品期限  资金来源    实际购买公司名称 实际购买公司和上市公司关系 买卖方是否有关联关系  \\\n0 2019-03-27 2019-09-23  180天  自有资金  恒生电子股份有限公司          公司本身          否   \n1 2019-03-27        NaT   NaN  自有资金  恒生电子股份有限公司          公司本身          否   \n\n        公告日期  \n0 2019-04-25  \n1 2019-04-25  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>认购日期</th>\n      <th>理财产品名称</th>\n      <th>产品发行方名称</th>\n      <th>理财类型</th>\n      <th>认购金额(万元)</th>\n      <th>产品起息日</th>\n      <th>产品到息日</th>\n      <th>产品期限</th>\n      <th>资金来源</th>\n      <th>实际购买公司名称</th>\n      <th>实际购买公司和上市公司关系</th>\n      <th>买卖方是否有关联关系</th>\n      <th>公告日期</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2019-03-27</td>\n      <td>汇聚金1号</td>\n      <td>中融国际信托有限公司</td>\n      <td>信托</td>\n      <td>10000.0</td>\n      <td>2019-03-27</td>\n      <td>2019-09-23</td>\n      <td>180天</td>\n      <td>自有资金</td>\n      <td>恒生电子股份有限公司</td>\n      <td>公司本身</td>\n      <td>否</td>\n      <td>2019-04-25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2019-03-27</td>\n      <td>招商银行步步生金8699</td>\n      <td>招商银行</td>\n      <td>银行理财产品</td>\n      <td>200.0</td>\n      <td>2019-03-27</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>自有资金</td>\n      <td>恒生电子股份有限公司</td>\n      <td>公司本身</td>\n      <td>否</td>\n      <td>2019-04-25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id                  file_path  \\\n0          1  datasets/train_data/1.PDF   \n1          2  datasets/train_data/2.PDF   \n\n                                                text  \\\n0  ['                                            ...   \n1  ['                                            ...   \n\n                                               tabel  \n0  [[['', None, None, '', None, None, '', None, N...  \n1  [[['', None, None, '', None, None, '', None, N...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>file_path</th>\n      <th>text</th>\n      <th>tabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>datasets/train_data/1.PDF</td>\n      <td>['                                            ...</td>\n      <td>[[['', None, None, '', None, None, '', None, N...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>datasets/train_data/2.PDF</td>\n      <td>['                                            ...</td>\n      <td>[[['', None, None, '', None, None, '', None, N...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id                     file_path  \\\n0      11188  datasets/test_data/11188.PDF   \n1      11189  datasets/test_data/11189.PDF   \n\n                                                text tabel  \n0  ['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...    []  \n1  ['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...    []  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>file_path</th>\n      <th>text</th>\n      <th>tabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11188</td>\n      <td>datasets/test_data/11188.PDF</td>\n      <td>['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11189</td>\n      <td>datasets/test_data/11189.PDF</td>\n      <td>['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# 数据准备(train_output文件中格式有点问题，需要提前用excel或者wps打开然后另存为excel文件)\n",
    "train_outputs = pd.read_excel('../datasets/train_output.xlsx')\n",
    "\n",
    "# 获取pdf中文字和表格\n",
    "def extract_pdf_content(pdf_path):\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for index_page in np.arange(0, len(pdf.pages), 1):\n",
    "            # 读取多页\n",
    "            page = pdf.pages[index_page]   # 第n页的信息\n",
    "            text = page.extract_text()\n",
    "            text_list.append(text)\n",
    "            table = page.extract_tables()\n",
    "            for t in table:\n",
    "                table_list.append(t)\n",
    "    return text_list, table_list\n",
    "\n",
    "def get_dir_file(path):\n",
    "    '''\n",
    "    输入文件夹位置，输出整理好的dataframe\n",
    "    '''\n",
    "    path_list = os.listdir(path)\n",
    "    id_list = []\n",
    "    file_path_list = []\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    for i in tqdm(path_list):\n",
    "        if '.PDF' in i:\n",
    "            file_path = path + i\n",
    "            id_list.append(int(i.split('.')[0]))\n",
    "            file_path_list.append(file_path)\n",
    "            try:\n",
    "                text_temp, table_temp = extract_pdf_content(file_path)\n",
    "            except Exception:\n",
    "                print('此pdf无法读取')\n",
    "                text_temp, table_temp = [], []\n",
    "            text_list.append(text_temp)\n",
    "            table_list.append(table_temp)\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df['sample_id'] = id_list\n",
    "    df['file_path'] = file_path_list\n",
    "    df['text'] = text_list\n",
    "    df['tabel'] = table_list\n",
    "    df = df.sort_values('sample_id')\n",
    "    return df\n",
    "\n",
    "# 文件处理太慢，可持续化保存文件\n",
    "train_path = '../datasets/train.csv'\n",
    "if os.path.exists(train_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "else:\n",
    "    train_df = get_dir_file('datasets/train_data/')\n",
    "    train_df.to_csv(train_path,index=False)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "\n",
    "test_path =  '../datasets/test.csv'\n",
    "if os.path.exists(test_path):\n",
    "    test_df = pd.read_csv(test_path)\n",
    "else:\n",
    "    test_df = get_dir_file('datasets/test_data/')\n",
    "    test_df.to_csv(test_path,index=False)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "train_outputs.head(2)\n",
    "train_df.head(2)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造训练集验证集\n",
    "train_df = train_df.sample(frac=1, random_state=1017)\n",
    "val_df = train_df[:1800]\n",
    "train_df = train_df[1800:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理\n",
    "## 抽取整体数据（一个sampleid内此字段内容都相同）\n",
    "## 公告时间，实际购买公司"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.抽取公告时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:00<00:00, 2203.19it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.4583333333333333"
     },
     "metadata": {},
     "execution_count": 4
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:00<00:00, 2731.44it/s]\n"
    }
   ],
   "source": [
    "# 首先针对任务抽取时间（每个时间跟每个id是一一对应的）\n",
    "# 要不是取第一个时间，要不就是取最后一个时间（或者时间加一）这里可以建立一个模型预测\n",
    "# base这里面直接取最后一个时间作为发布日期\n",
    "\n",
    "CN_NUM = {\n",
    "    u'〇': 0, u'一': 1, u'二': 2, u'三': 3,\n",
    "    u'四': 4, u'五': 5, u'六': 6, u'七': 7,\n",
    "    u'八': 8, u'九': 9, u'零': 0, u'壹': 1,\n",
    "    u'贰': 2, u'叁': 3, u'肆': 4, u'伍': 5,\n",
    "    u'陆': 6, u'柒': 7, u'捌': 8, u'玖': 9,\n",
    "    u'貮': 2, u'两': 2,\n",
    "}\n",
    "\n",
    "\n",
    "def get_put_time_from_text(row):\n",
    "    row = row.replace(' ', '').replace('\\\\n', '')\n",
    "    for key in CN_NUM:\n",
    "        row = row.replace(key, str(CN_NUM[key]))   \n",
    "    r = row.replace(\"年\", \"-\").replace(\"月\", \"-\").replace(\"日\", \" \").replace(\"/\", \"-\").strip()\n",
    "    regex = \"(\\d{4}-\\d{1,2}-\\d{1,2})\"\n",
    "    r = re.findall(regex, r)\n",
    "    if len(r)==0:\n",
    "        return np.nan\n",
    "    time_str = r[-1]\n",
    "    first = time_str.split('-')[0]\n",
    "    second = time_str.split('-')[1]\n",
    "    last = time_str.split('-')[-1]\n",
    "    second = str.zfill(second, 2)\n",
    "    last = str.zfill(last, 2)\n",
    "    r = '-'.join([first, second, last])\n",
    "    return r\n",
    "\n",
    "val_result = pd.DataFrame()\n",
    "val_result['sample_id'] = val_df['sample_id']\n",
    "val_result['predict_time'] = val_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "test_gg = train_outputs.groupby('sample_id').apply(lambda row:list(row['公告日期'])[0]).reset_index()\n",
    "test_gg.columns = ['sample_id', 'time']\n",
    "val_result = pd.merge(val_result, test_gg, on='sample_id', how='left')\n",
    "\n",
    "# 判断验证集的准确率\n",
    "np.sum(val_result['predict_time'].astype(str) == val_result['time'].astype(str))/len(val_result)\n",
    "\n",
    "val_time = val_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "# test_time = test_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.抽取实际购买公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:00<00:00, 1912.85it/s]\n"
    }
   ],
   "source": [
    "# 抽取购买公司\n",
    "# 前几句话出现\n",
    "# 将其按照\\\\n 和空格切割\n",
    "def get_gm(row):\n",
    "    result = re.split('[\\\\\\\\n ]',row)\n",
    "    for i in result:\n",
    "        if '公司' in i:\n",
    "            return i\n",
    "\n",
    "val_gm = val_df.progress_apply(lambda row:get_gm(row['text']), axis=1)\n",
    "# test_gm = test_df.progress_apply(lambda row:get_gm(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.清洗提取出来的tabel数据，主要是清洗掉有问题的列 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:03<00:00, 510.93it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1419    [[银行名称, 产品类型, 投资金额, 起始日, 到期日, 实际收回本金, 实际投资收益],...\n1480    [[认购主体, 产品种类, 产品类型, 金额（万元）, 预期收益率（年化）, 产品期限, 利...\n5755                                                   []\n2446    [[序, 金额, 预计到期, 期限, 产品收益], [号, （万元）, 日期, （天）, 率...\n5657                                                   []\n                              ...                        \n392                                                    []\n177     [[关联, 产品名称, 金额（万, 起始日期, 期限, 确定], [否, 七天通知存款, 低...\n2767    [[受托人, 关联关系, 产品名称, 购买金额, 产品类型, 起始日, 到期日, 收益率],...\n6973                                                   []\n4840                                                   []\nName: tabel, Length: 1800, dtype: object"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# 将table转换格式以及处理\n",
    "def deal_tabel(row):\n",
    "    row = eval(row)\n",
    "    if len(row)==0:\n",
    "        return []\n",
    "    else:\n",
    "        new_row = []\n",
    "        for i in row:\n",
    "            for d in i:\n",
    "                new_temp = []\n",
    "                for h in d:\n",
    "                    # 这里处理空数据或者错误的数据\n",
    "                    h = str(h).replace('None', '').replace('\\n','').replace(' ', '')                    \n",
    "                    if h=='':\n",
    "                        continue\n",
    "                    if h=='.':\n",
    "                        continue\n",
    "                    if h=='/':\n",
    "                        continue\n",
    "                    new_temp.append(h)\n",
    "                new_row.append(new_temp)\n",
    "        # 这里判断是否构成一个完整得认购数据(通过一个list进行判断)\n",
    "        new_new_row = []\n",
    "        for i in new_row:\n",
    "            if len(i) == 0:\n",
    "                continue\n",
    "            elif len(i) <= 4:\n",
    "                continue\n",
    "            else:\n",
    "                new_new_row.append(i)\n",
    "        return new_new_row\n",
    "# train_df_tabel = train_df['tabel'].progress_apply(lambda row:deal_tabel(row))\n",
    "val_df_tabel = val_df['tabel'].progress_apply(lambda row:deal_tabel(row))\n",
    "\n",
    "# test_df_tabel = test_df['tabel'].progress_apply(lambda row:deal_tabel(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'sample_id'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2888\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2889\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sample_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-ee401fb8371a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_df_tabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sample_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         if (\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 991\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    992\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sample_id'"
     ]
    }
   ],
   "source": [
    "val_df_tabel[\"sample_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.抽取的是单独的数据包含\n",
    "#### 起息日，到息日， 金额，认购日期，产品发行方，理财产品"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#大量PDF的理财购买信息不在table中，而是在text中，此段为判断理财信息是否只需要从text中提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "title_num_char=[\"一、\",\"二、\",\"三、\",\"四、\",\"五、\",\"六、\",\"七、\",\"八、\",\"九、\",\"十、\",\"十一、\",\"十二、\",\"十三、\",\"十四、\",\"十五、\"]\n",
    "s_title_num_char=[\"（一）\",\"（二）\",\"（三）\",\"（四）\",\"（五）\",\"（六）\",\"（七）\",\"（八）\",\"（九）\",\"（十）\",\"（十一）\",\"（十二）\",\"（十三）\",\"（十四）\",\"（十五）\"]\n",
    "s_title_num_char.extend([\"[(]一[)]\",\"[(]二[)]\",\"[(]三[)]\",\"[(]四[)]\",\"[(]五[)]\",\"[(]六[)]\",\"[(]七[)]\",\"[(]八[)]\",\"[(]九[)]\",\"[(]十[)]\",\"[(]十一[)]\",\"[(]十二[)]\",\"[(]十三[)]\",\"[(]十四[)]\",\"[(]十五[)]\"])\n",
    "\n",
    "title_pos_words=[]\n",
    "title_neg_words=[\"备查\",\"日前\",\"过去\",\"履行\",\"审批\",\"程序\",\"风险\",\"措施\",\"影响\",\"累计\",\"赎回\",\"到期\"]\n",
    "\n",
    "\n",
    "def get_title(text):\n",
    "    global title_num_char\n",
    "    title_list=[]\n",
    "    title_type_list=[]\n",
    "    text_start_iter_list=[]\n",
    "    text_end_iter_list=[]\n",
    "    for item in title_num_char:\n",
    "        pattern = re.compile(item+r\"[ ]*?[^ ]+?[ ]\")\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(1)\n",
    "            text_end_iter_list.append(i.span(0)[1])\n",
    "    \n",
    "    # for item in title_list:\n",
    "    for item in s_title_num_char:\n",
    "        pattern = re.compile(item+r\"[ ]*?[^ ]+?[ ]\")\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(2)\n",
    "            text_end_iter_list.append(i.span(0)[1])\n",
    "\n",
    "    title_list.append(\"引言\")\n",
    "    title_type_list.append(1)\n",
    "    text_start_iter_list.append(0)\n",
    "    text_end_iter_list.append(0)\n",
    "\n",
    "    result_df=pd.DataFrame([title_list,title_type_list,text_start_iter_list,text_end_iter_list]).T.sort_values(by=2).reset_index(drop=True)\n",
    "    # print(result_df)\n",
    "    return result_df\n",
    "\n",
    "def get_title_text(text,title_df):\n",
    "    # print(title_df)\n",
    "    title_1_df=title_df[title_df[1]==1]\n",
    "    text_iter_list=[]\n",
    "    text_list=[]\n",
    "    # print(title_1_df)\n",
    "    for iter1,iter2 in title_1_df[[2,3]].values:\n",
    "        # print(iter1)\n",
    "        if(len(text_iter_list)!=0):\n",
    "            text_iter_list.append(iter1)\n",
    "        text_iter_list.append(iter2)\n",
    "    # text_iter_list.append(text_iter_list[len(text_iter_list)-1])\n",
    "    text_iter_list.append(len(text))\n",
    "    for index in range(int(len(text_iter_list)/2)):\n",
    "        text_list.append(text[text_iter_list[2*index]:text_iter_list[2*index+1]])\n",
    "    \n",
    "    title_1_df[4]=text_list\n",
    "\n",
    "    return title_1_df.reset_index(drop=True)\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "def judge_title(sample_id=0,text=r\"test\\n\"):\n",
    "    # print(text)\n",
    "    text=text.replace(r\"\\n\",\"\")\n",
    "    title_df=get_title(text)\n",
    "    title_df[\"sample_id\"]=[sample_id for x in range(title_df.shape[0])]\n",
    "    # print(title_df)\n",
    "    title_1_df=get_title_text(text,title_df)[[\"sample_id\",0,1,2,3,4]]\n",
    "\n",
    "    \n",
    "\n",
    "    global val_df\n",
    "    global train_outputs\n",
    "    val_true_name=train_outputs[train_outputs[\"sample_id\"]==sample_id][\"理财产品名称\"]\n",
    "    \n",
    "    # print(title_1_df)\n",
    "    title_1_df[\"匹配分数\"]=0\n",
    "    for item in val_true_name:\n",
    "        title_1_df[\"匹配分数\"]=title_1_df[\"匹配分数\"]+title_1_df[4].apply(lambda x:fuzz.partial_ratio(x,str(item)))\n",
    "    \n",
    "    max_score=np.max(title_1_df[\"匹配分数\"])\n",
    "    title_1_df[\"是否为信息来源\"]=title_1_df[\"匹配分数\"].apply(lambda x:0 if x < max_score else 1)\n",
    "    # print(title_1_df)\n",
    "\n",
    "\n",
    "    return title_1_df\n",
    "    # print(title_list)\n",
    "\n",
    "judge_title_result=None\n",
    "\n",
    "\n",
    "# for sample_id,text in tqdm(train_df[[\"sample_id\",\"text\"]].values):\n",
    "#     # print(sample_id)\n",
    "#     # print(text)\n",
    "#     judge_title_result= judge_title(sample_id,text) if judge_title_result is None else pd.concat([judge_title_result,judge_title(sample_id,text)])\n",
    "\n",
    "# judge_title_result.to_excel(\"训练集段落标题分类结果.xlsx\",index=None)\n",
    "\n",
    "\n",
    "# is_from_text(val_df[val_df[\"sample_id\"]==930][\"sample_id\"].iloc[0],val_df[val_df[\"sample_id\"]==930][\"text\"].iloc[0])\n",
    "# is_from_text(val_df[val_df[\"sample_id\"]==125][\"text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [00:22<00:00, 79.55it/s]\n"
    }
   ],
   "source": [
    "title_num_char=[\"一、\",\"二、\",\"三、\",\"四、\",\"五、\",\"六、\",\"七、\",\"八、\",\"九、\",\"十、\",\"十一、\",\"十二、\",\"十三、\",\"十四、\",\"十五、\"]\n",
    "s_title_num_char=[\"（一）\",\"（二）\",\"（三）\",\"（四）\",\"（五）\",\"（六）\",\"（七）\",\"（八）\",\"（九）\",\"（十）\",\"（十一）\",\"（十二）\",\"（十三）\",\"（十四）\",\"（十五）\"]\n",
    "s_title_num_char.extend([\"[(]一[)]\",\"[(]二[)]\",\"[(]三[)]\",\"[(]四[)]\",\"[(]五[)]\",\"[(]六[)]\",\"[(]七[)]\",\"[(]八[)]\",\"[(]九[)]\",\"[(]十[)]\",\"[(]十一[)]\",\"[(]十二[)]\",\"[(]十三[)]\",\"[(]十四[)]\",\"[(]十五[)]\"])\n",
    "\n",
    "title_pos_words=[]\n",
    "title_neg_words=[\"备查\",\"日前\",\"过去\",\"履行\",\"审批\",\"程序\",\"风险\",\"措施\",\"影响\",\"累计\",\"赎回\",\"到期\",\"截至\"]\n",
    "\n",
    "\n",
    "def get_title(text):\n",
    "    global title_num_char\n",
    "    title_list=[]\n",
    "    title_type_list=[]\n",
    "    text_start_iter_list=[]\n",
    "    text_end_iter_list=[]\n",
    "    for item in title_num_char:\n",
    "        pattern = re.compile(item+r\"[ ]*?[^ ]+?[ ]\")\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(1)\n",
    "            text_end_iter_list.append(i.span(0)[1])\n",
    "    \n",
    "    # for item in title_list:\n",
    "    for item in s_title_num_char:\n",
    "        pattern = re.compile(item+r\"[ ]*?[^ ]+?[ ]\")\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(2)\n",
    "            text_end_iter_list.append(i.span(0)[1])\n",
    "\n",
    "    title_list.append(\"引言\")\n",
    "    title_type_list.append(1)\n",
    "    text_start_iter_list.append(0)\n",
    "    text_end_iter_list.append(0)\n",
    "\n",
    "    result_df=pd.DataFrame([title_list,title_type_list,text_start_iter_list,text_end_iter_list]).T.sort_values(by=2).reset_index(drop=True)\n",
    "    # print(result_df)\n",
    "    return result_df\n",
    "\n",
    "def get_title_text(text,title_df):\n",
    "    # print(title_df)\n",
    "    title_1_df=title_df[title_df[1]==1]\n",
    "    text_iter_list=[]\n",
    "    text_list=[]\n",
    "    # print(title_1_df)\n",
    "    for iter1,iter2 in title_1_df[[2,3]].values:\n",
    "        # print(iter1)\n",
    "        if(len(text_iter_list)!=0):\n",
    "            text_iter_list.append(iter1)\n",
    "        text_iter_list.append(iter2)\n",
    "    # text_iter_list.append(text_iter_list[len(text_iter_list)-1])\n",
    "    text_iter_list.append(len(text))\n",
    "    for index in range(int(len(text_iter_list)/2)):\n",
    "        text_list.append(text[text_iter_list[2*index]:text_iter_list[2*index+1]])\n",
    "    \n",
    "    title_1_df[4]=text_list\n",
    "\n",
    "    return title_1_df.reset_index(drop=True)\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "def judge_title(sample_id=0,text=r\"test\\n\"):\n",
    "    # print(text)\n",
    "    text=text.replace(r\"\\n\",\"\")\n",
    "    title_df=get_title(text)\n",
    "    title_df[\"sample_id\"]=[sample_id for x in range(title_df.shape[0])]\n",
    "    # print(title_df)\n",
    "    title_1_df=get_title_text(text,title_df)[[\"sample_id\",0,1,2,3,4]]\n",
    "\n",
    "    \n",
    "\n",
    "    global val_df\n",
    "    global train_outputs\n",
    "    val_true_name=train_outputs[train_outputs[\"sample_id\"]==sample_id][\"理财产品名称\"]\n",
    "    \n",
    "    index=0\n",
    "    neg_index=[]\n",
    "    for title_des in title_1_df[0].values:\n",
    "        for item in title_neg_words:\n",
    "            if re.search(item,title_des) is not None:\n",
    "                neg_index.append(index)\n",
    "                break\n",
    "        index+=1\n",
    "\n",
    "\n",
    "    return title_1_df.drop(neg_index)\n",
    "    # print(title_list)\n",
    "\n",
    "judge_title_result=None\n",
    "\n",
    "\n",
    "for sample_id,text in tqdm(val_df[[\"sample_id\",\"text\"]].values):\n",
    "    # print(sample_id)\n",
    "    # print(text)\n",
    "    judge_title_result= judge_title(sample_id,text) if judge_title_result is None else pd.concat([judge_title_result,judge_title(sample_id,text)])\n",
    "\n",
    "# judge_title_result.to_excel(\"训练集段落标题分类结果.xlsx\",index=None)\n",
    "\n",
    "\n",
    "# is_from_text(val_df[val_df[\"sample_id\"]==930][\"sample_id\"].iloc[0],val_df[val_df[\"sample_id\"]==930][\"text\"].iloc[0])\n",
    "# is_from_text(val_df[val_df[\"sample_id\"]==125][\"text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id                  0  1    2    3  \\\n0       1067                 引言  1    0    0   \n1       1067  一、闲置募集资金购买理财产品情况   1  272  289   \n2       1067    二、自有资金购买理财产品情况   1  678  693   \n\n                                                   4  \n0  ['证券代码：603508        证券简称：思维列控       公告编号：2016...  \n1  委托  预期年序 受托 资金 委托理财产品 产品  期限公司  金额  起息日  到息日  ...  \n2  ', '委托金 预期年序 受托 资金 委托理财产品 产品  期限公司  额（万 起息日  到...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1067</td>\n      <td>引言</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['证券代码：603508        证券简称：思维列控       公告编号：2016...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1067</td>\n      <td>一、闲置募集资金购买理财产品情况</td>\n      <td>1</td>\n      <td>272</td>\n      <td>289</td>\n      <td>委托  预期年序 受托 资金 委托理财产品 产品  期限公司  金额  起息日  到息日  ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1067</td>\n      <td>二、自有资金购买理财产品情况</td>\n      <td>1</td>\n      <td>678</td>\n      <td>693</td>\n      <td>', '委托金 预期年序 受托 资金 委托理财产品 产品  期限公司  额（万 起息日  到...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "judge_title(1067,train_df[train_df[\"sample_id\"]==1067][\"text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1800/1800 [12:49<00:00,  2.34it/s]\n"
    }
   ],
   "source": [
    "# 直接提取时间\n",
    "# 如果出现两个时间第一个就是起息日，第二个就是到期日\n",
    "# 如果出现一个时间就是起息日\n",
    "# 出现的第一个money就是最后的金额\n",
    "# 从这里面抽取所有序列\n",
    "# 这里认为有逗号出现的就是money\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    " \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "from src.time_extractor import TimeFinder\n",
    "import datetime\n",
    "def get_list_data(df):\n",
    "    df = list(df)\n",
    "    new_df = []\n",
    "    for i in tqdm(df):\n",
    "        temp_df = []\n",
    "        for h in i:\n",
    "            new_h = []\n",
    "            for digital in h:\n",
    "                if ',' in digital:\n",
    "                    # 这里也是为了统一数据有些是用元，有些是用万元\n",
    "                    try:\n",
    "                        ttt = float(digital.replace(',', '').replace('万元', '').replace('人民币', '').replace('元', ''))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    if ttt > 20000:\n",
    "                        ttt = ttt/10000\n",
    "                    new_h.append(ttt)\n",
    "                else:\n",
    "                    continue\n",
    "            if len(new_h) == 0:\n",
    "                continue\n",
    "            temp_single = {}\n",
    "            a = '_'.join(h)\n",
    "            # 抽取时间和money\n",
    "            t = TimeFinder()\n",
    "            time_all = t.find_time(a)\n",
    "            if time_all == None:\n",
    "                continue\n",
    "            rgrq = time_all[0]\n",
    "            cpqxr = time_all[0]\n",
    "            if len(time_all) > 1:\n",
    "                try:\n",
    "                    cpdxr = time_all[1]\n",
    "                    # 相减\n",
    "                    d1 = datetime.datetime.strptime(cpqxr, '%Y-%m-%d')\n",
    "                    d2 = datetime.datetime.strptime(cpdxr, '%Y-%m-%d')\n",
    "                    d = d2 - d1\n",
    "                    cpqx = str(d.days) + '天'\n",
    "                except Exception:\n",
    "                    cpdxr = np.nan\n",
    "                    cpqx = np.nan\n",
    "            else:\n",
    "                cpdxr = np.nan\n",
    "                cpqx = np.nan\n",
    "                \n",
    "            # 筛选出除开数字与包含时间的列\n",
    "            # 末尾是\n",
    "            last_two = ['公司', '银行', '信托', '证券',  '分行', '支行', '中心', '业部', '商行', '建行']\n",
    "            mowei = np.nan\n",
    "            selected_bank_and_works = []\n",
    "            for l in h:\n",
    "                new_l = list(str(l))\n",
    "                new_l_test = ''.join(l[-2:])\n",
    "                if new_l_test in last_two:\n",
    "                    mowei = l\n",
    "                    continue\n",
    "                if '资金' in l:\n",
    "                    continue\n",
    "                if '收益' in l:\n",
    "                    continue\n",
    "                if '到期' in l:\n",
    "                    continue\n",
    "                if ',' in l:\n",
    "                    continue\n",
    "                if '.' in l:\n",
    "                    continue\n",
    "                if '/' in l:\n",
    "                    continue\n",
    "                if '年' in l:\n",
    "                    continue\n",
    "                if '-' in l:\n",
    "                    continue\n",
    "                if len(l) < 4:\n",
    "                    continue\n",
    "                if is_number(l):\n",
    "                    continue\n",
    "                selected_bank_and_works.append(l)\n",
    "            if len(selected_bank_and_works) < 1:\n",
    "                continue\n",
    "            \n",
    "            temp_single['认购日期'] = rgrq\n",
    "            temp_single['产品起息日'] = cpqxr\n",
    "            temp_single['产品到期日'] = cpdxr\n",
    "            temp_single['产品期限'] = cpqx\n",
    "            temp_single['认购金额(万元)'] = new_h[0]\n",
    "            temp_single['产品发行方名称'] = mowei\n",
    "            temp_single['理财产品名称'] = selected_bank_and_works[0]\n",
    "            temp_df.append(temp_single)\n",
    "        new_df.append(temp_df)\n",
    "    return new_df\n",
    "\n",
    "val_contain_date = get_list_data(val_df_tabel)\n",
    "# test_contain_data = get_list_data(test_df_tabel) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.汇总整理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将前面提取到的数据整理成对应格式\n",
    "sample_id_list = []\n",
    "rgrq_list = []\n",
    "lccp_list = []\n",
    "cpfxf_list = []\n",
    "rgje_list = []\n",
    "cpqxr_list = []\n",
    "cpdxr_list = []\n",
    "cpqx_list = []\n",
    "sjgmgsmc_list = []\n",
    "ggrq_list = []\n",
    "\n",
    "sample_id = list(val_df['sample_id'])\n",
    "gg = list(val_gm)\n",
    "time = list(val_time)\n",
    "for i, value in enumerate(sample_id):\n",
    "    for j in val_contain_date[i]:\n",
    "        sample_id_list.append(sample_id[i])\n",
    "        rgrq_list.append(j['认购日期'])\n",
    "        lccp_list.append(j['理财产品名称'])\n",
    "        cpfxf_list.append(j['产品发行方名称'])\n",
    "        rgje_list.append(j['认购金额(万元)'])\n",
    "        cpqxr_list.append(j['产品起息日'])\n",
    "        cpdxr_list.append(j['产品到期日'])\n",
    "        cpqx_list.append(j['产品期限'])\n",
    "        sjgmgsmc_list.append(gg[i])\n",
    "        ggrq_list.append(time[i])\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['sample_id'] = sample_id_list\n",
    "result['认购日期'] = rgrq_list\n",
    "result['理财产品名称'] = lccp_list\n",
    "result['产品发行方名称'] = cpfxf_list\n",
    "result['认购金额(万元)'] = rgje_list\n",
    "result['产品起息日'] = cpqxr_list\n",
    "result['产品到期日'] = cpdxr_list\n",
    "result['产品期限'] = cpqx_list\n",
    "result['实际购买公司名称'] = sjgmgsmc_list\n",
    "result['公告日期'] = ggrq_list\n",
    "val_result = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_id_list = []\n",
    "rgrq_list = []\n",
    "lccp_list = []\n",
    "cpfxf_list = []\n",
    "rgje_list = []\n",
    "cpqxr_list = []\n",
    "cpdxr_list = []\n",
    "cpqx_list = []\n",
    "sjgmgsmc_list = []\n",
    "ggrq_list = []\n",
    "\n",
    "sample_id = list(test_df['sample_id'])\n",
    "gg = list(test_gm)\n",
    "time = list(test_time)\n",
    "for i, value in enumerate(sample_id):\n",
    "    for j in test_contain_data[i]:\n",
    "        sample_id_list.append(sample_id[i])\n",
    "        rgrq_list.append(j['认购日期'])\n",
    "        lccp_list.append(j['理财产品名称'])\n",
    "        cpfxf_list.append(j['产品发行方名称'])\n",
    "        rgje_list.append(j['认购金额(万元)'])\n",
    "        cpqxr_list.append(j['产品起息日'])\n",
    "        cpdxr_list.append(j['产品到期日'])\n",
    "        cpqx_list.append(j['产品期限'])\n",
    "        sjgmgsmc_list.append(gg[i])\n",
    "        ggrq_list.append(time[i])\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['sample_id'] = sample_id_list\n",
    "result['认购日期'] = rgrq_list\n",
    "result['理财产品名称'] = lccp_list\n",
    "result['产品发行方名称'] = cpfxf_list\n",
    "result['认购金额(万元)'] = rgje_list\n",
    "result['产品起息日'] = cpqxr_list\n",
    "result['产品到期日'] = cpdxr_list\n",
    "result['产品期限'] = cpqx_list\n",
    "result['实际购买公司名称'] = sjgmgsmc_list\n",
    "result['公告日期'] = ggrq_list\n",
    "test_result = result\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.022710310267619153"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "  def get_F1(val_pred, val_true):\n",
    "      val_pred = list(val_pred)\n",
    "      val_true = list(val_true)\n",
    "      curr = list(set(val_pred).intersection(set(val_true)))\n",
    "      R = len(curr)/len(val_true)\n",
    "      P = len(curr)/len(val_pred)\n",
    "      return 2*P*R/(P+R)\n",
    "\n",
    "  r = pd.merge(val_df[['sample_id']], train_outputs, on='sample_id', how='left')\n",
    "  val_true = r['sample_id'].astype(str) + r['认购日期'].astype(str) + r['理财产品名称'].astype(str) + r['认购金额(万元)'].astype(str) + r['产品起息日'].astype(str)+ r['产品到息日'].astype(str) + r['产品期限'].astype(str) + r['实际购买公司名称'].astype(str)  + r['公告日期'].astype(str)+r['产品发行方名称'].astype(str)\n",
    "\n",
    "  r = val_result\n",
    "  val_pred = r['sample_id'].astype(str) + r['认购日期'].astype(str) + r['理财产品名称'].astype(str) + r['认购金额(万元)'].astype(str) + r['产品起息日'].astype(str)+ r['产品到期日'].astype(str) + r['产品期限'].astype(str) + r['实际购买公司名称'].astype(str)   + r['公告日期'].astype(str)+r['产品发行方名称'].astype(str)\n",
    "\n",
    "  score = get_F1(val_pred, val_true)\n",
    "  score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_judge(result):\n",
    "    global judge_title_result\n",
    "    score_limit=30\n",
    "    drop_list=[]\n",
    "    index=0\n",
    "    for sample_id,product_name in tqdm(result[[\"sample_id\",\"理财产品名称\"]].values):\n",
    "        score_list=[]\n",
    "        for text in judge_title_result[judge_title_result[\"sample_id\"]==sample_id][4].values:\n",
    "            score_list.append(fuzz.partial_ratio(product_name,text))\n",
    "        if np.max(pd.DataFrame(score_list)[0])<=score_limit:\n",
    "            drop_list.append(index)\n",
    "        index+=1 \n",
    "    \n",
    "    return result.copy().drop(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 13095/13095 [00:50<00:00, 260.86it/s](9975, 10)\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.02442767617342371"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "  def get_F1(val_pred, val_true):\n",
    "      val_pred = list(val_pred)\n",
    "      val_true = list(val_true)\n",
    "      curr = list(set(val_pred).intersection(set(val_true)))\n",
    "      R = len(curr)/len(val_true)\n",
    "      P = len(curr)/len(val_pred)\n",
    "      return 2*P*R/(P+R)\n",
    "\n",
    "  r = pd.merge(val_df[['sample_id']], train_outputs, on='sample_id', how='left')\n",
    "  val_true = r['sample_id'].astype(str) + r['认购日期'].astype(str) + r['理财产品名称'].astype(str) + r['认购金额(万元)'].astype(str) + r['产品起息日'].astype(str)+ r['产品到息日'].astype(str) + r['产品期限'].astype(str) + r['实际购买公司名称'].astype(str)  + r['公告日期'].astype(str)+r['产品发行方名称'].astype(str)\n",
    "\n",
    "  r = drop_judge(result)\n",
    "  print(r.shape)\n",
    "  val_pred = r['sample_id'].astype(str) + r['认购日期'].astype(str) + r['理财产品名称'].astype(str) + r['认购金额(万元)'].astype(str) + r['产品起息日'].astype(str)+ r['产品到期日'].astype(str) + r['产品期限'].astype(str) + r['实际购买公司名称'].astype(str)   + r['公告日期'].astype(str)+r['产品发行方名称'].astype(str)\n",
    "\n",
    "  score = get_F1(val_pred, val_true)\n",
    "  score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "val_result_file=val_result.sort_values(by='sample_id').reset_index(drop=True)\n",
    "val_true_file=pd.merge(train_outputs, val_df['sample_id'], on='sample_id',how=\"right\").sort_values(by=\"sample_id\").reset_index(drop=True)\n",
    "# train_outputs\n",
    "# val_result_file\n",
    "# val_true_file\n",
    "val_id_list=val_result_file[\"sample_id\"].unique()\n",
    "val_id_count={}\n",
    "val_id_count[\"sample_id\"]=[]\n",
    "val_id_count[\"预测\"]=[]\n",
    "val_id_count[\"实际\"]=[]\n",
    "for item in val_id_list:\n",
    "    val_id_count[\"sample_id\"].append(item)\n",
    "    val_id_count[\"预测\"].append(val_result_file[val_result_file[\"sample_id\"]==item].shape[0])\n",
    "    val_id_count[\"实际\"].append(val_true_file[val_true_file[\"sample_id\"]==item].shape[0])\n",
    "\n",
    "val_id_count=pd.DataFrame(val_id_count)\n",
    "val_id_count[\"差值\"]=val_id_count[\"预测\"]-val_id_count[\"实际\"]\n",
    "print(val_id_count[val_id_count[\"差值\"]==0].shape[0]/val_id_count.shape[0])\n",
    "val_id_count.to_excel(\"验证集row数量对比.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}