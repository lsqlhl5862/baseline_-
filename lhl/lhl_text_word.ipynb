{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关包\n",
    "import os\n",
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from io import StringIO\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from tqdm.autonotebook import *\n",
    "import pdfplumber\n",
    "tqdm.pandas()\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from tgrocery import Grocery\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF解析原始数据 \n",
    "## 加载数据并采用pdfplumber抽取PDF中的文字和表格\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id       认购日期        理财产品名称     产品发行方名称    理财类型  认购金额(万元)  \\\n0          1 2019-03-27         汇聚金1号  中融国际信托有限公司      信托   10000.0   \n1          1 2019-03-27  招商银行步步生金8699        招商银行  银行理财产品     200.0   \n\n       产品起息日      产品到息日  产品期限  资金来源    实际购买公司名称 实际购买公司和上市公司关系 买卖方是否有关联关系  \\\n0 2019-03-27 2019-09-23  180天  自有资金  恒生电子股份有限公司          公司本身          否   \n1 2019-03-27        NaT   NaN  自有资金  恒生电子股份有限公司          公司本身          否   \n\n        公告日期  \n0 2019-04-25  \n1 2019-04-25  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>认购日期</th>\n      <th>理财产品名称</th>\n      <th>产品发行方名称</th>\n      <th>理财类型</th>\n      <th>认购金额(万元)</th>\n      <th>产品起息日</th>\n      <th>产品到息日</th>\n      <th>产品期限</th>\n      <th>资金来源</th>\n      <th>实际购买公司名称</th>\n      <th>实际购买公司和上市公司关系</th>\n      <th>买卖方是否有关联关系</th>\n      <th>公告日期</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2019-03-27</td>\n      <td>汇聚金1号</td>\n      <td>中融国际信托有限公司</td>\n      <td>信托</td>\n      <td>10000.0</td>\n      <td>2019-03-27</td>\n      <td>2019-09-23</td>\n      <td>180天</td>\n      <td>自有资金</td>\n      <td>恒生电子股份有限公司</td>\n      <td>公司本身</td>\n      <td>否</td>\n      <td>2019-04-25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2019-03-27</td>\n      <td>招商银行步步生金8699</td>\n      <td>招商银行</td>\n      <td>银行理财产品</td>\n      <td>200.0</td>\n      <td>2019-03-27</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>自有资金</td>\n      <td>恒生电子股份有限公司</td>\n      <td>公司本身</td>\n      <td>否</td>\n      <td>2019-04-25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id                  file_path  \\\n0          1  datasets/train_data/1.PDF   \n1          2  datasets/train_data/2.PDF   \n\n                                                text  \\\n0  ['                                            ...   \n1  ['                                            ...   \n\n                                               tabel  \n0  [[['', None, None, '', None, None, '', None, N...  \n1  [[['', None, None, '', None, None, '', None, N...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>file_path</th>\n      <th>text</th>\n      <th>tabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>datasets/train_data/1.PDF</td>\n      <td>['                                            ...</td>\n      <td>[[['', None, None, '', None, None, '', None, N...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>datasets/train_data/2.PDF</td>\n      <td>['                                            ...</td>\n      <td>[[['', None, None, '', None, None, '', None, N...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample_id                     file_path  \\\n0      11188  datasets/test_data/11188.PDF   \n1      11189  datasets/test_data/11189.PDF   \n\n                                                text tabel  \n0  ['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...    []  \n1  ['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...    []  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>file_path</th>\n      <th>text</th>\n      <th>tabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11188</td>\n      <td>datasets/test_data/11188.PDF</td>\n      <td>['北京京西文化旅游股份有限公司监事会\\n \\n \\n关于使用部分闲置募集资金购买理财产品的...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11189</td>\n      <td>datasets/test_data/11189.PDF</td>\n      <td>['北京京西文化旅游股份有限公司 \\n监事会关于使用部分自有资金购买理财产品的意见 \\n根据...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# 数据准备(train_output文件中格式有点问题，需要提前用excel或者wps打开然后另存为excel文件)\n",
    "train_outputs = pd.read_excel('../datasets/train_output.xlsx')\n",
    "\n",
    "# 获取pdf中文字和表格\n",
    "def extract_pdf_content(pdf_path):\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for index_page in np.arange(0, len(pdf.pages), 1):\n",
    "            # 读取多页\n",
    "            page = pdf.pages[index_page]   # 第n页的信息\n",
    "            text = page.extract_text()\n",
    "            text_list.append(text)\n",
    "            table = page.extract_tables()\n",
    "            for t in table:\n",
    "                table_list.append(t)\n",
    "    return text_list, table_list\n",
    "\n",
    "def get_dir_file(path):\n",
    "    '''\n",
    "    输入文件夹位置，输出整理好的dataframe\n",
    "    '''\n",
    "    path_list = os.listdir(path)\n",
    "    id_list = []\n",
    "    file_path_list = []\n",
    "    text_list = []\n",
    "    table_list = []\n",
    "    for i in tqdm(path_list):\n",
    "        if '.PDF' in i:\n",
    "            file_path = path + i\n",
    "            id_list.append(int(i.split('.')[0]))\n",
    "            file_path_list.append(file_path)\n",
    "            try:\n",
    "                text_temp, table_temp = extract_pdf_content(file_path)\n",
    "            except Exception:\n",
    "                print('此pdf无法读取')\n",
    "                text_temp, table_temp = [], []\n",
    "            text_list.append(text_temp)\n",
    "            table_list.append(table_temp)\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df['sample_id'] = id_list\n",
    "    df['file_path'] = file_path_list\n",
    "    df['text'] = text_list\n",
    "    df['tabel'] = table_list\n",
    "    df = df.sort_values('sample_id')\n",
    "    return df\n",
    "\n",
    "# 文件处理太慢，可持续化保存文件\n",
    "train_path = '../datasets/train.csv'\n",
    "if os.path.exists(train_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "else:\n",
    "    train_df = get_dir_file('datasets/train_data/')\n",
    "    train_df.to_csv(train_path,index=False)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "\n",
    "test_path =  '../datasets/test.csv'\n",
    "if os.path.exists(test_path):\n",
    "    test_df = pd.read_csv(test_path)\n",
    "else:\n",
    "    test_df = get_dir_file('datasets/test_data/')\n",
    "    test_df.to_csv(test_path,index=False)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "train_outputs.head(2)\n",
    "train_df.head(2)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造训练集验证集\n",
    "train_df = train_df.sample(frac=1, random_state=1017)\n",
    "val_df = train_df[:1800]\n",
    "train_df = train_df[1800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理\n",
    "## 抽取整体数据（一个sampleid内此字段内容都相同）\n",
    "## 公告时间，实际购买公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "认购金额(万元)\n认购日期\n资金来源\n实际购买公司和上市公司关系\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                              text_1 label_1\n0                 中银保本理财-人民币按期开放理财产品    理财产品\n1                 中银保本理财-人民币按期开放理财产品    理财产品\n2                        与利率挂钩的结构性产品    理财产品\n3             广发银行“薪加薪”16号XJXCKJ2578    理财产品\n4       兴业银行“金雪球-优悦”保本开放式人民币理财产品(2M)    理财产品\n...                              ...     ...\n185903                        控股参股公司      其它\n185904                        控股参股公司      其它\n185905                        控股参股公司      其它\n185906                        控股参股公司      其它\n185907                        控股参股公司      其它\n\n[185908 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_1</th>\n      <th>label_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>中银保本理财-人民币按期开放理财产品</td>\n      <td>理财产品</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>中银保本理财-人民币按期开放理财产品</td>\n      <td>理财产品</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>与利率挂钩的结构性产品</td>\n      <td>理财产品</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>广发银行“薪加薪”16号XJXCKJ2578</td>\n      <td>理财产品</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>兴业银行“金雪球-优悦”保本开放式人民币理财产品(2M)</td>\n      <td>理财产品</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>185903</th>\n      <td>控股参股公司</td>\n      <td>其它</td>\n    </tr>\n    <tr>\n      <th>185904</th>\n      <td>控股参股公司</td>\n      <td>其它</td>\n    </tr>\n    <tr>\n      <th>185905</th>\n      <td>控股参股公司</td>\n      <td>其它</td>\n    </tr>\n    <tr>\n      <th>185906</th>\n      <td>控股参股公司</td>\n      <td>其它</td>\n    </tr>\n    <tr>\n      <th>185907</th>\n      <td>控股参股公司</td>\n      <td>其它</td>\n    </tr>\n  </tbody>\n</table>\n<p>185908 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tgrocery.Grocery at 0x132052fa250>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# 提取公司\n",
    "# train_lstm_input = pd.merge(train_df, train_outputs, on='sample_id', how='left')\n",
    "# result_matrix\n",
    "train_lstm_input = pd.merge(train_df, train_outputs, on='sample_id', how='left')\n",
    "\n",
    "train_lstm_input = train_lstm_input.fillna('否')\n",
    "\n",
    "# label_1理财类型-10  label_2资金来源-3 label_3实际购买公司和上市公司关系-3 label_4买卖方是否有关联关系-2\n",
    "# label_2 = LabelEncoder()\n",
    "# label_3 = LabelEncoder()\n",
    "# label_4 = LabelEncoder()\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "tmp=pd.DataFrame()\n",
    "train_data['text_1'] = train_lstm_input['理财产品名称'].astype(str) \n",
    "\n",
    "# train_data['text_1'] = train_lstm_input['理财产品名称'].astype(str) + '_' + train_lstm_input['产品发行方名称'].astype(str)\n",
    "\n",
    "# train_data['text_2'] = train_lstm_input['text'].astype(str)\n",
    "\n",
    "# train_lstm_input[\"文本类别\"]=\"理财产品\"\n",
    "\n",
    "train_data['label_1'] = \"理财产品\"\n",
    "\n",
    "\n",
    "train_data2=train_lstm_input[train_lstm_input[\"产品发行方名称\"]!=\"否\"].reset_index(drop=True)\n",
    "\n",
    "# train_data2[\"文本类别\"]=\"发行方\"\n",
    "\n",
    "tmp['text_1']=train_data2[\"产品发行方名称\"].astype(str)\n",
    "\n",
    "# tmp['text_2']= train_data2[\"text\"].astype(str)\n",
    "\n",
    "tmp['label_1']=\"发行方\"\n",
    "\n",
    "train_data = pd.concat([train_data,tmp]).reset_index(drop=True)\n",
    "\n",
    "train_data2=train_lstm_input[train_lstm_input[\"实际购买公司名称\"]!=\"否\"].reset_index(drop=True)\n",
    "\n",
    "# train_data2[\"文本类别\"]=\"发行方\"\n",
    "\n",
    "tmp['text_1']=train_data2[\"实际购买公司名称\"].astype(str)\n",
    "\n",
    "# tmp['text_2']= train_data2[\"text\"].astype(str)\n",
    "\n",
    "tmp['label_1']=\"购买公司\"\n",
    "\n",
    "train_data = pd.concat([train_data,tmp]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "other_columns_list=[\"认购金额(万元)\",\"认购日期\",\"资金来源\",\"实际购买公司和上市公司关系\"]\n",
    "\n",
    "# train_lstm_input[train_lstm_input[\"认购金额(万元)\"].astype(str)!=\"否\"]\n",
    "\n",
    "for item in other_columns_list:\n",
    "    print(item)\n",
    "\n",
    "    train_data2=train_lstm_input[train_lstm_input[item].astype(str)!=\"否\"].reset_index(drop=True)\n",
    "\n",
    "    # train_data2[\"文本类别\"]=item\n",
    "\n",
    "    tmp['text_1']=train_data2[item].astype(str)\n",
    "\n",
    "    # tmp['text_2']= train_data2[\"text\"].astype(str)\n",
    "\n",
    "    tmp['label_1']=\"其它\"\n",
    "\n",
    "    \n",
    "    train_data = pd.concat([train_data,tmp]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# train_data['label_2'] = label_2.fit_transform(train_lstm_input['资金来源'])\n",
    "# train_data['label_3'] = label_3.fit_transform(train_lstm_input['实际购买公司和上市公司关系'])\n",
    "# train_data['label_4'] = label_4.fit_transform(train_lstm_input['买卖方是否有关联关系'])\n",
    "train_data\n",
    "\n",
    "train_src=[]\n",
    "for text,label in train_data[[\"text_1\",\"label_1\"]].values:\n",
    "    train_src.append([label,text])\n",
    "\n",
    "\n",
    "grocery_word_selector=Grocery(\"wordSelector\")\n",
    "\n",
    "\n",
    "grocery_word_selector.train(train_src)\n",
    "\n",
    "grocery_word_selector.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "10%|█         | 2/20 [00:00<00:02,  7.25it/s]125\n1739\n————————————————\n179\n1806\n————————————————\n23\n7032\n————————————————\n 20%|██        | 4/20 [00:00<00:02,  7.44it/s]208\n2974\n————————————————\n98\n6903\n————————————————\n 40%|████      | 8/20 [00:04<00:06,  1.99it/s]902\n446\n————————————————\n67\n9083\n————————————————\n85\n3581\n————————————————\n 45%|████▌     | 9/20 [00:04<00:04,  2.21it/s]374\n4188\n————————————————\n76\n7237\n————————————————\n118\n2765\n————————————————\n 65%|██████▌   | 13/20 [00:05<00:01,  3.73it/s]91\n4791\n————————————————\n112\n9075\n————————————————\n 70%|███████   | 14/20 [00:05<00:01,  3.74it/s]183\n9004\n————————————————\n128\n7617\n————————————————\n 80%|████████  | 16/20 [00:05<00:00,  4.34it/s]169\n4028\n————————————————\n131\n7618\n————————————————\n 90%|█████████ | 18/20 [00:06<00:00,  5.09it/s]143\n2996\n————————————————\n53\n6220\n————————————————\n100%|██████████| 20/20 [00:06<00:00,  3.00it/s]262\n3247\n————————————————\n\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_title(text):\n",
    "    global title_num_char\n",
    "    title_list=[]\n",
    "    title_type_list=[]\n",
    "    text_start_iter_list=[]\n",
    "    text_end_iter_list=[]\n",
    "    for item in title_num_char:\n",
    "        pattern = re.compile(item+r\"[ ]*?[^ ]+?[ ]\")\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(1)\n",
    "            # text_end_iter_list.append(i.span(0)[1]) #把标题纳入text\n",
    "            text_end_iter_list.append(i.span(0)[0])\n",
    "    \n",
    "    # for item in title_list:\n",
    "    for item in s_title_num_char:\n",
    "        pattern = re.compile(item+r\"[ ]*?[^ ]+?[ ]\")\n",
    "        tmp=pattern.finditer(text)\n",
    "        for i in tmp:\n",
    "            title_list.append(i.group())\n",
    "            text_start_iter_list.append(i.span(0)[0])\n",
    "            title_type_list.append(2)\n",
    "            # text_end_iter_list.append(i.span(0)[1]) #把标题纳入text\n",
    "            text_end_iter_list.append(i.span(0)[0])\n",
    "\n",
    "    title_list.append(\"引言\")\n",
    "    title_type_list.append(1)\n",
    "    text_start_iter_list.append(0)\n",
    "    text_end_iter_list.append(0)\n",
    "\n",
    "    result_df=pd.DataFrame([title_list,title_type_list,text_start_iter_list,text_end_iter_list]).T.sort_values(by=2).reset_index(drop=True)\n",
    "    # print(result_df)\n",
    "    return result_df\n",
    "\n",
    "def get_title_text(text,title_df):\n",
    "    # print(title_df)\n",
    "    title_1_df=title_df[title_df[1]==1]\n",
    "    text_iter_list=[]\n",
    "    text_list=[]\n",
    "    # print(title_1_df)\n",
    "    for iter1,iter2 in title_1_df[[2,3]].values:\n",
    "        # print(iter1)\n",
    "        if(len(text_iter_list)!=0):\n",
    "            text_iter_list.append(iter1)\n",
    "        text_iter_list.append(iter2)\n",
    "    # text_iter_list.append(text_iter_list[len(text_iter_list)-1])\n",
    "    text_iter_list.append(len(text))\n",
    "    for index in range(int(len(text_iter_list)/2)):\n",
    "        text_list.append(text[text_iter_list[2*index]:text_iter_list[2*index+1]])\n",
    "    \n",
    "    title_1_df[4]=text_list\n",
    "\n",
    "    return title_1_df.reset_index(drop=True)\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "def judge_title(sample_id=0,text=r\"test\\n\"):\n",
    "    # print(text)\n",
    "    text=text.replace(r\"\\^\",\"\")\n",
    "    count=re.findall(r\".*?\\^.*?\",text)\n",
    "    if (count is not None and len(count)>0):\n",
    "        print(len(count))\n",
    "        print(sample_id)\n",
    "        print(\"————————————————\")\n",
    "    text=text.replace(r\"\\n\",\"^\").replace(\"（\",\"(\").replace(\"）\",\")\")\n",
    "    title_df=get_title(text)\n",
    "    count=re.findall(r\".*?\\^.*?\",text)\n",
    "    if (count is not None and len(count)>0):\n",
    "        print(len(count))\n",
    "        print(sample_id)\n",
    "        print(\"————————————————\")\n",
    "    title_df[\"sample_id\"]=[sample_id for x in range(title_df.shape[0])]\n",
    "    # print(title_df)\n",
    "    title_1_df=get_title_text(text,title_df)[[\"sample_id\",0,1,2,3,4]]\n",
    "\n",
    "    \n",
    "\n",
    "    global val_df\n",
    "    global train_outputs\n",
    "    val_true_name=train_outputs[train_outputs[\"sample_id\"]==sample_id][\"理财产品名称\"]\n",
    "    \n",
    "    index=0\n",
    "    neg_index=[]\n",
    "    for title_des in title_1_df[0].values:\n",
    "        for item in title_neg_words:\n",
    "            if re.search(item,title_des) is not None:\n",
    "                neg_index.append(index)\n",
    "                break\n",
    "        index+=1\n",
    "\n",
    "\n",
    "    return title_1_df.drop(neg_index)\n",
    "    # print(title_list)\n",
    "\n",
    "def get_judge_title_result(val_df):\n",
    "\n",
    "    judge_title_result=None\n",
    "\n",
    "\n",
    "    for sample_id,text in tqdm(val_df[[\"sample_id\",\"text\"]].values):\n",
    "        # print(sample_id)\n",
    "        # print(text)\n",
    "        judge_title_result= judge_title(sample_id,text) if judge_title_result is None else pd.concat([judge_title_result,judge_title(sample_id,text)])\n",
    "    \n",
    "    return judge_title_result\n",
    "\n",
    "title_num_char=[\"一、\",\"二、\",\"三、\",\"四、\",\"五、\",\"六、\",\"七、\",\"八、\",\"九、\",\"十、\",\"十一、\",\"十二、\",\"十三、\",\"十四、\",\"十五、\"]\n",
    "s_title_num_char=[\"（一）\",\"（二）\",\"（三）\",\"（四）\",\"（五）\",\"（六）\",\"（七）\",\"（八）\",\"（九）\",\"（十）\",\"（十一）\",\"（十二）\",\"（十三）\",\"（十四）\",\"（十五）\"]\n",
    "s_title_num_char.extend([\"[(]一[)]\",\"[(]二[)]\",\"[(]三[)]\",\"[(]四[)]\",\"[(]五[)]\",\"[(]六[)]\",\"[(]七[)]\",\"[(]八[)]\",\"[(]九[)]\",\"[(]十[)]\",\"[(]十一[)]\",\"[(]十二[)]\",\"[(]十三[)]\",\"[(]十四[)]\",\"[(]十五[)]\"])\n",
    "\n",
    "title_pos_words=[]\n",
    "title_neg_words=[\"备查\",\"日前\",\"过去\",\"履行\",\"审批\",\"程序\",\"风险\",\"措施\",\"影响\",\"累计\",\"赎回\",\"到期\",\"截至\",\"意见\",\"十二个月内\",\"公告前\",\"报备文件\",\"前期\"]\n",
    "\n",
    "val_judge_title_result=get_judge_title_result(val_df.head(20))\n",
    "# test_judge_title_result=get_judge_title_result(test_df)\n",
    "# judge_title_result.to_excel(\"训练集段落标题分类结果.xlsx\",index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 32818/32818 [00:00<00:00, 301057.63it/s]\nBuilding prefix dict from the default dictionary ...\nLoading model from cache C:\\Users\\lsqlh\\AppData\\Local\\Temp\\jieba.cache\nLoading model cost 2.130 seconds.\nPrefix dict has been built successfully.\n"
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "import jieba\n",
    "\n",
    "text_list=[]\n",
    "for product_name in tqdm(train_outputs[\"产品发行方名称\"].values):\n",
    "    text_list.append(str(product_name))\n",
    "\n",
    "# text_list\n",
    "\n",
    "a_list=[]\n",
    "\n",
    "for x in jieba.analyse.extract_tags((\",\").join(i for i in text_list),topK=100):#可以再添加一个参数指定输出个数\n",
    "    a_list.append(x)#直接输出关键词和词频\n",
    "\n",
    "# a_list\n",
    "\n",
    "# text_list=[]\n",
    "# for product_name in tqdm(train_outputs[\"理财产品名称\"].values):\n",
    "#     text_list.append(str(product_name))\n",
    "\n",
    "# b_list=[]\n",
    "\n",
    "# for x in jieba.analyse.extract_tags((\",\").join(i for i in text_list)):#可以再添加一个参数指定输出个数\n",
    "#     b_list.append(x)\n",
    "\n",
    "# set(b_list).difference(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'理财产品': -0.32860552275738786,\n '发行方': 1.0606784357993329,\n '购买公司': -0.42195233996337866,\n '其它': -0.3101205730785791}"
     },
     "metadata": {},
     "execution_count": 53
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['信赢', '步步高升', '4', '号', '(', 'B15C0873', ')']\n"
    }
   ],
   "source": [
    "a=\"中国银行股份[有限公司]辽宁省分行\"\n",
    "grocery_word_selector.predict(a).dec_values\n",
    "\n",
    "a=\"信赢步步高升4号(B15C0873)\"\n",
    "a=jieba.cut(a)\n",
    "print(list(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"['证券代码：002782         证券简称：可立克         公告编号：2016-081 ^ ^深圳可立克科技股份有限公司 ^关于使用闲置自有资金购买保本型银行理财产品的^实施公告 ^公司及董事会全体成员保证公告内容的真实、准确和完整，对公告的虚假^记载、误导性陈述或者重大遗漏负连带责任。 ^深圳可立克科技股份有限公司（以下简称“公司”或“本公司”）于 2016^年2月 1日在公司会议室召开了第二届董事会第十三次会议，审议通过了《关于^公司使用部分闲置自有资金购买理财产品的议案》，为提高资金使用效率，在确^保公司日常运营和资金安全的情况下，同意公司使用最高不超过人民币 16,000^万元的自有资金进行现金管理，用于购买低风险、短期的、由商业银行发行的保^本型理财产品。购买理财产品的额度在董事会审议通过之日起 12 个月有效期内^可以滚动使用，并授权董事长行使该项投资决策权、由财务负责人负责具体购买^事宜。公司独立董事、监事会、保荐机构已分别对此发表了同意的意见。具体内^容详见公司《深圳可立克科技股份有限公司关于使用部分闲置自有资金购买理财^产品的公告》（临时公告 2016-012号）。  ^一、本次使用部分闲置自有资金购买理财产品的实施情况  ^1、产品名称：招商银行点金公司理财之人民币岁月流金 51442号理财计划。  ^2、产品类型：保本浮动收益型。  ^3、理财产品投资方向：本理财计划由招商银行投资于我国银行间市场信用^级别较高、流动性较好的金融资产，包括但不限于国债、金融债、央行票据、债^券回购、资金拆借、银行存款以及高信用级别的企业债、公司债、短期融资券、^中期票据、资产支付证券、次级债等其他金融资产，并可投资于可转换债券、可^分离债、新股申购、交易所债券等其他金融资产。 ^4、预期最高收益率：年化收益率为2.75%。  ^5、产品期限：2016年10月18日—2017年1月16日。  ^1 ^ ', '6、认购金额：人民币 10,000,000.00元。  ^7、资金来源：公司闲置自有资金。  ^8、公司与招商银行股份有限公司深圳新时代支行无关联关系。  ^\""
     },
     "metadata": {},
     "execution_count": 90
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'理财产品': [' ^关于使用闲置自有资金购买保本型银行理财产品的^实施公告 ^公司'], '发行方': ['招商银行点金公司', '公司与招商银行股份有限公司'], '购买公司': ['081 ^ ^深圳可立克科技股份有限公司', ' ^深圳可立克科技股份有限公司', '深圳可立克科技股份有限公司'], '其它': []}\n"
    }
   ],
   "source": [
    "# firm=['公司', '银行', '分行', '支行', '中心', '业部', '商行', '建行']\n",
    "sample_id=7618\n",
    "\n",
    "text_list=[]\n",
    "for item in val_judge_title_result[val_judge_title_result[\"sample_id\"]==sample_id][4].values:\n",
    "    text_list.append(item)\n",
    "\n",
    "text=(\"\").join(i for i in text_list)\n",
    "text\n",
    "\n",
    "firm=['公司']\n",
    "for word in firm:\n",
    "    char_list=[]\n",
    "    for char in word:\n",
    "        char_list.append(\"[\"+char+\"]\")\n",
    "    word=(\"\").join(i for i in char_list)\n",
    "    firm_pattern=re.compile(\"[0-9A-Za-z\\u4e00-\\u9fa5\\^ ]+?\"+word+\"[0-9A-Za-z\\u4e00-\\u9fa5\\^ ]*?\")\n",
    "    re_result=firm_pattern.findall(text)\n",
    "\n",
    "    if re_result is None:\n",
    "        break\n",
    "\n",
    "    tmp_score=grocery_word_selector.predict(item).dec_values\n",
    "    result={}\n",
    "\n",
    "    for key in tmp_score:\n",
    "        result[key]=[]\n",
    "    \n",
    "    for item in re_result:\n",
    "        w_s_result=grocery_word_selector.predict(item)\n",
    "        key=str(w_s_result)\n",
    "        if(w_s_result.dec_values[key]>0.5):\n",
    "            result[key].append(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.抽取公告时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 首先针对任务抽取时间（每个时间跟每个id是一一对应的）\n",
    "# 要不是取第一个时间，要不就是取最后一个时间（或者时间加一）这里可以建立一个模型预测\n",
    "# base这里面直接取最后一个时间作为发布日期\n",
    "\n",
    "CN_NUM = {\n",
    "    u'〇': 0, u'一': 1, u'二': 2, u'三': 3,\n",
    "    u'四': 4, u'五': 5, u'六': 6, u'七': 7,\n",
    "    u'八': 8, u'九': 9, u'零': 0, u'壹': 1,\n",
    "    u'贰': 2, u'叁': 3, u'肆': 4, u'伍': 5,\n",
    "    u'陆': 6, u'柒': 7, u'捌': 8, u'玖': 9,\n",
    "    u'貮': 2, u'两': 2,\n",
    "}\n",
    "\n",
    "\n",
    "def get_put_time_from_text(row):\n",
    "    row = row.replace(' ', '').replace('\\\\n', '')\n",
    "    for key in CN_NUM:\n",
    "        row = row.replace(key, str(CN_NUM[key]))   \n",
    "    r = row.replace(\"年\", \"-\").replace(\"月\", \"-\").replace(\"日\", \" \").replace(\"/\", \"-\").strip()\n",
    "    regex = \"(\\d{4}-\\d{1,2}-\\d{1,2})\"\n",
    "    r = re.findall(regex, r)\n",
    "    if len(r)==0:\n",
    "        return np.nan\n",
    "    time_str = r[-1]\n",
    "    first = time_str.split('-')[0]\n",
    "    second = time_str.split('-')[1]\n",
    "    last = time_str.split('-')[-1]\n",
    "    second = str.zfill(second, 2)\n",
    "    last = str.zfill(last, 2)\n",
    "    r = '-'.join([first, second, last])\n",
    "    return r\n",
    "\n",
    "val_result = pd.DataFrame()\n",
    "val_result['sample_id'] = val_df['sample_id']\n",
    "val_result['predict_time'] = val_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "test_gg = train_outputs.groupby('sample_id').apply(lambda row:list(row['公告日期'])[0]).reset_index()\n",
    "test_gg.columns = ['sample_id', 'time']\n",
    "val_result = pd.merge(val_result, test_gg, on='sample_id', how='left')\n",
    "\n",
    "# 判断验证集的准确率\n",
    "np.sum(val_result['predict_time'].astype(str) == val_result['time'].astype(str))/len(val_result)\n",
    "\n",
    "val_time = val_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)\n",
    "# test_time = test_df.progress_apply(lambda row: get_put_time_from_text(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.抽取实际购买公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 抽取购买公司\n",
    "# 前几句话出现\n",
    "# 将其按照\\\\n 和空格切割\n",
    "def get_gm(row):\n",
    "    result = re.split('[\\\\\\\\n ]',row)\n",
    "    for i in result:\n",
    "        if '公司' in i:\n",
    "            return i\n",
    "\n",
    "val_gm = val_df.progress_apply(lambda row:get_gm(row['text']), axis=1)\n",
    "# test_gm = test_df.progress_apply(lambda row:get_gm(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后一部分字段采用预测好的部分，跟提取的text做交互采用双输入lstm在dense层做交互预测最后几个字段\n",
    "\n",
    "# train_lstm_input = pd.merge(train_df, train_outputs, on='sample_id', how='left')\n",
    "result_matrix\n",
    "train_lstm_input = pd.merge(train_table_df, train_outputs, on='sample_id', how='left')\n",
    "\n",
    "train_lstm_input = train_lstm_input.fillna('否')\n",
    "\n",
    "# label_1理财类型-10  label_2资金来源-3 label_3实际购买公司和上市公司关系-3 label_4买卖方是否有关联关系-2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_1 = LabelEncoder()\n",
    "# label_2 = LabelEncoder()\n",
    "# label_3 = LabelEncoder()\n",
    "# label_4 = LabelEncoder()\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "tmp=pd.DataFrame()\n",
    "train_data['text_1'] = train_lstm_input['理财产品名称'].astype(str) \n",
    "\n",
    "# train_data['text_1'] = train_lstm_input['理财产品名称'].astype(str) + '_' + train_lstm_input['产品发行方名称'].astype(str)\n",
    "\n",
    "train_data['text_2'] = train_lstm_input['text'].astype(str)\n",
    "\n",
    "train_lstm_input[\"文本类别\"]=\"理财产品\"\n",
    "\n",
    "train_data['label_1'] = label_1.fit_transform(train_lstm_input[\"文本类别\"])\n",
    "\n",
    "\n",
    "train_data2=train_lstm_input[train_lstm_input[\"产品发行方名称\"]!=\"无\"].reset_index(drop=True)\n",
    "\n",
    "train_data2[\"文本类别\"]=\"发行方\"\n",
    "\n",
    "tmp['text_1']=train_data2[\"产品发行方名称\"].astype(str)\n",
    "\n",
    "tmp['text_2']= train_data2[\"text\"].astype(str)\n",
    "\n",
    "tmp['label_1']=label_1.fit_transform(train_data2[\"文本类别\"])\n",
    "\n",
    "train_data = pd.concat([train_data,tmp]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "other_columns_list=[\"认购金额(万元)\",\"认购日期\"]\n",
    "\n",
    "for item in other_columns_list:\n",
    "\n",
    "    train_data2=train_lstm_input[train_lstm_input[item]!=\"无\"].reset_index(drop=True)\n",
    "\n",
    "    train_data2[\"文本类别\"]=\"其他\"\n",
    "\n",
    "    tmp['text_1']=train_data2[item].astype(str)\n",
    "\n",
    "    tmp['text_2']= train_data2[\"text\"].astype(str)\n",
    "\n",
    "    tmp['label_1']=label_1.fit_transform(train_data2[\"文本类别\"])\n",
    "\n",
    "    \n",
    "    train_data = pd.concat([train_data,tmp]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# train_data['label_2'] = label_2.fit_transform(train_lstm_input['资金来源'])\n",
    "# train_data['label_3'] = label_3.fit_transform(train_lstm_input['实际购买公司和上市公司关系'])\n",
    "# train_data['label_4'] = label_4.fit_transform(train_lstm_input['买卖方是否有关联关系'])\n",
    "train_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}